{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-Based Timetable Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# For data manipulations\n",
    "import pandas as pd\n",
    "import os\n",
    "# api for better ML\n",
    "import sklearn\n",
    "# Normalization functions\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer,RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import genfromtxt\n",
    "#from numba import njit, cuda,jit \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import several things from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequencial holds the box for neurons\n",
    "from tensorflow.keras.models import Sequential\n",
    "# The various neuron manupulation functions\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Embedding, LSTM, SimpleRNN, Dropout, Bidirectional, MaxPooling1D, Conv1D, TimeDistributed, Flatten,ConvLSTM2D,RepeatVector\n",
    "# These are going to adjust the weight and biases\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "# EarlyStopping is a callback that ends code when there is no improvement in error(validation model: pop quiz)\n",
    "# ModelCheckpoint is used to put checkpoints within the training and also saves only the best weights\n",
    "# Tensorboard keeps data logs\n",
    "# ReduceLROnPlateau prevents overshoots across the global mimnimum\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "# Just for better programming\n",
    "from keras.backend.tensorflow_backend import set_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 13570203439205308339\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 9427416405351648099\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 5066607840\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 454338882301452780\nphysical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 17007105467415447532\nphysical_device_desc: \"device: XLA_GPU device\"\n]\nNum GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Checking the GPU availabilty from tensorflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was developed using Python 3.6 (Anaconda) and package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.2.0-rc3'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.0.3'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Timetable Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [ 'data_file_algebra', 'data_file_comm', 'data_file_mech']\n",
    "file=f'E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Data\\Single_courses\\{data_files[0]}.csv'\n",
    "#myData = pd.read_csv(file, delimiter=',')\n",
    "myData = pd.read_csv(file, delimiter=',', usecols=['Program','Actual CWA','Score','Study Time','Lecturer Performance','Difficulty'\n",
    "])\n",
    "#figsize=(35,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(188, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "myData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Program  Actual CWA  Score  Study Time  Lecturer Performance  \\\n",
       "0      Electrical       74.00   66.0         3.0                     4   \n",
       "1        Computer       70.00   55.0         3.0                     7   \n",
       "2      Electrical       68.30   55.0         2.0                     1   \n",
       "3      Electrical       76.00   85.0         1.0                     9   \n",
       "4     Electrical        65.00   57.0         1.0                     7   \n",
       "..            ...         ...    ...         ...                   ...   \n",
       "183      Computer       65.00   40.0         3.5                     4   \n",
       "184  Agricultural       63.67   68.0         4.5                    10   \n",
       "185      Computer       56.70   54.0         0.8                     6   \n",
       "186     Computer        65.00   40.0         3.5                     4   \n",
       "187      Computer       71.24   68.0         4.5                     7   \n",
       "\n",
       "     Difficulty  \n",
       "0             9  \n",
       "1             8  \n",
       "2             9  \n",
       "3             1  \n",
       "4             5  \n",
       "..          ...  \n",
       "183          10  \n",
       "184           5  \n",
       "185           5  \n",
       "186          10  \n",
       "187           8  \n",
       "\n",
       "[188 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Actual CWA</th>\n      <th>Score</th>\n      <th>Study Time</th>\n      <th>Lecturer Performance</th>\n      <th>Difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Electrical</td>\n      <td>74.00</td>\n      <td>66.0</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Computer</td>\n      <td>70.00</td>\n      <td>55.0</td>\n      <td>3.0</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Electrical</td>\n      <td>68.30</td>\n      <td>55.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Electrical</td>\n      <td>76.00</td>\n      <td>85.0</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Electrical</td>\n      <td>65.00</td>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>Computer</td>\n      <td>65.00</td>\n      <td>40.0</td>\n      <td>3.5</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>Agricultural</td>\n      <td>63.67</td>\n      <td>68.0</td>\n      <td>4.5</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>Computer</td>\n      <td>56.70</td>\n      <td>54.0</td>\n      <td>0.8</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>Computer</td>\n      <td>65.00</td>\n      <td>40.0</td>\n      <td>3.5</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>Computer</td>\n      <td>71.24</td>\n      <td>68.0</td>\n      <td>4.5</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>188 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "myData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the variables used in the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Program', 'Actual CWA', 'Score', 'Study Time',\n",
       "       'Lecturer Performance', 'Difficulty'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data_top = myData.columns.values\n",
    "data_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the top rows of the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Program  Actual CWA  Score  Study Time  Lecturer Performance  \\\n",
       "0   Electrical        74.0   66.0         3.0                     4   \n",
       "1     Computer        70.0   55.0         3.0                     7   \n",
       "2   Electrical        68.3   55.0         2.0                     1   \n",
       "3   Electrical        76.0   85.0         1.0                     9   \n",
       "4  Electrical         65.0   57.0         1.0                     7   \n",
       "\n",
       "   Difficulty  \n",
       "0           9  \n",
       "1           8  \n",
       "2           9  \n",
       "3           1  \n",
       "4           5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Actual CWA</th>\n      <th>Score</th>\n      <th>Study Time</th>\n      <th>Lecturer Performance</th>\n      <th>Difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Electrical</td>\n      <td>74.0</td>\n      <td>66.0</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Computer</td>\n      <td>70.0</td>\n      <td>55.0</td>\n      <td>3.0</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Electrical</td>\n      <td>68.3</td>\n      <td>55.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Electrical</td>\n      <td>76.0</td>\n      <td>85.0</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Electrical</td>\n      <td>65.0</td>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "myData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a signal"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "figsize=(10,10)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(myData['Score'],myData['Study Time'], 'o')\n",
    "plt.grid(color='b', linestyle='-.', linewidth=0.5)\n",
    "plt.show()"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"574.678125pt\" version=\"1.1\" viewBox=\"0 0 585.7625 574.678125\" width=\"585.7625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 574.678125 \r\nL 585.7625 574.678125 \r\nL 585.7625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 20.5625 550.8 \r\nL 578.5625 550.8 \r\nL 578.5625 7.2 \r\nL 20.5625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 42.220137 550.8 \r\nL 42.220137 7.2 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m54d9d9163a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.220137\" xlink:href=\"#m54d9d9163a\" y=\"550.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(39.038887 565.398438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 154.523154 550.8 \r\nL 154.523154 7.2 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"154.523154\" xlink:href=\"#m54d9d9163a\" y=\"550.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(148.160654 565.398438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 266.826171 550.8 \r\nL 266.826171 7.2 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.826171\" xlink:href=\"#m54d9d9163a\" y=\"550.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(260.463671 565.398438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 379.129187 550.8 \r\nL 379.129187 7.2 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"379.129187\" xlink:href=\"#m54d9d9163a\" y=\"550.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(372.766687 565.398438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 491.432204 550.8 \r\nL 491.432204 7.2 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"491.432204\" xlink:href=\"#m54d9d9163a\" y=\"550.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(485.069704 565.398438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 510.14956 \r\nL 578.5625 510.14956 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m3d7535b7ae\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"510.14956\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 1 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 513.948779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 430.442815 \r\nL 578.5625 430.442815 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"430.442815\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(7.2 434.242034)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 350.73607 \r\nL 578.5625 350.73607 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"350.73607\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 3 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 354.535289)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 271.029326 \r\nL 578.5625 271.029326 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"271.029326\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(7.2 274.828544)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 191.322581 \r\nL 578.5625 191.322581 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"191.322581\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 195.121799)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 111.615836 \r\nL 578.5625 111.615836 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"111.615836\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 6 -->\r\n      <g transform=\"translate(7.2 115.415055)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p3d501a16c5)\" d=\"M 20.5625 31.909091 \r\nL 578.5625 31.909091 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:3.2,0.8,0.5,0.8;stroke-dashoffset:0;stroke-width:0.5;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m3d7535b7ae\" y=\"31.909091\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 7 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 35.70831)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m277fd45444\" style=\"stroke:#1f77b4;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#p3d501a16c5)\">\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"412.820093\" xlink:href=\"#m277fd45444\" y=\"350.73607\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"351.053433\" xlink:href=\"#m277fd45444\" y=\"350.73607\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"351.053433\" xlink:href=\"#m277fd45444\" y=\"430.442815\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"519.507959\" xlink:href=\"#m277fd45444\" y=\"510.14956\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"362.283735\" xlink:href=\"#m277fd45444\" y=\"510.14956\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"452.126148\" xlink:href=\"#m277fd45444\" y=\"191.322581\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"510.14956\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"553.198864\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"452.126148\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"457.741299\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"474.586752\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"457.741299\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"401.589791\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"452.126148\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"373.514037\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"440.895847\" xlink:href=\"#m277fd45444\" y=\"31.909091\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"463.35645\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"429.665545\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"373.514037\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"513.892808\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"367.898886\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"401.589791\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"367.898886\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"457.741299\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"474.586752\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"440.895847\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"418.435243\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"412.820093\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"463.35645\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"553.198864\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"351.053433\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"31.909091\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"395.97464\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"418.435243\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"395.97464\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"384.744338\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"429.665545\" xlink:href=\"#m277fd45444\" y=\"191.322581\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"553.198864\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"474.586752\" xlink:href=\"#m277fd45444\" y=\"71.762463\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"485.817054\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"294.901925\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"322.977679\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"412.820093\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"373.514037\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"497.047355\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"401.589791\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"440.895847\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"502.662506\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"485.817054\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"457.741299\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"373.514037\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"418.435243\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"497.047355\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"294.901925\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"362.283735\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"508.277657\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"327.245194\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"334.207981\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"452.126148\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"440.895847\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"508.277657\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"306.132226\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"452.126148\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"339.823132\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"351.053433\" xlink:href=\"#m277fd45444\" y=\"191.322581\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"367.898886\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"502.662506\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"384.744338\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"31.909091\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"519.507959\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"457.741299\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"367.898886\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"513.892808\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"294.901925\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"191.322581\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"463.35645\" xlink:href=\"#m277fd45444\" y=\"111.615836\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"395.97464\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"502.662506\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"45.926136\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"519.507959\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"334.207981\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"384.744338\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"468.971601\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"351.053433\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"463.35645\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"429.665545\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"351.053433\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"345.438282\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"440.895847\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"418.435243\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"463.35645\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"345.438282\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"429.665545\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"463.35645\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"339.823132\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"407.204942\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"362.283735\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"446.510998\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"485.817054\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"485.817054\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"553.198864\" xlink:href=\"#m277fd45444\" y=\"510.14956\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"519.507959\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"318.853372\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"395.97464\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"491.432204\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"362.283735\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"429.665545\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.201903\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"379.129187\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"306.132226\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"367.898886\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"322.977679\" xlink:href=\"#m277fd45444\" y=\"470.296188\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"435.280696\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"519.507959\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"390.359489\" xlink:href=\"#m277fd45444\" y=\"390.589443\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"362.283735\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"401.589791\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"367.898886\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"345.438282\" xlink:href=\"#m277fd45444\" y=\"526.090909\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"266.826171\" xlink:href=\"#m277fd45444\" y=\"310.882698\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"424.050394\" xlink:href=\"#m277fd45444\" y=\"231.175953\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 20.5625 550.8 \r\nL 20.5625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 578.5625 550.8 \r\nL 578.5625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 20.5625 550.8 \r\nL 578.5625 550.8 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 20.5625 7.2 \r\nL 578.5625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p3d501a16c5\">\r\n   <rect height=\"543.6\" width=\"558\" x=\"20.5625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(188, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "myData.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Program  Actual CWA  Score  Study Time  Lecturer Performance  Difficulty\n",
       "0  Electrical        74.0   66.0         3.0                     4           9"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Actual CWA</th>\n      <th>Score</th>\n      <th>Study Time</th>\n      <th>Lecturer Performance</th>\n      <th>Difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Electrical</td>\n      <td>74.0</td>\n      <td>66.0</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "myData.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 5 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"528.925252pt\" version=\"1.1\" viewBox=\"0 0 601.665625 528.925252\" width=\"601.665625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 528.925252 \r\nL 601.665625 528.925252 \r\nL 601.665625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 91.613793 \r\nL 594.465625 91.613793 \r\nL 594.465625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m769b7ac07c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.829261\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.646471\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.46368\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.28089\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.098099\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"400.915309\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"468.732519\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"536.549728\" xlink:href=\"#m769b7ac07c\" y=\"91.613793\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"ma13a9a9a03\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"90.518523\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(23.103125 94.317742)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"66.883001\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 25 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(16.740625 70.68222)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"43.24748\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(16.740625 47.046698)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"19.611958\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 75 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(16.740625 23.411177)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p1cc6de5207)\" d=\"M 61.829261 20.557379 \r\nL 64.54195 24.339062 \r\nL 67.254638 25.946278 \r\nL 69.967327 18.666537 \r\nL 72.680015 29.066167 \r\nL 75.392703 19.611958 \r\nL 78.105392 40.97847 \r\nL 80.81808 26.088091 \r\nL 83.530768 25.14267 \r\nL 88.956145 15.830274 \r\nL 91.668834 15.017212 \r\nL 94.381522 29.198525 \r\nL 97.09421 24.282337 \r\nL 99.806899 28.120746 \r\nL 102.519587 32.526407 \r\nL 105.232275 17.588757 \r\nL 107.944964 17.541486 \r\nL 110.657652 27.175325 \r\nL 113.370341 30.011587 \r\nL 116.083029 20.954456 \r\nL 118.795717 21.578433 \r\nL 121.508406 15.745187 \r\nL 124.221094 26.229904 \r\nL 126.933783 17.172772 \r\nL 129.646471 24.24452 \r\nL 132.359159 23.544909 \r\nL 135.071848 21.824243 \r\nL 137.784536 20.557379 \r\nL 140.497224 28.120746 \r\nL 143.209913 19.044705 \r\nL 145.922601 20.481745 \r\nL 148.63529 20.557379 \r\nL 151.347978 26.229904 \r\nL 154.060666 15.575011 \r\nL 156.773355 29.066167 \r\nL 159.486043 21.5028 \r\nL 162.198731 20.765371 \r\nL 164.91142 23.507092 \r\nL 167.624108 25.804465 \r\nL 170.336797 26.229904 \r\nL 173.049485 20.557379 \r\nL 175.762173 45.80957 \r\nL 178.474862 24.443059 \r\nL 181.18755 16.945871 \r\nL 183.900239 14.884854 \r\nL 186.612927 25.568109 \r\nL 189.325615 22.826389 \r\nL 192.038304 24.282337 \r\nL 194.750992 19.148702 \r\nL 197.46368 23.970348 \r\nL 200.176369 21.758063 \r\nL 202.889057 11.604243 \r\nL 205.601746 30.011587 \r\nL 208.314434 25.993549 \r\nL 211.027122 23.403096 \r\nL 213.739811 17.721116 \r\nL 216.452499 22.845297 \r\nL 219.165187 30.011587 \r\nL 221.877876 17.721116 \r\nL 224.590564 25.095399 \r\nL 227.303253 19.611958 \r\nL 230.015941 16.482615 \r\nL 232.728629 22.391495 \r\nL 235.441318 25.284483 \r\nL 238.154006 24.925223 \r\nL 240.866695 19.101431 \r\nL 243.579383 15.225205 \r\nL 246.292071 11.036991 \r\nL 249.00476 39.465796 \r\nL 251.717448 27.269867 \r\nL 254.430136 23.393641 \r\nL 257.142825 25.104853 \r\nL 259.855513 25.61538 \r\nL 262.568202 31.47699 \r\nL 265.28089 16.775695 \r\nL 267.993578 33.793271 \r\nL 270.706267 20.103577 \r\nL 273.418955 31.165001 \r\nL 276.131643 20.027943 \r\nL 278.844332 36.638988 \r\nL 281.55702 30.957008 \r\nL 284.269709 12.048591 \r\nL 286.982397 27.175325 \r\nL 289.695085 30.957008 \r\nL 292.407774 29.066167 \r\nL 295.120462 30.011587 \r\nL 297.833151 33.793271 \r\nL 300.545839 26.418988 \r\nL 303.258527 30.503206 \r\nL 305.971216 29.066167 \r\nL 308.683904 34.265981 \r\nL 311.396592 23.95144 \r\nL 314.109281 11.793327 \r\nL 316.821969 41.63081 \r\nL 319.534658 28.120746 \r\nL 322.247346 34.738692 \r\nL 324.960034 26.674252 \r\nL 327.672723 19.923947 \r\nL 330.385411 18.193827 \r\nL 333.098099 30.957008 \r\nL 335.810788 23.724539 \r\nL 338.523476 27.175325 \r\nL 341.236165 39.465796 \r\nL 343.948853 26.532439 \r\nL 346.661541 21.030089 \r\nL 349.37423 19.507962 \r\nL 352.086918 13.939433 \r\nL 354.799607 25.558655 \r\nL 357.512295 20.557379 \r\nL 360.224983 43.24748 \r\nL 362.937672 87.776803 \r\nL 365.65036 24.301245 \r\nL 368.363048 33.660912 \r\nL 371.075737 24.613234 \r\nL 373.788425 26.51353 \r\nL 376.501114 13.674715 \r\nL 379.213802 28.30983 \r\nL 381.92649 20.009035 \r\nL 384.639179 24.528146 \r\nL 387.351867 26.258267 \r\nL 390.064555 19.611958 \r\nL 392.777244 33.897267 \r\nL 395.489932 13.892162 \r\nL 398.202621 31.165001 \r\nL 400.915309 19.328332 \r\nL 403.627997 32.658766 \r\nL 406.340686 22.306407 \r\nL 409.053374 25.558655 \r\nL 411.766063 27.175325 \r\nL 414.478751 19.091976 \r\nL 417.191439 25.624835 \r\nL 419.904128 30.957008 \r\nL 422.616816 35.788109 \r\nL 425.329504 24.78341 \r\nL 428.042193 29.066167 \r\nL 430.754881 28.149108 \r\nL 433.46757 31.902429 \r\nL 436.180258 29.066167 \r\nL 438.892946 31.902429 \r\nL 441.605635 18.052013 \r\nL 444.318323 29.066167 \r\nL 447.031011 34.738692 \r\nL 449.7437 19.611958 \r\nL 452.456388 23.762355 \r\nL 455.169077 16.775695 \r\nL 457.881765 24.339062 \r\nL 460.594453 16.775695 \r\nL 463.307142 14.884854 \r\nL 466.01983 34.10526 \r\nL 468.732519 25.048128 \r\nL 471.445207 22.126777 \r\nL 474.157895 35.684113 \r\nL 476.870584 32.84785 \r\nL 479.583272 16.775695 \r\nL 482.29596 23.393641 \r\nL 485.008649 21.370441 \r\nL 487.721337 12.020228 \r\nL 490.434026 11.500247 \r\nL 493.146714 30.011587 \r\nL 495.859402 33.897267 \r\nL 498.572091 24.367425 \r\nL 501.284779 17.721116 \r\nL 503.997467 33.424557 \r\nL 506.710156 35.504483 \r\nL 509.422844 20.443928 \r\nL 512.135533 24.149978 \r\nL 514.848221 19.611958 \r\nL 517.560909 21.417712 \r\nL 520.273598 24.149978 \r\nL 522.986286 29.189071 \r\nL 525.698975 24.622688 \r\nL 528.411663 24.291791 \r\nL 531.124351 32.658766 \r\nL 533.83704 29.066167 \r\nL 536.549728 37.574954 \r\nL 539.262416 31.618803 \r\nL 541.975105 19.337786 \r\nL 544.687793 15.924816 \r\nL 547.400482 47.407331 \r\nL 550.11317 28.120746 \r\nL 552.825858 25.048128 \r\nL 555.538547 30.957008 \r\nL 558.251235 29.066167 \r\nL 560.963923 30.323576 \r\nL 563.676612 36.91316 \r\nL 566.3893 29.066167 \r\nL 569.101989 23.16674 \r\nL 569.101989 23.16674 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 91.613793 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 594.465625 91.613793 \r\nL 594.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 91.613793 \r\nL 594.465625 91.613793 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 594.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 43.465625 86.613793 \r\nL 133.132812 86.613793 \r\nQ 135.132812 86.613793 135.132812 84.613793 \r\nL 135.132812 70.935668 \r\nQ 135.132812 68.935668 133.132812 68.935668 \r\nL 43.465625 68.935668 \r\nQ 41.465625 68.935668 41.465625 70.935668 \r\nL 41.465625 84.613793 \r\nQ 41.465625 86.613793 43.465625 86.613793 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_14\">\r\n     <path d=\"M 45.465625 77.034106 \r\nL 65.465625 77.034106 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\"/>\r\n    <g id=\"text_5\">\r\n     <!-- Actual CWA -->\r\n     <defs>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n      <path d=\"M 3.328125 72.90625 \r\nL 13.28125 72.90625 \r\nL 28.609375 11.28125 \r\nL 43.890625 72.90625 \r\nL 54.984375 72.90625 \r\nL 70.3125 11.28125 \r\nL 85.59375 72.90625 \r\nL 95.609375 72.90625 \r\nL 77.296875 0 \r\nL 64.890625 0 \r\nL 49.515625 63.28125 \r\nL 33.984375 0 \r\nL 21.578125 0 \r\nz\r\n\" id=\"DejaVuSans-87\"/>\r\n     </defs>\r\n     <g transform=\"translate(73.465625 80.534106)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"160.847656\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"224.226562\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"285.505859\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"313.289062\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"345.076172\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"414.900391\" xlink:href=\"#DejaVuSans-87\"/>\r\n      <use x=\"508.277344\" xlink:href=\"#DejaVuSans-65\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 36.465625 192.910345 \r\nL 594.465625 192.910345 \r\nL 594.465625 108.496552 \r\nL 36.465625 108.496552 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.829261\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.646471\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.46368\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.28089\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_13\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.098099\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_14\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"400.915309\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_15\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"468.732519\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_16\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"536.549728\" xlink:href=\"#m769b7ac07c\" y=\"192.910345\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"189.633995\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(23.103125 193.433214)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"168.397607\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(16.740625 172.196826)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"147.161219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(16.740625 150.960437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"125.924831\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 75 -->\r\n      <g transform=\"translate(16.740625 129.724049)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_28\">\r\n    <path clip-path=\"url(#p7719059e1c)\" d=\"M 61.829261 133.56993 \r\nL 64.54195 142.913941 \r\nL 67.254638 142.913941 \r\nL 69.967327 117.430275 \r\nL 72.680015 141.21503 \r\nL 75.392703 127.623742 \r\nL 78.105392 155.655774 \r\nL 80.81808 123.376464 \r\nL 83.530768 138.666664 \r\nL 86.243457 138.666664 \r\nL 88.956145 123.376464 \r\nL 91.668834 112.333542 \r\nL 94.381522 130.172108 \r\nL 97.09421 121.677553 \r\nL 99.806899 127.623742 \r\nL 102.519587 126.774286 \r\nL 105.232275 124.22592 \r\nL 107.944964 128.473197 \r\nL 110.657652 136.967752 \r\nL 113.370341 136.967752 \r\nL 116.083029 126.774286 \r\nL 118.795717 135.268841 \r\nL 121.508406 121.677553 \r\nL 124.221094 127.623742 \r\nL 126.933783 123.376464 \r\nL 129.646471 123.376464 \r\nL 132.359159 136.967752 \r\nL 135.071848 139.516119 \r\nL 137.784536 129.322653 \r\nL 140.497224 138.666664 \r\nL 143.209913 125.924831 \r\nL 145.922601 131.021564 \r\nL 148.63529 121.677553 \r\nL 151.347978 139.516119 \r\nL 154.060666 118.279731 \r\nL 156.773355 140.365575 \r\nL 159.486043 130.172108 \r\nL 162.198731 128.473197 \r\nL 164.91142 135.268841 \r\nL 167.624108 140.365575 \r\nL 170.336797 126.774286 \r\nL 173.049485 128.473197 \r\nL 175.762173 155.655774 \r\nL 178.474862 134.419386 \r\nL 181.18755 124.22592 \r\nL 183.900239 129.322653 \r\nL 186.612927 138.666664 \r\nL 189.325615 132.720475 \r\nL 192.038304 121.677553 \r\nL 194.750992 133.56993 \r\nL 197.46368 125.924831 \r\nL 200.176369 131.871019 \r\nL 202.889057 112.333542 \r\nL 205.601746 142.913941 \r\nL 208.314434 128.473197 \r\nL 211.027122 138.666664 \r\nL 213.739811 136.118297 \r\nL 216.452499 132.720475 \r\nL 219.165187 138.666664 \r\nL 221.877876 136.118297 \r\nL 224.590564 137.817208 \r\nL 227.303253 131.021564 \r\nL 230.015941 112.333542 \r\nL 232.728629 123.376464 \r\nL 235.441318 123.376464 \r\nL 238.154006 134.419386 \r\nL 240.866695 124.22592 \r\nL 243.579383 122.527009 \r\nL 246.292071 123.376464 \r\nL 249.00476 151.408496 \r\nL 251.717448 147.161219 \r\nL 254.430136 133.56993 \r\nL 257.142825 136.967752 \r\nL 259.855513 121.677553 \r\nL 262.568202 139.516119 \r\nL 265.28089 120.828098 \r\nL 267.993578 130.172108 \r\nL 270.706267 128.473197 \r\nL 273.418955 135.268841 \r\nL 276.131643 129.322653 \r\nL 278.844332 128.473197 \r\nL 281.55702 119.978642 \r\nL 284.269709 122.527009 \r\nL 286.982397 126.774286 \r\nL 289.695085 139.516119 \r\nL 292.407774 130.172108 \r\nL 295.120462 132.720475 \r\nL 297.833151 134.419386 \r\nL 300.545839 120.828098 \r\nL 303.258527 151.408496 \r\nL 305.971216 128.473197 \r\nL 308.683904 141.21503 \r\nL 314.109281 119.129187 \r\nL 316.821969 146.515633 \r\nL 319.534658 145.462308 \r\nL 322.247346 131.871019 \r\nL 324.960034 127.623742 \r\nL 327.672723 129.322653 \r\nL 330.385411 119.129187 \r\nL 333.098099 149.709585 \r\nL 335.810788 127.623742 \r\nL 338.523476 134.419386 \r\nL 341.236165 144.612852 \r\nL 343.948853 142.913941 \r\nL 346.661541 134.419386 \r\nL 349.37423 140.365575 \r\nL 352.086918 119.978642 \r\nL 354.799607 137.817208 \r\nL 357.512295 131.871019 \r\nL 360.224983 134.419386 \r\nL 362.937672 117.430275 \r\nL 365.65036 126.774286 \r\nL 368.363048 138.666664 \r\nL 371.075737 131.871019 \r\nL 373.788425 140.365575 \r\nL 376.501114 118.279731 \r\nL 379.213802 151.408496 \r\nL 381.92649 121.677553 \r\nL 384.639179 136.967752 \r\nL 387.351867 131.871019 \r\nL 390.064555 125.924831 \r\nL 392.777244 136.118297 \r\nL 395.489932 119.978642 \r\nL 398.202621 189.073354 \r\nL 400.915309 117.430275 \r\nL 403.627997 145.462308 \r\nL 406.340686 136.967752 \r\nL 409.053374 137.817208 \r\nL 411.766063 128.473197 \r\nL 414.478751 123.376464 \r\nL 417.191439 130.172108 \r\nL 419.904128 125.075375 \r\nL 422.616816 131.871019 \r\nL 425.329504 136.967752 \r\nL 428.042193 142.913941 \r\nL 430.754881 125.924831 \r\nL 433.46757 131.021564 \r\nL 436.180258 142.913941 \r\nL 438.892946 143.763397 \r\nL 441.605635 129.322653 \r\nL 444.318323 132.720475 \r\nL 447.031011 138.666664 \r\nL 449.7437 125.924831 \r\nL 452.456388 143.763397 \r\nL 455.169077 128.473197 \r\nL 457.881765 131.021564 \r\nL 463.307142 125.924831 \r\nL 466.01983 144.612852 \r\nL 468.732519 134.419386 \r\nL 471.445207 131.871019 \r\nL 474.157895 141.21503 \r\nL 476.870584 131.871019 \r\nL 479.583272 128.473197 \r\nL 482.29596 122.527009 \r\nL 485.008649 122.527009 \r\nL 487.721337 112.333542 \r\nL 490.434026 117.430275 \r\nL 493.146714 155.655774 \r\nL 495.859402 136.118297 \r\nL 498.572091 138.666664 \r\nL 501.284779 121.677553 \r\nL 503.997467 155.655774 \r\nL 506.710156 141.21503 \r\nL 509.422844 131.021564 \r\nL 512.135533 123.376464 \r\nL 514.848221 130.172108 \r\nL 517.560909 123.376464 \r\nL 520.273598 123.376464 \r\nL 522.986286 130.172108 \r\nL 525.698975 131.871019 \r\nL 528.411663 138.666664 \r\nL 531.124351 149.709585 \r\nL 533.83704 140.365575 \r\nL 536.549728 147.161219 \r\nL 539.262416 130.172108 \r\nL 541.975105 117.430275 \r\nL 544.687793 136.967752 \r\nL 547.400482 155.655774 \r\nL 550.11317 141.21503 \r\nL 552.825858 135.268841 \r\nL 555.538547 140.365575 \r\nL 558.251235 155.655774 \r\nL 560.963923 131.871019 \r\nL 566.3893 155.655774 \r\nL 569.101989 131.871019 \r\nL 569.101989 131.871019 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 36.465625 192.910345 \r\nL 36.465625 108.496552 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 594.465625 192.910345 \r\nL 594.465625 108.496552 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 36.465625 192.910345 \r\nL 594.465625 192.910345 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 36.465625 108.496552 \r\nL 594.465625 108.496552 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_2\">\r\n    <g id=\"patch_13\">\r\n     <path d=\"M 43.465625 187.910345 \r\nL 103.470313 187.910345 \r\nQ 105.470313 187.910345 105.470313 185.910345 \r\nL 105.470313 172.23222 \r\nQ 105.470313 170.23222 103.470313 170.23222 \r\nL 43.465625 170.23222 \r\nQ 41.465625 170.23222 41.465625 172.23222 \r\nL 41.465625 185.910345 \r\nQ 41.465625 187.910345 43.465625 187.910345 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_29\">\r\n     <path d=\"M 45.465625 178.330657 \r\nL 65.465625 178.330657 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_30\"/>\r\n    <g id=\"text_10\">\r\n     <!-- Score -->\r\n     <defs>\r\n      <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n     </defs>\r\n     <g transform=\"translate(73.465625 181.830657)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"118.457031\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"179.638672\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"218.501953\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g id=\"patch_14\">\r\n    <path d=\"M 36.465625 294.206897 \r\nL 594.465625 294.206897 \r\nL 594.465625 209.793103 \r\nL 36.465625 209.793103 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_5\">\r\n    <g id=\"xtick_17\">\r\n     <g id=\"line2d_31\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.829261\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_18\">\r\n     <g id=\"line2d_32\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.646471\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_19\">\r\n     <g id=\"line2d_33\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.46368\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_20\">\r\n     <g id=\"line2d_34\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.28089\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_21\">\r\n     <g id=\"line2d_35\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.098099\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_22\">\r\n     <g id=\"line2d_36\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"400.915309\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_23\">\r\n     <g id=\"line2d_37\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"468.732519\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_24\">\r\n     <g id=\"line2d_38\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"536.549728\" xlink:href=\"#m769b7ac07c\" y=\"294.206897\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_6\">\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_39\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"275.517039\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(23.103125 279.316258)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_40\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"250.762261\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(23.103125 254.56148)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_41\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"226.007483\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(23.103125 229.806702)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_42\">\r\n    <path clip-path=\"url(#p180472a44b)\" d=\"M 61.829261 263.13965 \r\nL 64.54195 263.13965 \r\nL 69.967327 287.894428 \r\nL 72.680015 287.894428 \r\nL 75.392703 238.384872 \r\nL 78.105392 287.894428 \r\nL 80.81808 269.328345 \r\nL 83.530768 244.573567 \r\nL 86.243457 256.950956 \r\nL 88.956145 256.950956 \r\nL 91.668834 269.328345 \r\nL 94.381522 244.573567 \r\nL 97.09421 269.328345 \r\nL 99.806899 256.950956 \r\nL 102.519587 269.328345 \r\nL 105.232275 269.328345 \r\nL 107.944964 290.369906 \r\nL 110.657652 269.328345 \r\nL 113.370341 269.328345 \r\nL 116.083029 256.950956 \r\nL 118.795717 290.369906 \r\nL 121.508406 244.573567 \r\nL 124.221094 290.369906 \r\nL 126.933783 244.573567 \r\nL 129.646471 244.573567 \r\nL 132.359159 281.705734 \r\nL 135.071848 269.328345 \r\nL 137.784536 213.630094 \r\nL 140.497224 281.705734 \r\nL 143.209913 244.573567 \r\nL 145.922601 256.950956 \r\nL 148.63529 281.705734 \r\nL 151.347978 290.369906 \r\nL 154.060666 256.950956 \r\nL 156.773355 281.705734 \r\nL 159.486043 256.950956 \r\nL 162.198731 244.573567 \r\nL 164.91142 269.328345 \r\nL 167.624108 244.573567 \r\nL 170.336797 281.705734 \r\nL 173.049485 244.573567 \r\nL 175.762173 269.328345 \r\nL 178.474862 281.705734 \r\nL 181.18755 269.328345 \r\nL 183.900239 281.705734 \r\nL 186.612927 269.328345 \r\nL 189.325615 244.573567 \r\nL 192.038304 269.328345 \r\nL 194.750992 244.573567 \r\nL 197.46368 256.950956 \r\nL 200.176369 256.950956 \r\nL 202.889057 269.328345 \r\nL 208.314434 244.573567 \r\nL 211.027122 213.630094 \r\nL 213.739811 290.369906 \r\nL 216.452499 290.369906 \r\nL 219.165187 244.573567 \r\nL 221.877876 290.369906 \r\nL 224.590564 269.328345 \r\nL 227.303253 238.384872 \r\nL 230.015941 256.950956 \r\nL 232.728629 281.705734 \r\nL 235.441318 256.950956 \r\nL 238.154006 281.705734 \r\nL 240.866695 219.818789 \r\nL 243.579383 244.573567 \r\nL 246.292071 256.950956 \r\nL 249.00476 281.705734 \r\nL 251.717448 269.328345 \r\nL 254.430136 290.369906 \r\nL 257.142825 269.328345 \r\nL 259.855513 256.950956 \r\nL 262.568202 281.705734 \r\nL 265.28089 244.573567 \r\nL 267.993578 269.328345 \r\nL 270.706267 290.369906 \r\nL 273.418955 256.950956 \r\nL 276.131643 281.705734 \r\nL 278.844332 256.950956 \r\nL 281.55702 281.705734 \r\nL 286.982397 256.950956 \r\nL 289.695085 269.328345 \r\nL 292.407774 269.328345 \r\nL 297.833151 244.573567 \r\nL 300.545839 256.950956 \r\nL 303.258527 256.950956 \r\nL 305.971216 269.328345 \r\nL 308.683904 269.328345 \r\nL 311.396592 244.573567 \r\nL 314.109281 256.950956 \r\nL 319.534658 256.950956 \r\nL 322.247346 269.328345 \r\nL 324.960034 256.950956 \r\nL 327.672723 256.950956 \r\nL 330.385411 244.573567 \r\nL 333.098099 256.950956 \r\nL 335.810788 281.705734 \r\nL 338.523476 269.328345 \r\nL 341.236165 281.705734 \r\nL 343.948853 238.384872 \r\nL 346.661541 244.573567 \r\nL 349.37423 269.328345 \r\nL 352.086918 244.573567 \r\nL 354.799607 256.950956 \r\nL 357.512295 213.630094 \r\nL 360.224983 269.328345 \r\nL 362.937672 244.573567 \r\nL 365.65036 244.573567 \r\nL 368.363048 281.705734 \r\nL 373.788425 256.950956 \r\nL 376.501114 256.950956 \r\nL 379.213802 269.328345 \r\nL 381.92649 269.328345 \r\nL 384.639179 256.950956 \r\nL 387.351867 238.384872 \r\nL 390.064555 226.007483 \r\nL 392.777244 269.328345 \r\nL 395.489932 244.573567 \r\nL 398.202621 269.328345 \r\nL 400.915309 256.950956 \r\nL 403.627997 290.369906 \r\nL 406.340686 244.573567 \r\nL 411.766063 269.328345 \r\nL 414.478751 244.573567 \r\nL 417.191439 281.705734 \r\nL 419.904128 244.573567 \r\nL 422.616816 269.328345 \r\nL 425.329504 256.950956 \r\nL 428.042193 269.328345 \r\nL 430.754881 244.573567 \r\nL 433.46757 269.328345 \r\nL 436.180258 281.705734 \r\nL 438.892946 281.705734 \r\nL 441.605635 269.328345 \r\nL 444.318323 281.705734 \r\nL 447.031011 269.328345 \r\nL 449.7437 269.328345 \r\nL 452.456388 281.705734 \r\nL 455.169077 256.950956 \r\nL 457.881765 281.705734 \r\nL 460.594453 256.950956 \r\nL 463.307142 269.328345 \r\nL 466.01983 256.950956 \r\nL 468.732519 256.950956 \r\nL 471.445207 244.573567 \r\nL 474.157895 290.369906 \r\nL 476.870584 269.328345 \r\nL 479.583272 281.705734 \r\nL 482.29596 256.950956 \r\nL 485.008649 256.950956 \r\nL 487.721337 287.894428 \r\nL 490.434026 269.328345 \r\nL 493.146714 258.188695 \r\nL 495.859402 269.328345 \r\nL 498.572091 256.950956 \r\nL 501.284779 290.369906 \r\nL 503.997467 269.328345 \r\nL 509.422844 244.573567 \r\nL 512.135533 244.573567 \r\nL 514.848221 290.369906 \r\nL 517.560909 269.328345 \r\nL 520.273598 244.573567 \r\nL 522.986286 269.328345 \r\nL 528.411663 269.328345 \r\nL 531.124351 256.950956 \r\nL 533.83704 281.705734 \r\nL 536.549728 281.705734 \r\nL 539.262416 269.328345 \r\nL 544.687793 269.328345 \r\nL 547.400482 290.369906 \r\nL 550.11317 244.573567 \r\nL 552.825858 244.573567 \r\nL 555.538547 256.950956 \r\nL 558.251235 256.950956 \r\nL 560.963923 244.573567 \r\nL 563.676612 290.369906 \r\nL 566.3893 256.950956 \r\nL 569.101989 244.573567 \r\nL 569.101989 244.573567 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path d=\"M 36.465625 294.206897 \r\nL 36.465625 209.793103 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path d=\"M 594.465625 294.206897 \r\nL 594.465625 209.793103 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_17\">\r\n    <path d=\"M 36.465625 294.206897 \r\nL 594.465625 294.206897 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_18\">\r\n    <path d=\"M 36.465625 209.793103 \r\nL 594.465625 209.793103 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_3\">\r\n    <g id=\"patch_19\">\r\n     <path d=\"M 498.946875 232.471228 \r\nL 587.465625 232.471228 \r\nQ 589.465625 232.471228 589.465625 230.471228 \r\nL 589.465625 216.793103 \r\nQ 589.465625 214.793103 587.465625 214.793103 \r\nL 498.946875 214.793103 \r\nQ 496.946875 214.793103 496.946875 216.793103 \r\nL 496.946875 230.471228 \r\nQ 496.946875 232.471228 498.946875 232.471228 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_43\">\r\n     <path d=\"M 500.946875 222.891541 \r\nL 520.946875 222.891541 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_44\"/>\r\n    <g id=\"text_14\">\r\n     <!-- Study Time -->\r\n     <defs>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n     </defs>\r\n     <g transform=\"translate(528.946875 226.391541)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"102.685547\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"166.064453\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"229.541016\" xlink:href=\"#DejaVuSans-121\"/>\r\n      <use x=\"288.720703\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"320.507812\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"378.466797\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"406.25\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"503.662109\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g id=\"patch_20\">\r\n    <path d=\"M 36.465625 395.503448 \r\nL 594.465625 395.503448 \r\nL 594.465625 311.089655 \r\nL 36.465625 311.089655 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_7\">\r\n    <g id=\"xtick_25\">\r\n     <g id=\"line2d_45\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.829261\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_26\">\r\n     <g id=\"line2d_46\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.646471\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_27\">\r\n     <g id=\"line2d_47\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.46368\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_28\">\r\n     <g id=\"line2d_48\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.28089\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_29\">\r\n     <g id=\"line2d_49\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.098099\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_30\">\r\n     <g id=\"line2d_50\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"400.915309\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_31\">\r\n     <g id=\"line2d_51\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"468.732519\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_32\">\r\n     <g id=\"line2d_52\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"536.549728\" xlink:href=\"#m769b7ac07c\" y=\"395.503448\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_8\">\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_53\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"378.876489\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 2.5 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(13.5625 382.675708)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_54\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"357.559875\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(13.5625 361.359093)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_14\">\r\n     <g id=\"line2d_55\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"336.24326\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 7.5 -->\r\n      <g transform=\"translate(13.5625 340.042479)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_15\">\r\n     <g id=\"line2d_56\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"314.926646\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 10.0 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 318.725865)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_57\">\r\n    <path clip-path=\"url(#pb8c836b6f4)\" d=\"M 61.829261 366.08652 \r\nL 64.54195 340.506583 \r\nL 67.254638 391.666458 \r\nL 69.967327 323.453292 \r\nL 72.680015 340.506583 \r\nL 75.392703 349.033229 \r\nL 78.105392 340.506583 \r\nL 80.81808 383.139812 \r\nL 83.530768 340.506583 \r\nL 88.956145 340.506583 \r\nL 91.668834 314.926646 \r\nL 94.381522 366.08652 \r\nL 97.09421 340.506583 \r\nL 99.806899 323.453292 \r\nL 102.519587 374.613166 \r\nL 105.232275 366.08652 \r\nL 107.944964 331.979937 \r\nL 110.657652 314.926646 \r\nL 113.370341 323.453292 \r\nL 116.083029 357.559875 \r\nL 118.795717 374.613166 \r\nL 121.508406 340.506583 \r\nL 124.221094 349.033229 \r\nL 126.933783 331.979937 \r\nL 129.646471 349.033229 \r\nL 132.359159 357.559875 \r\nL 135.071848 383.139812 \r\nL 137.784536 366.08652 \r\nL 143.209913 349.033229 \r\nL 145.922601 391.666458 \r\nL 148.63529 349.033229 \r\nL 151.347978 374.613166 \r\nL 154.060666 366.08652 \r\nL 156.773355 383.139812 \r\nL 159.486043 374.613166 \r\nL 162.198731 349.033229 \r\nL 164.91142 357.559875 \r\nL 167.624108 383.139812 \r\nL 170.336797 349.033229 \r\nL 175.762173 383.139812 \r\nL 178.474862 383.139812 \r\nL 181.18755 357.559875 \r\nL 183.900239 340.506583 \r\nL 186.612927 357.559875 \r\nL 192.038304 340.506583 \r\nL 194.750992 366.08652 \r\nL 197.46368 366.08652 \r\nL 200.176369 331.979937 \r\nL 202.889057 323.453292 \r\nL 205.601746 357.559875 \r\nL 208.314434 331.979937 \r\nL 211.027122 349.033229 \r\nL 213.739811 340.506583 \r\nL 216.452499 323.453292 \r\nL 219.165187 340.506583 \r\nL 221.877876 340.506583 \r\nL 224.590564 323.453292 \r\nL 227.303253 391.666458 \r\nL 230.015941 323.453292 \r\nL 232.728629 323.453292 \r\nL 235.441318 340.506583 \r\nL 238.154006 340.506583 \r\nL 240.866695 323.453292 \r\nL 243.579383 323.453292 \r\nL 246.292071 340.506583 \r\nL 251.717448 357.559875 \r\nL 254.430136 357.559875 \r\nL 257.142825 374.613166 \r\nL 259.855513 357.559875 \r\nL 262.568202 357.559875 \r\nL 265.28089 331.979937 \r\nL 267.993578 314.926646 \r\nL 270.706267 366.08652 \r\nL 273.418955 391.666458 \r\nL 276.131643 357.559875 \r\nL 278.844332 331.979937 \r\nL 281.55702 314.926646 \r\nL 284.269709 331.979937 \r\nL 286.982397 314.926646 \r\nL 289.695085 323.453292 \r\nL 292.407774 357.559875 \r\nL 295.120462 349.033229 \r\nL 297.833151 331.979937 \r\nL 300.545839 323.453292 \r\nL 303.258527 366.08652 \r\nL 305.971216 331.979937 \r\nL 308.683904 323.453292 \r\nL 311.396592 349.033229 \r\nL 314.109281 331.979937 \r\nL 316.821969 357.559875 \r\nL 319.534658 366.08652 \r\nL 322.247346 366.08652 \r\nL 324.960034 357.559875 \r\nL 327.672723 314.926646 \r\nL 330.385411 340.506583 \r\nL 333.098099 331.979937 \r\nL 338.523476 349.033229 \r\nL 341.236165 349.033229 \r\nL 343.948853 374.613166 \r\nL 346.661541 349.033229 \r\nL 349.37423 374.613166 \r\nL 352.086918 323.453292 \r\nL 354.799607 340.506583 \r\nL 360.224983 340.506583 \r\nL 362.937672 331.979937 \r\nL 365.65036 349.033229 \r\nL 368.363048 331.979937 \r\nL 371.075737 340.506583 \r\nL 373.788425 340.506583 \r\nL 376.501114 331.979937 \r\nL 379.213802 340.506583 \r\nL 381.92649 331.979937 \r\nL 384.639179 357.559875 \r\nL 387.351867 331.979937 \r\nL 390.064555 323.453292 \r\nL 392.777244 357.559875 \r\nL 395.489932 349.033229 \r\nL 398.202621 349.033229 \r\nL 400.915309 340.506583 \r\nL 403.627997 340.506583 \r\nL 406.340686 357.559875 \r\nL 409.053374 340.506583 \r\nL 411.766063 340.506583 \r\nL 414.478751 314.926646 \r\nL 417.191439 374.613166 \r\nL 419.904128 323.453292 \r\nL 422.616816 331.979937 \r\nL 425.329504 323.453292 \r\nL 428.042193 357.559875 \r\nL 430.754881 323.453292 \r\nL 433.46757 349.033229 \r\nL 436.180258 340.506583 \r\nL 438.892946 349.033229 \r\nL 441.605635 366.08652 \r\nL 444.318323 357.559875 \r\nL 447.031011 357.559875 \r\nL 449.7437 340.506583 \r\nL 452.456388 391.666458 \r\nL 455.169077 357.559875 \r\nL 460.594453 357.559875 \r\nL 463.307142 323.453292 \r\nL 466.01983 340.506583 \r\nL 468.732519 383.139812 \r\nL 471.445207 349.033229 \r\nL 474.157895 383.139812 \r\nL 476.870584 323.453292 \r\nL 479.583272 349.033229 \r\nL 482.29596 331.979937 \r\nL 485.008649 357.559875 \r\nL 487.721337 331.979937 \r\nL 490.434026 331.979937 \r\nL 493.146714 366.08652 \r\nL 495.859402 357.559875 \r\nL 498.572091 323.453292 \r\nL 501.284779 349.033229 \r\nL 503.997467 349.033229 \r\nL 506.710156 340.506583 \r\nL 509.422844 357.559875 \r\nL 514.848221 323.453292 \r\nL 520.273598 340.506583 \r\nL 522.986286 323.453292 \r\nL 525.698975 331.979937 \r\nL 528.411663 331.979937 \r\nL 531.124351 349.033229 \r\nL 533.83704 383.139812 \r\nL 536.549728 349.033229 \r\nL 541.975105 314.926646 \r\nL 544.687793 340.506583 \r\nL 547.400482 374.613166 \r\nL 550.11317 374.613166 \r\nL 552.825858 331.979937 \r\nL 555.538547 331.979937 \r\nL 558.251235 366.08652 \r\nL 560.963923 314.926646 \r\nL 563.676612 349.033229 \r\nL 566.3893 366.08652 \r\nL 569.101989 340.506583 \r\nL 569.101989 340.506583 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path d=\"M 36.465625 395.503448 \r\nL 36.465625 311.089655 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_22\">\r\n    <path d=\"M 594.465625 395.503448 \r\nL 594.465625 311.089655 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_23\">\r\n    <path d=\"M 36.465625 395.503448 \r\nL 594.465625 395.503448 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path d=\"M 36.465625 311.089655 \r\nL 594.465625 311.089655 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_4\">\r\n    <g id=\"patch_25\">\r\n     <path d=\"M 245.466406 390.503448 \r\nL 385.464844 390.503448 \r\nQ 387.464844 390.503448 387.464844 388.503448 \r\nL 387.464844 374.825323 \r\nQ 387.464844 372.825323 385.464844 372.825323 \r\nL 245.466406 372.825323 \r\nQ 243.466406 372.825323 243.466406 374.825323 \r\nL 243.466406 388.503448 \r\nQ 243.466406 390.503448 245.466406 390.503448 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_58\">\r\n     <path d=\"M 247.466406 380.923761 \r\nL 267.466406 380.923761 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_59\"/>\r\n    <g id=\"text_19\">\r\n     <!-- Lecturer Performance -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n      <path d=\"M 37.109375 75.984375 \r\nL 37.109375 68.5 \r\nL 28.515625 68.5 \r\nQ 23.6875 68.5 21.796875 66.546875 \r\nQ 19.921875 64.59375 19.921875 59.515625 \r\nL 19.921875 54.6875 \r\nL 34.71875 54.6875 \r\nL 34.71875 47.703125 \r\nL 19.921875 47.703125 \r\nL 19.921875 0 \r\nL 10.890625 0 \r\nL 10.890625 47.703125 \r\nL 2.296875 47.703125 \r\nL 2.296875 54.6875 \r\nL 10.890625 54.6875 \r\nL 10.890625 58.5 \r\nQ 10.890625 67.625 15.140625 71.796875 \r\nQ 19.390625 75.984375 28.609375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-102\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n     </defs>\r\n     <g transform=\"translate(275.466406 384.423761)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"115.486328\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"170.466797\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"209.675781\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"273.054688\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"311.917969\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"373.441406\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"414.554688\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"446.341797\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"503.019531\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"564.542969\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"605.65625\" xlink:href=\"#DejaVuSans-102\"/>\r\n      <use x=\"640.861328\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"702.042969\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"741.40625\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"838.818359\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"900.097656\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"963.476562\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"1018.457031\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_5\">\r\n   <g id=\"patch_26\">\r\n    <path d=\"M 36.465625 496.8 \r\nL 594.465625 496.8 \r\nL 594.465625 412.386207 \r\nL 36.465625 412.386207 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_9\">\r\n    <g id=\"xtick_33\">\r\n     <g id=\"line2d_60\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.829261\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(55.279331 513.56169)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_34\">\r\n     <g id=\"line2d_61\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.646471\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(117.586454 516.74294)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_35\">\r\n     <g id=\"line2d_62\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.46368\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(185.403663 516.74294)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_36\">\r\n     <g id=\"line2d_63\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.28089\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 75 -->\r\n      <g transform=\"translate(253.220873 516.74294)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_37\">\r\n     <g id=\"line2d_64\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.098099\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_24\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(315.527996 519.92419)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_38\">\r\n     <g id=\"line2d_65\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"400.915309\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_25\">\r\n      <!-- 125 -->\r\n      <g transform=\"translate(383.345205 519.92419)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_39\">\r\n     <g id=\"line2d_66\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"468.732519\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_26\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(451.162415 519.92419)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_40\">\r\n     <g id=\"line2d_67\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"536.549728\" xlink:href=\"#m769b7ac07c\" y=\"496.8\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_27\">\r\n      <!-- 175 -->\r\n      <g transform=\"translate(518.979624 519.92419)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_10\">\r\n    <g id=\"ytick_16\">\r\n     <g id=\"line2d_68\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"480.173041\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_28\">\r\n      <!-- 2.5 -->\r\n      <g transform=\"translate(13.5625 483.97226)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_17\">\r\n     <g id=\"line2d_69\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"458.856426\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_29\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(13.5625 462.655645)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_18\">\r\n     <g id=\"line2d_70\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"437.539812\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_30\">\r\n      <!-- 7.5 -->\r\n      <g transform=\"translate(13.5625 441.339031)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_19\">\r\n     <g id=\"line2d_71\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#ma13a9a9a03\" y=\"416.223197\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_31\">\r\n      <!-- 10.0 -->\r\n      <g transform=\"translate(7.2 420.022416)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_72\">\r\n    <path clip-path=\"url(#p13bcc6fadf)\" d=\"M 61.829261 424.749843 \r\nL 64.54195 433.276489 \r\nL 67.254638 424.749843 \r\nL 69.967327 492.963009 \r\nL 72.680015 458.856426 \r\nL 75.392703 441.803135 \r\nL 78.105392 416.223197 \r\nL 80.81808 424.749843 \r\nL 88.956145 475.909718 \r\nL 91.668834 467.383072 \r\nL 94.381522 467.383072 \r\nL 97.09421 441.803135 \r\nL 99.806899 450.329781 \r\nL 102.519587 450.329781 \r\nL 105.232275 433.276489 \r\nL 107.944964 467.383072 \r\nL 110.657652 458.856426 \r\nL 113.370341 441.803135 \r\nL 116.083029 467.383072 \r\nL 121.508406 467.383072 \r\nL 124.221094 458.856426 \r\nL 126.933783 441.803135 \r\nL 129.646471 458.856426 \r\nL 132.359159 433.276489 \r\nL 135.071848 433.276489 \r\nL 137.784536 424.749843 \r\nL 140.497224 450.329781 \r\nL 143.209913 441.803135 \r\nL 145.922601 458.856426 \r\nL 148.63529 492.963009 \r\nL 151.347978 467.383072 \r\nL 154.060666 467.383072 \r\nL 156.773355 416.223197 \r\nL 159.486043 475.909718 \r\nL 162.198731 433.276489 \r\nL 164.91142 450.329781 \r\nL 167.624108 416.223197 \r\nL 170.336797 458.856426 \r\nL 173.049485 450.329781 \r\nL 175.762173 458.856426 \r\nL 178.474862 475.909718 \r\nL 181.18755 467.383072 \r\nL 189.325615 416.223197 \r\nL 194.750992 467.383072 \r\nL 197.46368 484.436364 \r\nL 200.176369 424.749843 \r\nL 202.889057 484.436364 \r\nL 205.601746 433.276489 \r\nL 208.314434 424.749843 \r\nL 211.027122 458.856426 \r\nL 213.739811 416.223197 \r\nL 216.452499 416.223197 \r\nL 219.165187 441.803135 \r\nL 221.877876 416.223197 \r\nL 224.590564 433.276489 \r\nL 227.303253 492.963009 \r\nL 230.015941 450.329781 \r\nL 232.728629 450.329781 \r\nL 235.441318 458.856426 \r\nL 238.154006 458.856426 \r\nL 240.866695 433.276489 \r\nL 243.579383 475.909718 \r\nL 246.292071 441.803135 \r\nL 249.00476 441.803135 \r\nL 251.717448 424.749843 \r\nL 254.430136 416.223197 \r\nL 257.142825 475.909718 \r\nL 259.855513 458.856426 \r\nL 262.568202 433.276489 \r\nL 265.28089 475.909718 \r\nL 267.993578 441.803135 \r\nL 270.706267 441.803135 \r\nL 273.418955 450.329781 \r\nL 276.131643 441.803135 \r\nL 278.844332 450.329781 \r\nL 281.55702 433.276489 \r\nL 284.269709 450.329781 \r\nL 286.982397 492.963009 \r\nL 289.695085 484.436364 \r\nL 292.407774 450.329781 \r\nL 295.120462 433.276489 \r\nL 297.833151 433.276489 \r\nL 300.545839 484.436364 \r\nL 303.258527 416.223197 \r\nL 305.971216 450.329781 \r\nL 308.683904 441.803135 \r\nL 311.396592 458.856426 \r\nL 314.109281 433.276489 \r\nL 316.821969 467.383072 \r\nL 319.534658 433.276489 \r\nL 324.960034 450.329781 \r\nL 327.672723 433.276489 \r\nL 333.098099 433.276489 \r\nL 335.810788 450.329781 \r\nL 338.523476 441.803135 \r\nL 341.236165 424.749843 \r\nL 343.948853 424.749843 \r\nL 346.661541 441.803135 \r\nL 349.37423 424.749843 \r\nL 354.799607 441.803135 \r\nL 357.512295 433.276489 \r\nL 360.224983 416.223197 \r\nL 362.937672 458.856426 \r\nL 365.65036 450.329781 \r\nL 368.363048 450.329781 \r\nL 373.788425 433.276489 \r\nL 376.501114 467.383072 \r\nL 379.213802 424.749843 \r\nL 387.351867 450.329781 \r\nL 390.064555 433.276489 \r\nL 392.777244 458.856426 \r\nL 395.489932 458.856426 \r\nL 398.202621 441.803135 \r\nL 400.915309 450.329781 \r\nL 403.627997 433.276489 \r\nL 406.340686 450.329781 \r\nL 409.053374 441.803135 \r\nL 411.766063 441.803135 \r\nL 414.478751 458.856426 \r\nL 419.904128 458.856426 \r\nL 422.616816 450.329781 \r\nL 425.329504 433.276489 \r\nL 428.042193 475.909718 \r\nL 430.754881 441.803135 \r\nL 436.180258 424.749843 \r\nL 438.892946 450.329781 \r\nL 441.605635 433.276489 \r\nL 444.318323 441.803135 \r\nL 447.031011 458.856426 \r\nL 449.7437 458.856426 \r\nL 452.456388 424.749843 \r\nL 455.169077 475.909718 \r\nL 457.881765 458.856426 \r\nL 460.594453 475.909718 \r\nL 463.307142 484.436364 \r\nL 466.01983 458.856426 \r\nL 474.157895 458.856426 \r\nL 476.870584 441.803135 \r\nL 482.29596 475.909718 \r\nL 485.008649 458.856426 \r\nL 487.721337 433.276489 \r\nL 490.434026 484.436364 \r\nL 493.146714 416.223197 \r\nL 495.859402 458.856426 \r\nL 498.572091 450.329781 \r\nL 501.284779 492.963009 \r\nL 503.997467 441.803135 \r\nL 506.710156 458.856426 \r\nL 509.422844 484.436364 \r\nL 512.135533 424.749843 \r\nL 514.848221 458.856426 \r\nL 517.560909 475.909718 \r\nL 520.273598 424.749843 \r\nL 522.986286 441.803135 \r\nL 525.698975 441.803135 \r\nL 528.411663 475.909718 \r\nL 531.124351 450.329781 \r\nL 533.83704 416.223197 \r\nL 536.549728 475.909718 \r\nL 539.262416 450.329781 \r\nL 541.975105 458.856426 \r\nL 544.687793 433.276489 \r\nL 550.11317 433.276489 \r\nL 552.825858 416.223197 \r\nL 555.538547 433.276489 \r\nL 558.251235 416.223197 \r\nL 560.963923 458.856426 \r\nL 563.676612 458.856426 \r\nL 566.3893 416.223197 \r\nL 569.101989 433.276489 \r\nL 569.101989 433.276489 \r\n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_27\">\r\n    <path d=\"M 36.465625 496.8 \r\nL 36.465625 412.386207 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_28\">\r\n    <path d=\"M 594.465625 496.8 \r\nL 594.465625 412.386207 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_29\">\r\n    <path d=\"M 36.465625 496.8 \r\nL 594.465625 496.8 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_30\">\r\n    <path d=\"M 36.465625 412.386207 \r\nL 594.465625 412.386207 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_5\">\r\n    <g id=\"patch_31\">\r\n     <path d=\"M 43.465625 491.8 \r\nL 120.215625 491.8 \r\nQ 122.215625 491.8 122.215625 489.8 \r\nL 122.215625 476.121875 \r\nQ 122.215625 474.121875 120.215625 474.121875 \r\nL 43.465625 474.121875 \r\nQ 41.465625 474.121875 41.465625 476.121875 \r\nL 41.465625 489.8 \r\nQ 41.465625 491.8 43.465625 491.8 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_73\">\r\n     <path d=\"M 45.465625 482.220313 \r\nL 65.465625 482.220313 \r\n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_74\"/>\r\n    <g id=\"text_32\">\r\n     <!-- Difficulty -->\r\n     <defs>\r\n      <path d=\"M 19.671875 64.796875 \r\nL 19.671875 8.109375 \r\nL 31.59375 8.109375 \r\nQ 46.6875 8.109375 53.6875 14.9375 \r\nQ 60.6875 21.78125 60.6875 36.53125 \r\nQ 60.6875 51.171875 53.6875 57.984375 \r\nQ 46.6875 64.796875 31.59375 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 30.078125 72.90625 \r\nQ 51.265625 72.90625 61.171875 64.09375 \r\nQ 71.09375 55.28125 71.09375 36.53125 \r\nQ 71.09375 17.671875 61.125 8.828125 \r\nQ 51.171875 0 30.078125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-68\"/>\r\n     </defs>\r\n     <g transform=\"translate(73.465625 485.720313)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-68\"/>\r\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"104.785156\" xlink:href=\"#DejaVuSans-102\"/>\r\n      <use x=\"139.990234\" xlink:href=\"#DejaVuSans-102\"/>\r\n      <use x=\"175.195312\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"202.978516\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"257.958984\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"321.337891\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"349.121094\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"388.330078\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p1cc6de5207\">\r\n   <rect height=\"84.413793\" width=\"558\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p7719059e1c\">\r\n   <rect height=\"84.413793\" width=\"558\" x=\"36.465625\" y=\"108.496552\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p180472a44b\">\r\n   <rect height=\"84.413793\" width=\"558\" x=\"36.465625\" y=\"209.793103\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pb8c836b6f4\">\r\n   <rect height=\"84.413793\" width=\"558\" x=\"36.465625\" y=\"311.089655\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p13bcc6fadf\">\r\n   <rect height=\"84.413793\" width=\"558\" x=\"36.465625\" y=\"412.386207\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "myData.plot(subplots=True, figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove any signal which is deemed unimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Actual CWA  Score  Study Time  Lecturer Performance  Difficulty\n",
       "0        74.0   66.0         3.0                     4           9\n",
       "1        70.0   55.0         3.0                     7           8\n",
       "2        68.3   55.0         2.0                     1           9\n",
       "3        76.0   85.0         1.0                     9           1\n",
       "4        65.0   57.0         1.0                     7           5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual CWA</th>\n      <th>Score</th>\n      <th>Study Time</th>\n      <th>Lecturer Performance</th>\n      <th>Difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74.0</td>\n      <td>66.0</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>70.0</td>\n      <td>55.0</td>\n      <td>3.0</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68.3</td>\n      <td>55.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76.0</td>\n      <td>85.0</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.0</td>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "myData.drop(( 'Program'), axis=1, inplace=True)\n",
    "myData.astype('Float32')\n",
    "myData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(188, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "myData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Data for Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try and predict these signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the number of time-steps that we will shift the target-data. Our data-set is resampled to have an observation for each hour, so there are 24 observations for 24 hours.\n",
    "\n",
    "If we want to predict the weather 24 hours into the future, we shift the data 6 time-steps. If we want to predict the weather 7 days into the future, we shift the data 7 * 6 time-steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new data-frame with the time-shifted data.\n",
    "\n",
    "**Note the negative time-shift!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Score\n",
       "0   66.0\n",
       "1   55.0\n",
       "2   55.0\n",
       "3   85.0\n",
       "4   57.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>66.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_targets = myData[target_names]\n",
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Arrays\n",
    "\n",
    "We now convert the Pandas data-frames to NumPy arrays that can be input to the neural network. We also remove the last part of the numpy arrays, because the target-data has `NaN` for the shifted period, and we only want to have valid data and we need the same array-shapes for the input- and output-data.\n",
    "\n",
    "These are the input-signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Actual CWA  Score  Study Time  Lecturer Performance  Difficulty\n",
       "0         74.00   66.0         3.0                     4           9\n",
       "1         70.00   55.0         3.0                     7           8\n",
       "2         68.30   55.0         2.0                     1           9\n",
       "3         76.00   85.0         1.0                     9           1\n",
       "4         65.00   57.0         1.0                     7           5\n",
       "..          ...    ...         ...                   ...         ...\n",
       "183       65.00   40.0         3.5                     4          10\n",
       "184       63.67   68.0         4.5                    10           5\n",
       "185       56.70   54.0         0.8                     6           5\n",
       "186       65.00   40.0         3.5                     4          10\n",
       "187       71.24   68.0         4.5                     7           8\n",
       "\n",
       "[188 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual CWA</th>\n      <th>Score</th>\n      <th>Study Time</th>\n      <th>Lecturer Performance</th>\n      <th>Difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74.00</td>\n      <td>66.0</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>70.00</td>\n      <td>55.0</td>\n      <td>3.0</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68.30</td>\n      <td>55.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76.00</td>\n      <td>85.0</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.00</td>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>65.00</td>\n      <td>40.0</td>\n      <td>3.5</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>63.67</td>\n      <td>68.0</td>\n      <td>4.5</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>56.70</td>\n      <td>54.0</td>\n      <td>0.8</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>65.00</td>\n      <td>40.0</td>\n      <td>3.5</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>71.24</td>\n      <td>68.0</td>\n      <td>4.5</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>188 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "myData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Actual CWA  Study Time  Lecturer Performance  Difficulty\n",
       "0         74.00         3.0                     4           9\n",
       "1         70.00         3.0                     7           8\n",
       "2         68.30         2.0                     1           9\n",
       "3         76.00         1.0                     9           1\n",
       "4         65.00         1.0                     7           5\n",
       "..          ...         ...                   ...         ...\n",
       "183       65.00         3.5                     4          10\n",
       "184       63.67         4.5                    10           5\n",
       "185       56.70         0.8                     6           5\n",
       "186       65.00         3.5                     4          10\n",
       "187       71.24         4.5                     7           8\n",
       "\n",
       "[188 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual CWA</th>\n      <th>Study Time</th>\n      <th>Lecturer Performance</th>\n      <th>Difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74.00</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>70.00</td>\n      <td>3.0</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68.30</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76.00</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.00</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>65.00</td>\n      <td>3.5</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>63.67</td>\n      <td>4.5</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>56.70</td>\n      <td>0.8</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>65.00</td>\n      <td>3.5</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>71.24</td>\n      <td>4.5</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>188 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "myData_1=myData.copy()\n",
    "myData_1.drop(( 'Score'), axis=1, inplace=True)\n",
    "myData_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0    1     2     3\n",
       "183  65.00  3.5   4.0  10.0\n",
       "184  63.67  4.5  10.0   5.0\n",
       "185  56.70  0.8   6.0   5.0\n",
       "186  65.00  3.5   4.0  10.0\n",
       "187  71.24  4.5   7.0   8.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>183</th>\n      <td>65.00</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>63.67</td>\n      <td>4.5</td>\n      <td>10.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>56.70</td>\n      <td>0.8</td>\n      <td>6.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>65.00</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>71.24</td>\n      <td>4.5</td>\n      <td>7.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "x_data = myData_1.values\n",
    "pd.DataFrame(x_data).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\nShape: (188, 4)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_data))\n",
    "print(\"Shape:\", x_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the output-signals (or target-signals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        0\n",
       "183  40.0\n",
       "184  68.0\n",
       "185  54.0\n",
       "186  40.0\n",
       "187  68.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>183</th>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>68.0</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>54.0</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>68.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "y_data = df_targets.values\n",
    "pd.DataFrame(y_data).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\nShape: (188, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(y_data))\n",
    "print(\"Shape:\", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "num_data = len(x_data)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fraction of the data-set that will be used for the training-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4,) (1,)\n"
     ]
    }
   ],
   "source": [
    "# the dataset knows the number of features, e.g. 2\n",
    "for i in range(1): print(x_data[i].shape,y_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of observations in the training-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "num_train = int(train_split * num_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of observations in the test-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "num_test = num_data - num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the input-signals for the training- and test-sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "x_train = x_data[0:num_train]\n",
    "x_test = x_data[num_train:]\n",
    "len(x_train) + len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the output-signals for the training- and test-sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "y_train = y_data[0:num_train]\n",
    "y_test = y_data[num_train:]\n",
    "len(y_train) + len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of input-signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "num_x_signals = x_data.shape[1]\n",
    "num_x_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of output-signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "num_y_signals = y_data.shape[1]\n",
    "num_y_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Data\n",
    "\n",
    "The data-set contains a wide range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Min: 0.8\nMax: 84.07\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(x_train))\n",
    "print(\"Max:\", np.max(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network works best on values roughly between -1 and 1, so we need to scale the data before it is being input to the neural network. We can use `scikit-learn` for this.\n",
    "\n",
    "We first create a scaler-object for the input-signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(169, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then detect the range of values from the training-data and scale the training-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from a small rounding-error, the data has been scaled to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Min: 0.0\nMax: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(x_train_scaled))\n",
    "print(\"Max:\", np.max(x_train_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same scaler-object for the input-signals in the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x360 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x360 with 4 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"285.714315pt\" version=\"1.1\" viewBox=\"0 0 316.303125 285.714315\" width=\"316.303125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 285.714315 \r\nL 316.303125 285.714315 \r\nL 316.303125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 60.417391 \r\nL 309.103125 60.417391 \r\nL 309.103125 7.2 \r\nL 30.103125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mf05414a22d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.784943\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.012216\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.239489\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.466761\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.694034\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.921307\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.14858\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.375852\" xlink:href=\"#mf05414a22d\" y=\"60.417391\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mb6b65dd75b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"49.278496\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 53.077715)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"25.693152\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 29.492371)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_11\">\r\n    <path clip-path=\"url(#padb04ac629)\" d=\"M 42.784943 22.258648 \r\nL 56.875852 30.002265 \r\nL 70.966761 22.985066 \r\nL 85.05767 22.476573 \r\nL 99.14858 35.334174 \r\nL 113.239489 29.813396 \r\nL 127.330398 42.888922 \r\nL 141.421307 33.736054 \r\nL 155.512216 14.863711 \r\nL 169.603125 9.618972 \r\nL 183.694034 57.998419 \r\nL 197.784943 28.36056 \r\nL 211.875852 23.638842 \r\nL 225.966761 32.719068 \r\nL 240.05767 29.813396 \r\nL 254.14858 31.745668 \r\nL 268.239489 41.871937 \r\nL 282.330398 29.813396 \r\nL 296.421307 20.747698 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 60.417391 \r\nL 30.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 309.103125 60.417391 \r\nL 309.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 60.417391 \r\nL 309.103125 60.417391 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 7.2 \r\nL 309.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 37.103125 55.417391 \r\nL 75.465625 55.417391 \r\nQ 77.465625 55.417391 77.465625 53.417391 \r\nL 77.465625 39.739266 \r\nQ 77.465625 37.739266 75.465625 37.739266 \r\nL 37.103125 37.739266 \r\nQ 35.103125 37.739266 35.103125 39.739266 \r\nL 35.103125 53.417391 \r\nQ 35.103125 55.417391 37.103125 55.417391 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_12\">\r\n     <path d=\"M 39.103125 45.837704 \r\nL 59.103125 45.837704 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_13\"/>\r\n    <g id=\"text_3\">\r\n     <!-- 0 -->\r\n     <g transform=\"translate(67.103125 49.337704)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-48\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 30.103125 124.278261 \r\nL 309.103125 124.278261 \r\nL 309.103125 71.06087 \r\nL 30.103125 71.06087 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.784943\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.012216\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.239489\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.466761\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_13\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.694034\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_14\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.921307\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_15\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.14858\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_16\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.375852\" xlink:href=\"#mf05414a22d\" y=\"124.278261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"121.859289\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 125.658507)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"81.325158\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 0.5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 85.124376)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_24\">\r\n    <path clip-path=\"url(#p0838bac811)\" d=\"M 42.784943 73.479842 \r\nL 56.875852 99.630894 \r\nL 70.966761 99.630894 \r\nL 85.05767 99.630894 \r\nL 99.14858 86.555368 \r\nL 113.239489 112.70642 \r\nL 127.330398 112.70642 \r\nL 141.421307 99.630894 \r\nL 155.512216 99.630894 \r\nL 169.603125 99.630894 \r\nL 183.694034 121.859289 \r\nL 197.784943 73.479842 \r\nL 211.875852 73.479842 \r\nL 225.966761 86.555368 \r\nL 240.05767 86.555368 \r\nL 254.14858 73.479842 \r\nL 268.239489 121.859289 \r\nL 282.330398 86.555368 \r\nL 296.421307 73.479842 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 30.103125 124.278261 \r\nL 30.103125 71.06087 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 309.103125 124.278261 \r\nL 309.103125 71.06087 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 30.103125 124.278261 \r\nL 309.103125 124.278261 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 30.103125 71.06087 \r\nL 309.103125 71.06087 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_2\">\r\n    <g id=\"patch_13\">\r\n     <path d=\"M 37.103125 119.278261 \r\nL 75.465625 119.278261 \r\nQ 77.465625 119.278261 77.465625 117.278261 \r\nL 77.465625 103.600136 \r\nQ 77.465625 101.600136 75.465625 101.600136 \r\nL 37.103125 101.600136 \r\nQ 35.103125 101.600136 35.103125 103.600136 \r\nL 35.103125 117.278261 \r\nQ 35.103125 119.278261 37.103125 119.278261 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_25\">\r\n     <path d=\"M 39.103125 109.698573 \r\nL 59.103125 109.698573 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_26\"/>\r\n    <g id=\"text_6\">\r\n     <!-- 1 -->\r\n     <defs>\r\n      <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n     </defs>\r\n     <g transform=\"translate(67.103125 113.198573)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-49\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g id=\"patch_14\">\r\n    <path d=\"M 30.103125 188.13913 \r\nL 309.103125 188.13913 \r\nL 309.103125 134.921739 \r\nL 30.103125 134.921739 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_5\">\r\n    <g id=\"xtick_17\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.784943\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_18\">\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.012216\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_19\">\r\n     <g id=\"line2d_29\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.239489\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_20\">\r\n     <g id=\"line2d_30\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.466761\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_21\">\r\n     <g id=\"line2d_31\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.694034\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_22\">\r\n     <g id=\"line2d_32\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.921307\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_23\">\r\n     <g id=\"line2d_33\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.14858\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_24\">\r\n     <g id=\"line2d_34\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.375852\" xlink:href=\"#mf05414a22d\" y=\"188.13913\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_6\">\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_35\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"164.55415\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(7.2 168.353369)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_36\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"137.340711\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 141.13993)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_37\">\r\n    <path clip-path=\"url(#pdea5f7a4a2)\" d=\"M 42.784943 155.483004 \r\nL 56.875852 143.388142 \r\nL 70.966761 149.435573 \r\nL 85.05767 149.435573 \r\nL 99.14858 161.530435 \r\nL 113.239489 185.720158 \r\nL 127.330398 161.530435 \r\nL 141.421307 149.435573 \r\nL 155.512216 137.340711 \r\nL 169.603125 155.483004 \r\nL 183.694034 179.672727 \r\nL 197.784943 179.672727 \r\nL 211.875852 149.435573 \r\nL 225.966761 149.435573 \r\nL 240.05767 173.625296 \r\nL 254.14858 137.340711 \r\nL 268.239489 161.530435 \r\nL 282.330398 173.625296 \r\nL 296.421307 155.483004 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path d=\"M 30.103125 188.13913 \r\nL 30.103125 134.921739 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path d=\"M 309.103125 188.13913 \r\nL 309.103125 134.921739 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_17\">\r\n    <path d=\"M 30.103125 188.13913 \r\nL 309.103125 188.13913 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_18\">\r\n    <path d=\"M 30.103125 134.921739 \r\nL 309.103125 134.921739 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_3\">\r\n    <g id=\"patch_19\">\r\n     <path d=\"M 37.103125 183.13913 \r\nL 75.465625 183.13913 \r\nQ 77.465625 183.13913 77.465625 181.13913 \r\nL 77.465625 167.461005 \r\nQ 77.465625 165.461005 75.465625 165.461005 \r\nL 37.103125 165.461005 \r\nQ 35.103125 165.461005 35.103125 167.461005 \r\nL 35.103125 181.13913 \r\nQ 35.103125 183.13913 37.103125 183.13913 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_38\">\r\n     <path d=\"M 39.103125 173.559443 \r\nL 59.103125 173.559443 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_39\"/>\r\n    <g id=\"text_9\">\r\n     <!-- 2 -->\r\n     <defs>\r\n      <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n     </defs>\r\n     <g transform=\"translate(67.103125 177.059443)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-50\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g id=\"patch_20\">\r\n    <path d=\"M 30.103125 252 \r\nL 309.103125 252 \r\nL 309.103125 198.782609 \r\nL 30.103125 198.782609 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_7\">\r\n    <g id=\"xtick_25\">\r\n     <g id=\"line2d_40\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.784943\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(27.972589 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_26\">\r\n     <g id=\"line2d_41\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.012216\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 2.5 -->\r\n      <g transform=\"translate(63.199862 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_27\">\r\n     <g id=\"line2d_42\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.239489\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(98.427135 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_28\">\r\n     <g id=\"line2d_43\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.466761\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 7.5 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(133.654407 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_29\">\r\n     <g id=\"line2d_44\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.694034\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 10.0 -->\r\n      <g transform=\"translate(163.371593 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_30\">\r\n     <g id=\"line2d_45\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.921307\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 12.5 -->\r\n      <g transform=\"translate(198.598866 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_31\">\r\n     <g id=\"line2d_46\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.14858\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 15.0 -->\r\n      <g transform=\"translate(233.826139 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_32\">\r\n     <g id=\"line2d_47\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.375852\" xlink:href=\"#mf05414a22d\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 17.5 -->\r\n      <g transform=\"translate(269.053412 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_8\">\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_48\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"232.302654\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(7.2 236.101873)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_49\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6b65dd75b\" y=\"201.201581\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 205.0008)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_50\">\r\n    <path clip-path=\"url(#p8100362961)\" d=\"M 42.784943 208.112931 \r\nL 56.875852 221.93563 \r\nL 70.966761 221.93563 \r\nL 85.05767 249.581028 \r\nL 99.14858 228.846979 \r\nL 113.239489 201.201581 \r\nL 127.330398 249.581028 \r\nL 141.421307 228.846979 \r\nL 155.512216 235.758329 \r\nL 169.603125 215.02428 \r\nL 183.694034 215.02428 \r\nL 197.784943 215.02428 \r\nL 211.875852 201.201581 \r\nL 225.966761 215.02428 \r\nL 240.05767 201.201581 \r\nL 254.14858 235.758329 \r\nL 268.239489 235.758329 \r\nL 282.330398 201.201581 \r\nL 296.421307 215.02428 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path d=\"M 30.103125 252 \r\nL 30.103125 198.782609 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_22\">\r\n    <path d=\"M 309.103125 252 \r\nL 309.103125 198.782609 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_23\">\r\n    <path d=\"M 30.103125 252 \r\nL 309.103125 252 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path d=\"M 30.103125 198.782609 \r\nL 309.103125 198.782609 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_4\">\r\n    <g id=\"patch_25\">\r\n     <path d=\"M 37.103125 247 \r\nL 75.465625 247 \r\nQ 77.465625 247 77.465625 245 \r\nL 77.465625 231.321875 \r\nQ 77.465625 229.321875 75.465625 229.321875 \r\nL 37.103125 229.321875 \r\nQ 35.103125 229.321875 35.103125 231.321875 \r\nL 35.103125 245 \r\nQ 35.103125 247 37.103125 247 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_51\">\r\n     <path d=\"M 39.103125 237.420312 \r\nL 59.103125 237.420312 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_52\"/>\r\n    <g id=\"text_20\">\r\n     <!-- 3 -->\r\n     <defs>\r\n      <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n     </defs>\r\n     <g transform=\"translate(67.103125 240.920312)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-51\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"padb04ac629\">\r\n   <rect height=\"53.217391\" width=\"279\" x=\"30.103125\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p0838bac811\">\r\n   <rect height=\"53.217391\" width=\"279\" x=\"30.103125\" y=\"71.06087\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pdea5f7a4a2\">\r\n   <rect height=\"53.217391\" width=\"279\" x=\"30.103125\" y=\"134.921739\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p8100362961\">\r\n   <rect height=\"53.217391\" width=\"279\" x=\"30.103125\" y=\"198.782609\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEeCAYAAAAXYak7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd1yV1R/H34eNCxTEhYgL90YcmSNzZ+bIHGmOMitT04a2x680y1FpWZY5cpV775FbwVyoCOJgKFNA9oV7fn88Uqgg67kLnvfrxUvuvc9zzke4fO853/MdQkqJhoaGRknAytQCNDQ0NIyFZvA0NDRKDJrB09DQKDFoBk9DQ6PEoBk8DQ2NEoNm8DQ0NEoMNqaa2NXVVXp6eppqeg0NjWKKn59ftJSyYk6vmczgeXp64uvra6rpNSyIqHtpuJS2w8pKmFqKhgUghLiZ22smM3gaGo8jLjmdLefCWesXyrnQeD7t25BRT9Q0tSwNC0czeBpmgy5Tz99Xo1jrF8q+y5GkZ+qpX7kslcs5sP3iHc3gaRQZzeBpmJzLtxNY6xfKprNhRCem41LajuFtPRjUyp1GVZ34ZtcVFh4KJj5Fh5OjranlalgwmsHTMAnRiWlsOhvOOr9QLt1OwNZa0LV+JQa2cqdzvYrYWv8XQNClnhsLDlzjcGAUzzStakLVGpaOZvA0jEZ6hp79VyJY6xfGwYBIMvSSpu5OfPZsI/o2q0qF0nY53tfCozzOpWw5cEUzeBpFQzN4GkYhOCqRIb+cIPJeGm5l7RnboSYDW7njValsnvdaWwk61q3IoauR6PVSO63VKDSawdMwOKm6TN5Y+Q/pmXp+H92aJ+u4YmNdsJj3p+q7sflcOBfC4mlW3dlASjWKO1qmhYbB+WLrJS7fTmDO4GZ0qedWYGMH0NGrIkLA/iuRBlCoUVLQDJ6GQdl6PpwVJ28xrmMtnqpfqdDjVChtR4vqzhwM0AyeRuHRDJ6GwbgRncS0dRdo4eHMOz3qFXm8p+q7cS40nqh7aSqo0yiJaAZPwyCkZWQyYdUZrK0E84e1fCDMpLB0rucGoK3yShAhscmqjqcZPA2D8NW2y1wMS+Db55tRzdlRlTEbVS2HW1l7DgZEqTKehvmSkp7JjO2X6fztQQ5dVe/3bTGntD8eDKJOxTJ0a1gJIUwXlpCRqSc1Q0+qLvP+16Pfe7iUyle4RXFlx4XbLD1+k7EdatKtYeH9dg8jhKBLPTe2X7iNLlOvyqpRw/w4FhTN9A0XuBmTzFCf6jRX8VQ+XwZPCNET+A6wBn6VUs586HUn4A/A4/6Y30opf1dLZHqGnk3/hBMQcQ8fzwpM712fFh7l1Rr+EW5EJ/HjwSD+uRVHakYmKel60nSZpGZkosvMu8ubtZVg1sCmDGzlbjCN5sqtmGTeXXeeZtWdea9nfdXH71LfjTW+IfjdvEvbWi6qj18UEtMysLUW2NtYm1qKRRKfrOOr7ZdZ4xuCp0spVr7Shva1XVWdI0+DJ4SwBhYA3YBQ4LQQYrOU8lK2y94ALkkp+wohKgIBQogVUsp0NUTa2VixdWIH1pwOYd7eq/T/8Rh9mlbhvR718XAppcYUAFyPTuKH/YFsOhuOjZWgo1dFytrbYG9rjYOtFQ621jhm+97BxhoHO2scbO4/trXGzsaKb3ZdYepf54hNSueVjrVU02fuZPntAOYPbYGdjforsA51XbG1Fhy4EmkWBi8+WcfuS3fYduE2RwKjKV/aji/6NaJn4yqmlmZR7Lhwm483+xOblM74TrWZ/HRdHGzV/+DIzwrPBwiSUgYDCCFWA/2A7AZPAmWFstcsA8QCGWoKtbW24sW2NXiuRTV++TuYRX8Hs9v/DiPaevLmU3Uon0taUn4Ijkpk/v4gNp4Nw87GitHtPRnXqRZuZR0KNd7iUa2ZsuYcX26/THRSGtN61jfpNtxYzNxxhfOh8Sx8sRXVK6j3QZSdMvY2+NSswIGASKb3bmCQOfIiPkXHnksRbDsfzpGgaHSZkmrOjoxq78mxazGM/+MMvRpX5rN+jQr9HiopRCSk8vGmi+zyj6BR1XL8Pqo1jas5GWy+/Bi8akBItsehQJuHrpkPbAbCgbLAC1JKvSoKH6KMvQ1TunkxvI0Hc/dcZcmx6/zlF8IbXeowqr1ngT4Vrt03dJvuG7qxHWoyrmNtKpa1L5JGextrvh/agvKlbfn5UDCxienMGNCkUAG3lsIu/zv8fvQGo9p70rNxZYPO1aWeG//bdpnQu8m4lzeMYX2YhFQdey9FsO38bf4OjHrAyPVpWpVm7k4IIdBl6ll0OJh5ewM5GhTNB30aMNi7eon4wCsIUkpWnw7hq+2XSc/QM61XfV7uUNPgfyNCysf7pIQQzwM9pJQv3388AvCRUr6Z7ZpBwBPAFKA2sAdoJqVMeGisccA4AA8Pj1Y3b+ZamDTfBNy5x8wdlzkQEEU1Z0fe7uFFv2bVHptveS0qkR/2BbL5XDh2NlaMbOfJK0/WKrKhexgpJd/tC2Te3kCebuDG/GEtDbJMNzUhscn0+f4wNVxKs/a1dgb3YV2LSqTr7EN80a8RI9p5Gmyee6k69l6+b+SuRpOeqaeqkwO9m1ShT9MqNK/unKshC45KZNr6C5y6Hkv72i7MGNCEGi6lDabVkrgRncS09ec5ERxL21oVmDGgKTVd1fvZCCH8pJTeOb6WD4PXDvhUStnj/uPpAFLKGdmu2QbMlFIevv94PzBNSnkqt3G9vb2lmiXejwVF89UOJRSiUdVyvN+7AU/UedDhGRSZyA/7A9lyLhx7G2tGtqvBKx1r4VpGXUP3MMuP3+Djzf541yjPryNb41Sq+NR0S8/QM/jn41yLTGTbxCdV9anmhpSSzt8epHbFMiwe1Vr18Y9di+b3ozc4dDWK9Aw9VbIbOXfnfBcv0Oslq07fYub2K+j0eqZ082LME4ZfxZgrGZl6Fh2+zry9V7GzseKD3g14obX6q9+iGjwb4CrQFQgDTgPDpJT+2a75CYiQUn4qhKgEnEFZ4UXnNq7aBg+UN9iW8+HM2hlAWFwKnetVZHqvBlhbwff7gthyPhwHG2tGtq/BK08a3tBlZ+v5cN5ac5baFcuwdIwPlcoVD9/Ol9susejwdX4c3pLeTYznqP90sz+rT9/i7MfdVV01xySm8cTX+ynnYMszTavSp2kVWlTPv5HLiTvxqXy48SJ7L0fQ1N2JmQOa0rBqOdU0WwIXw+J5b915/MMT6NGoEp/3a2ywv4EiGbz7A/QG5qGEpSyWUn4phBgPIKVcKISoCiwBqgACZbX3x+PGNITByyJVl8my4zeYvz+IxLQMJOBoa31/61oTFyMauuwcCYzm1eW+lC9tx7IxPtSqWKbQY6Vn6Nl3OYLVp0MIuHOPBcNb0KpGBRXV5s3eSxG8vMyXEW1r8MVzjY0696GrUby0+BS/j25Nl/sZGGrw7a4AFhwMYs9bnajjVvjfz8NIKdl24TafbvYnLlnHq51q8eZTBTuJTEzL4EJoPOdD4zgfGs/5sDjiknRUr1CKGi6l8HApRY0KpZXvK5SiqrMj1mZQSuv3o9f537bLVDDSCXaRDZ4hMKTByyIuOZ3fjlxHCMGo9p65Fpg0JudD4xj9+2kAloz2oYl7wU6krkUl8ufpENadCSU6MZ3K5RywthLEJqWzcEQrOnnl2J1OdcLiUuj93WGqOTuy/vX2RvdNpuoyafH5Hp73dufzfuoY24RUHU/M3E+HOq789GIrVcZ8mLtJ6fxv22XWnQmlVsXSzBzQFJ+aj35QpeoyuXQ7gfMhWcYtnmtRiWT9uVZzdqRZdSdcy9gTEpvMzdhkQmNTSM/876zQ1lrgXl4xfllGsIbLfwbR0L+zjEw9X2y9xNLjN+nesBLfDGpmFHdOiTV45kpwVCIjfjtFXHI6v4z0fsTX+DAp6Zlsv3CbNadDOHUjFmsrQdf6bgz18aCjV0Vik9J5afEpAiPvMfeF5gavCqzL1PPCz8cJuHOPrROfVNXhXBBeXnqaK3fucfjdLqr4gX48GMSsnQFsmdChwB9EBeXvq1G8v+ECoXdTeLGtB8+3qq4YuNA4zoXEczXiHhl65W/TtYw9zdydaOruTNPqTjSt5pTjLiVTL7kdn8KtGMUA3oxJ5lZskvJvTDL30v6LFHMuZctX/ZsYzA2RmJbBmyvPcCAginEdazGtZ32jFW7VDJ4ZEpGQysjfTnE9Oom5LzSnT9NH33gXw+JZczqEjWfDuJeagadLKV5o7cHAVtUeie+KT9Hx8tLT+N68y5fPNWFYGw+DaZ+x4zI/Hwrm+6EteLaZ6Uqu/3HipuIbm9KROm5FS+VL1WXS4ev9NKzqxLIxPiopfDzJ6RnM3n2VxUev/7tyK+dgQ7PqzjSpphi4ZtWdqFzOocgGXUrJ3WQdN2OSuBWbzOKjNzgXEseQ1tX5uG9DStmpl2UaHpfCmCWnCYxM5It+jQ36XsyJxxk8i8mlLW5UKufAn6+2Y+zS00xYdYbY5MaMaFuDe6k6Np0NZ83pEC6ExWNnY0XvxpUZ4uNBm5oVcn3jOznasmxMG15b4cf7Gy4Qn6Ljtc61VdWckp7JnD0BLDp8naE+HiY1dqCkmQEcuBJVZIP3p28I0YnpvK7yz+xxlLKz4aNnGjKgZTWCo5JoUs2JGi6lDBKzJ4SgQmk7pa6gR3l6N6nCvL1X+fHgNU5dj+X7oS1UCfi9EBrP2KWnSUnP5PdRreloJBdLftFWeCYmJT2TCSvPsO9KJB3quOJ38y4pukzqVy7LUB8PnmterUB+j/QMPW//dY7N58J5tWMtpvVSJ8vj2LVopq27wK3YZIa18eDjZxqaRUxhj7l/U6G0HavGtS30GLpMPZ2/OUhlJwfWjm9XooKEj1+L4a01Z4lJSuPdHvUZ26Fmobeeu/3vMGn1WSqUtmPxqNbUq2yaAhraCs+McbSz5ucRrfhgw0W2XbjNcy2qMaR1dZrej9wvKHY2Vsx7oTlOjrb8/Hcwcck6vhrQpNCndQmpOmZsv8KqU7fwdCnF6nFtzSKHNYsu9d349XAwCak6yjkUziG++Ww4YXEpfPFcoxJl7ADa1XZhx6Qnmbb+PF9uv8zfgVHMfr4ZbgUIGZFS8tuR63y5/TJNqzmx6CVvs02p01Z4ZoSUUrU/OCklc/Zc5Yf9QfRqXJl5Q5oXOANi76UIPth4gah7abzyZC0mP+2Fo53pV3XZORkcwwu/nOCn4S3pVQgHvF4v6Tb3ELbWVuyY9GSJM3hZSClZdSqEz7f6U8rOhm8GNaVrg7xLe2Vk6vl0iz9/nLhFr8aVmTO4ucnfIxazwtPpdISGhpKammpqKY/FwcEBd3d3bG3VPWJX849NCMHU7vVwLmXHF1svcW+JLz+PaEVp+7x/5TGJaXy65RJbzoVTv3JZFo30pqm7eXYKa1WjPOUcbNh/JbJQBm/3pTtci0ri+6EtSqyxA+X9MqyNBz41KzBx1T+MXerLyHY1eL93g1xdF/dSdUxY+Q+HrkbxaqdavNfDeCexhcWsDF5oaChly5bF09PTbN98UkpiYmIIDQ2lZs2appaTJ2M71MTJ0Zb31p1n+K8nWTK6Nc6lco5HlFKy+Vw4n272JzEtgyndvBjfqbZByjyphY21FR29KnLwalSBe9ZKKfnx4DU8XUrRx4hZIuZMHbcybHijPd/sDODXI9c5ERzD90NbUL/yg5khYXEpjL1/EjtjQBOG+hj3JLawmNU7OTU1FRcXF7M1dqB8Erq4uJj9KjQ7g1q589Pwlly6ncDgn48TkfCo9vC4FMYu9WXS6rPUcCnNtolPMrFrXbM2dll0qedG1L00/MMT8r44G0eCojkfGs/4TrXNIiPBXLC3sebDZxqydIwPsUk6np1/lKXHbpDl/jofGsdzC44SdjeFpaN9LMbYgZkZPFB3W2coLEHjw3RvVJklo1sTdjeFgT8d40Z0EqD4sFacvEn3uX9z/FoMHz3TkHWvtbeoEvWd6ik9aw8UsLnPggNBVCpnT/+W1QykzLLp5FWRnZOf5InaLnyy2Z+Xl/ryl28Ig38+jp21Feteb0+HuupWJDY0ZmfwzIGdO3dSr1496tSpw8yZM/O+wUJoX9uVVePakpSWwaCFx9lzKYKhi07wwYaLNKvuxK7JHRnboabFrXZcy9jT1N25QE26/W7e5URwLK88WUsryf4YXMvYs3hUaz7p25DDgdG8s/Y89SuXY+MbT1jUh2IWZuXDMwcyMzN544032LNnD+7u7rRu3Zpnn32Whg0bmlqaKjR1d+av8e0Y8dspXlnmS1kHG2YNbMrz3u4WuXLN4ql6bszbd5WYxLR8FYf46WAQ5UvZWtR2zFQIIRj9RE3a1nLhQEAkY56oaRYxmIVBW+E9xKlTp6hTpw61atXCzs6OIUOGsGnTJlPLUpU6bmVZ+1p7Jnaty94pnRhsgJpkxqZL/YpISb5a+l2+ncDey5GMal8zX6fWGgoNqpTj9c51LNbYgWbwHiEsLIzq1av/+9jd3Z2wsDATKjIM1ZwdmdLNq9jU5WtcVakckp9t7U8Hr1HazpqX2tcwgjINc0KVNo33r+mMUjPPFoiWUnYqirDPtvhzqYCnbnnRsGo5Punb6LHX5BSIbemrn5KAlZWgc72K7Pa/Q0amPteqwjdjkth6PpxXnqyVa3iORvElzxVetjaNvYCGwFAhRMOHrnEGfgSelVI2Ap43gFaj4O7uTkjIfz2LQkNDqVrVtEnyGvnjqfpuJKRmcOZWXK7XLDwUjI210rBJo+ShVpvGYcB6KeUtACllweIDciCvlZihaN26NYGBgVy/fp1q1aqxevVqVq5caRItGgWjQ11XbKwEBwIicyyqGZGQyjq/UJ73di9QrqhG8SE/Pryc2jQ+HLjkBZQXQhwUQvgJIUaqJdDY2NjYMH/+fHr06EGDBg0YPHgwjRqZxvhqFIxyDrZ4e5bnQC5+vF8PB5MpJa92NF4JKA3zIj8rvJwcWA87umyAViiNfhyB40KIE1LKqw8M9GCbxoKrNRK9e/emd+/eppahUQiequ/GV9uvEB6XQlVnx3+fv5uUzoqTt3i2WVWjdFbTME/ys8ILBapne+yO0nD74Wt2SimT7ncq+xto9vBAUspfpJTeUkrvihXNqzCgRvEgq6HPw1kXS47dIDk9U/WiqBqWRX4M3mmgrhCiphDCDhgCbH7omk3Ak0IIGyFEKaANcFldqRoaeVPHrQzu5R0f2NYmpmWw5NgNujWsZJHZARrqkeeWVkqZIYSYAOzivzaN/tnbNEopLwshdgLnAT1K6MpFQwrX0MgJIQRd6rmx1i+UVF0mDrbWrDp5i/gUnVHLt2uYJ/mKw5NSbge2P/TcwocefwN8U1RBahbBNBSmKpqqkT+equ/G8hM3OXk9ljY1K7DocDDta7vQwqO8qaVpmBizyqtxcHAgJibGrEtEZdXDc3DQwhrMlba1XLC3seLAlUhC7yYTeS+NuS80N7UsDTPArAyeu7s7oaGhREXlnQ9pSrIqHmuYJ4521rSv7cL+K5HsvxJJs+rOtK9tPn04NEyHWRk8W1tbi6girGH+dKnvxoEAfwA+7NPAbHcMGsZFKx6gUSzJCk+p61aGp/PRjEajZGBWKzwNDbWoXqEUE7vW5YnaLmbfWEbDeGgGT6PYMqWbl6klaJgZJutLK4SIAm4W8DZXINoAcgqDpiV3zEmPpiVnirOWGlLKHFO5TGbwCoMQwje3BrvGRtOSO+akR9OSMyVVi3ZooaGhUWLQDJ6GhkaJwdIM3i+mFpANTUvumJMeTUvOlEgtFuXD09DQ0CgKlrbC09DQ0Cg0msHT0NAoMWgGT0NDo8SgGTwNDY0Sg2bwNDQ0Sgwmy6V1dXWVnp6epppeQ0OjmOLn5xedW2qZyQyep6cnvr6++b8h5DTY2EGVR5qhaWioS9RViA4o3L1VW4CTmReHTbsH9yLAtY6plTwevR7OroDmw8DKOt+3CSFyzdG3jGopGenw5whw9oAxu0Ar5qhhKPR6WNIHknJu5p0nDk4wfC1U91FXl1okhMPy/nD3BkwNAEdnUyvKmUwdbHwNLvwF9mWh0XOqDGsZBs/GDjpPgy2TIGA71O9jakUaxZXwM4qx6/YF1O5SsHvTEmHT67CsH7zwB9TpahiNhSXmGix7Du7dBr0Oru2HxgNMrepR0pPhr1EQuAu6fgIN+6k2tGUYPIDmL8Kx+bD3M6jbA6wtR7qGBXF1FwgraPEilKpQ8PvH7ILlA2DlCzBwETTqr77GwnDngqJLZioaVwyEwN3mZ/BS4mDVELh1Ap6ZC95jVB3eck5prW2g68eKb+XcSlOr0SiuBO4G99aFM3YAZdxg1Fao1grWjgG/JarKKxS3TsDvfcDaFkbvBPdWULsrBO5RtvDmQmIkLH0GQn1h0G+qGzvIp8ETQvQUQgQIIYKEENNyeL2zECJeCHH2/tfHqisFaNAXqnnDgRnKsldDQ03u3YHbZ6Fu96KN4+gMIzYoRmXLJDgyVx19hSFwj7KNLVNRWdlVvF8F2qsHJEdD+D+m05aduFuwuKey7R62GhoPNMg0eRo8IYQ1sADoBTQEhgohGuZw6WEpZfP7X5+rrDNLDHT7DO6Fw6mfDTKFRgkmaK/yb1ENHoBdKRiyUvnD3fsp7PkYjF2o48JaZXtY0UtZ2TlX/++1Ok8DQlnRmprIK/DbfQM8YuN9bYYhPys8HyBIShkspUwHVgPqeRELimcHxYd3eC4kx5pMhkYx5OouKFsFKjdRZzwbOxiwCLzHwtHvYMtE0GeqM3ZenP4V1r0M1dvAS1uVFV52SlVQtu6Bu4yjJzfC/OD3XqDPgFHbwaONQafLj8GrBoRkexx6/7mHaSeEOCeE2CGEaKSKutx4+hNISzDtVkGjeJGpg2sHoG43dcOerKyhz2zo+A6cWQZrR0NGmnrjP4yU8Pc3sG2qsm19cR04lMv5Wq/uypY2sZAhOEUl+BAsfVYJOxm7Cyo3NviU+TF4Of32H16bn0FpnNEM+AHYmONAQowTQvgKIXyjoqIKpjQ7lRpBs6Fw8meIDy38OBoaWdw6Dun3lN2D2ggBT30IPb6CS5uUE9y0RPXn0eth1wew/3/Q9AUlNMbWMffrs7bugXvU15IXl7fCikHgVF3xLVaoZZRp82PwQoFsm3/cgfDsF0gpE6SUife/3w7YCiFcHx5ISvmLlNJbSuldsWKOmR/5p8v7yr8HZhRtHA0NUHxZVrZQq5Ph5mj3BvT7Ea4fUmL11HTJZGbA5glwYgH4vArPLVROZR9H5aZQprLxt7X//KEkElRpBqO3Q7kqRps6PwbvNFBXCFFTCGEHDAE2Z79ACFFZCGUfIITwuT9ujNpiH8C5Ovi8ooSoRFwy6FQaJYCru8HzCWV7ZUhaDIfBy+HOefi9NyTcLvqYulT46yUlDavzdOj1NVjl409bCGULf+2AsqU3Bsfmw6Y3oGYn5YCisOE/hSTPn4qUMgOYAOwCLgN/Sin9hRDjhRDj7182CLgohDgHfA8MkcaoHf/kVLArC/sMcyisUUK4e0OJ71TjdDY/NHhGST+LD4HF3SE2uPBjpd1TtoZXtkKvWUpGUkF8kF49FH/4rROF15AfpIR9X8DuD5TMiWFrwL6MYefMgXylK9zfpm5/6LmF2b6fD8xXV1o+KFUBOkyGfZ/BzWNQo73RJahGRrpyLF+uqqmVlDyyfFiG8N/lRq1O8NJm+GOQEn/2zDwlD7cgyEzY8wncPgf9f4FmLxRCR2dlKx+4G2o+WfD784NeD9vfBt/foOVI5f9agGIAamKyJj7e3t6yQNVSciM9GX5oqTg/x+62zMICybGw4nmIuAhvnILyNUytqGTxxyCIvQYTTRCEG3lFSea/F573tTlh4wDPL4F6vQqvYemzkBgBb5ws/BiP4+xKpRDAE5Pg6c8M/jcqhPDLrbG35Sek2pVS/BZbJsKVbcp2wZLIql4Re115fHAG9F/4+Hs01CM9GW4chlajTDO/W314/RjcPl+4+8t7Fv0D0qsH7Hof7t40zIet72JwrWcUY5cXlm/wAJoPh+Pzla2tV0/LKSwQcw2WP6es8F5cC0H7lADVdhOMEpOkgWLsMlKN57/LCcfyhj0dzou63RWDF7hbOQhUkzsXIfQ09JhhcmMHllQ84HFY2yhlZKKvKidVlsCdC4rvJi0RXtoCNTsq/kgHJ8VwaxiHwN1gWwpqPGFqJabDpQ6Ur2mYNDO/JWBtD82GqD92ISgeBg+UGnnuPsqW0NwLC2SvXjFmJ1RrqTzvWF45eQ7cDdcPm1ZjSUBKJRylVmewdTC1GtMhhLLKu/436FLUGzc9Gc6vUU5ljRx+khvFx+D9W1jgNpw0Yx/YI9Ur6j34us84KFcN9n5i/GTzkkZUAMTfUmLRSjpe3ZWtvZoftP4blJAXU/lHc6D4GDxQwlK8esGReeZZWCCreoVr3UerV2Rh66BkkYT5weXNj76uoR5ZGQam9N+ZCzU6KFt7Nbe1fkvA1cuswsWKl8EDpUhoWgIcnm1qJQ+SvXrFqByqV2Sn2VCo2EAJqDZWBHxJ5OpuqNTY/JvuGANbByX7IXCXOjuLCH8IPaWs7szgsCKL4mfwKjVUuhyd+kUpKmhqpIS/v32oekUeAaZW1kpFmJgg+Ge5cXSWNFLjlYIB2nb2P7y6K38zUYXs2JYdv6Vgbad8eJsRxc/ggRKXhzB9YQEpYfeHsP8LaDI47+oV2fHqCR7t4OBMSE8yrM6SyLX9SqaCMbMrzJ06941/Ube16clwbrVZHVZkUTwNnnN1aDMOzq1SltamIDMDNk1Q4gN9XoX+P+ddvSI7QiiBmokRcOJHw+ksqQTuAQdnpQimhoJzdXBrVHSDd2kjpMWb1WFFFsXT4AF0mAL25ZQuZ8bm3+oVf0CnafmvXvEwHm2g/jNw5DtIMmzxmRKFXq/8UdfpajlB6sbCq7uy1U+NL/wYfkvApa5ZxjYW3992qQrw5FtKP4GL68GtgXHm1WfCrulKTFPPr6Ht+LzveRxdP4aAtnD4W+hpJrX/4kIg3QAFLHPD2k4pEKmW8/v2WUiK0k5nc6Jud6WS+LUDhWt+HeS1gu0AACAASURBVHEJQk5C9y/N6rAii+Jr8ADajIeTvyhltY2JsFa2sGpEl1esp/RIPbUI2ryq5E6aCikVn+Khmcaf+8mpivFXg8DdgDBosxiLxd1HOVQL3FM4g3fGPA8rsijeBs/WEV7Zp3ziGBOXuurmwnaeDuf/hANfwYBf1Bu3IOj1sHOa0i2u6QtFq85RUPw3KLGVDZ+DKk2LPl7gbnD3htKPFOXWsLa537N2t/I7L4grRpei+M0bPAulXQynsQiYlcHT6XSEhoaSmpqq7sBW9VUdzsHBAXd3d2xtC3AIURTKVVVWq1mFBdT4oy8ImTqlSu35Ncr83f9n3O1Krc5w87hSEeflfUWrpZYYBWFn/msRoPEoXj3Af72y9c9Ke8wP/hsV358ZHlZkYVYGLzQ0lLJly+Lp6Ykww/0/gJSSmJgYQkNDqVmzpvEm7jBZcQbv+0yJ5TMWuhT4azRc3aFsKTtMMb5vxrE89JoJa8co8ZVtXyv8WEF7AKn57x7Hvz1r9xTM4PktUQoReHYwlLIiY1antKmpqbi4uJitsQMQQuDi4qL+KjQvsgoLBO1VDkSMQWo8/DEQru6EPnOU+U31u2k0QDFS+74oWkB54G4oU0lpYKORM6VdoVqrgjX3ibwMISfMLrPiYczK4AFmbeyyMJlGn3FQzl0p623owgKJUbDkGcX/OfBXaD3WsPPlhRBKf1eAbW8X7v+fqYOg/Up2RWHChEoSXj2UrX9iPtup/ptZMcywuoqI9lt/iDFjxuDm5kbjxmZYgDOrsED4GaW/qaGIC4Hfe0J0IAxdDU0GGW6uguDsofR3DdylHGQUlJBTSkCstp3Nm7rdAKnsKPLi38OKvmZ7WJGFZvAeYtSoUezcudPUMnKn2RDDFhaIugqLeyif7CM3ml+uaZtXoWoL2PEepNwt2L2Bu+73nu1iGG3FicrNlK1/frIuLm2G1DizPqzIQjN4D9GxY0cqVDCv/L8HsLKGpz9Vms6cWabu2GFnlJVdpg5GbwOPtuqOrwZW1tD3O0iOgT0FjMsL3AM12oFDOcNoK05YWSm5tdf2KWmSj8NvCVSoDZ4G6nqmIprBs0S8eoBHeyUIOE2ljIfrf8PSvmBXWqnCXLmJOuMagirNoN0bisG/cSR/98SFQOQlbTtbELy6KwdXj4tjjbwCt46Z/WFFFmYVlvIAO6YpfR/UpHITJbzB0smq7vxbNzjxE3R6p2jjXdmmhJ5UqAUj1ltGb9zO0xU/5pbJMP5I3iXas7ZmWnWU/FOrC1jZKD87z1zyYs8sVdwEzc37sCILbYVnqVT3UQoLHP0OkqILP87ZVbBmhPJhMHq7ZRg7UNpzPjMXYgLzV+w1cDc411CqTWvkD4dySomy3Px4ulSl52yDvhaTtWK+K7zisBIzNFmFBQ7OgE7vFfz+C38p7flqdYYXVoB9GbUVGpY6XZU0tyNzofGA3AtE6FIh+BC0HGER2y6zwquHUtMxLuTRlgSXLeewIgvzNXgmYujQoRw8eJDo6Gjc3d357LPPGDvWxDFouZFVWOD0r8pXYWjQFwb+Bjb26mozFj2+Ug4jtkxS+oTkFF934whkpGj+u8JQt7ti8AJ3PxqL6bdEcYNYwGFFFprBe4hVq1aZWkLB6Pm10icjoxCZHw7OSkK+JdeEK+2qGL2N48FvMbR++dFrAneBjaNZpzyZLa5eiisgcM+DBi/qKtw8Ct0+t6ggbgt+p2sAii+rxYumVmFamg1RAl/3fgb1ej/oh5RSWZ3U6pT/8voa/5HVs/bsCsU1kHU45LdEOaww88yKh7Ec06yhkRtCKAcYmemw490HX4sOhLs3zC+A2pLw6gG65P9CgHSpcG4lNHjm8d33zBDN4GkUD1xqKwc3l7fA5a3/Pf9vOIrmvys0nh0Ul0DWz/LyFiXLxYIOK7IwO4MnDZ0UrwKWoLFE0v5Npc/s9ncgNUF5LnCXkorn7GFabZaMrSPU7Phfz1q/JVC+Jnh2NLWyApMvgyeE6CmECBBCBAkhpuXwuhBCfH//9fNCiAIU0foPBwcHYmJizNqgZNXDc3DII9BVw/hY20Lf7+HebSXXODVBKRzqpa3uioxXd8U1ELADbh5RVncWdFiRRZ6HFkIIa2AB0A0IBU4LITZLKS9lu6wXUPf+Vxvgp/v/Fgh3d3dCQ0OJispnSRoTkVXxWMMMcW+lFBg4+bOyMtHrtO2sGmT9DLdMvJ9ZMdy0egpJfk5pfYAgKWUwgBBiNdAPyG7w+gHLpLI0OyGEcBZCVJFS3i6IGFtbW+NWEdYonjz1oeJnOvY92DspYTsaRcPZQ3ENRF1WQpks7LAii/ysSasBIdkeh95/rqDXaGgYB/uy/xULrd2lYA3QNXIn66TbAg8rssjPCi+nXJyHnWz5uQYhxDhgHICHh+ZE1jAg9XrBsz8obQc11KHdG+DkDjU7mVpJocnPCi8UyJ5E5w6EF+IapJS/SCm9pZTeFSta5pJYw4JoORLc1O1YV6IpW1nxj1rgYUUWIq8TUSGEDXAV6AqEAaeBYVJK/2zX9AEmAL1RDiu+l1I+9qNVCBEF3CygXlegCKVBVEXTkjvmpEfTkjPFWUsNKWWOK6o8t7RSygwhxARgF2ANLJZS+gshxt9/fSGwHcXYBQHJwOh8jFvgJZ4QwldK6V3Q+wyBpiV3zEmPpiVnSqqWfOXSSim3oxi17M8tzPa9BN5QV5qGhoaGuljuZlxDQ0OjgFiawfvF1AKyoWnJHXPSo2nJmRKpJc9DCw0NDY3igqWt8DQ0NDQKjWbwNDQ0SgyawdPQ0Cgx5GnwhBCLhRCRQoiLubyuSmkoDQ0NDUOTnxXeEqDnY17PXhpqHEppKA0NDQ2zIz+ZFn8LITwfc0mhSkO5urpKT8/HDauhoaFRcPz8/KILnVqWD3IrDfVYg+fp6Ymvr68K02tYAjq9jt03dtPRvSNl7cqaWk6JJjI5Ev9of7p4dDG1FIMghMg1R1+NQ4t8lYa6L2ScEMJXCOFr7lWNNdTjXvo9Xt/7OtMOT+Odv98hU59pakklmtm+s5l4YCJ+EX6mlmJ01DB4+SoNBVp5qJJIWGIYI7aPwPeOL71r9uZo2FF+OW9OQf4li/i0ePbe3AvAzFMzS9yHjxoGbzMw8v5pbVsgvqCl3TWKJxeiLjBs2zAiUyJZ2G0hM5+cybO1n+Wncz9xJOyIqeWVSLZf3066Pp0xjcdwJfYK6wLXmVqSUclPWMoq4DhQTwgRKoQYK4QYn1UeCqWKSjBKaahFwOsGU6thMey5uYfRu0bjaOPIH73+oE2VNggh+LDth9QtX5f3/n6PsMQwU8sscawPXE+DCg2Y3HIyrSq14od/fiA+Ld7UsoxGngZPSjlUSllFSmkrpXSXUv4mpVyYVR5KKrwhpawtpWwipdROIkowUkp+v/g7Uw9OpX6F+qzovYJazrX+fd3RxpG5necipWTKwSmkZaaZUG3J4lLMJa7EXqF/3f4IIZjmM42E9AR+OldyIsmKfabFxeiL+N7xNetet8UFnV7H5yc+Z47fHLp7dufX7r/i4ujyyHUe5Tz4ssOXXIq5xIyTM0ygtGSyPnA99tb29K7ZG4D6FeozqO4gVl9ZTdDdIBOrMw7F2uCtu7qOEdtHMHrXaAZuGcjaq2tJyUgxtaxiyb30e0zYN4G1V9fycpOXmdVxFg42uTcr7+LRhZebvMy6wHVsCNxgRKUlk9SMVLYHb+fpGk/jZO/07/MTWkyglG0pvj79dYlYFBRLg6eXeub6zeXT45/SpkobPmn3CVZY8dnxz3j6r6eZ4zeH8MQcD5I1CsHtxNuM3DGSU7dP8Xn7z5nUchJWIu+31oTmE2hTpQ1fnvySyzGXjaC05LLn5h7u6e4xoM6AB54v71CeN5q/wYnbJ9gfst9E6oyHyerheXt7S0MEHqdmpPL+kffZc3MPz3s9z/tt3sfGygYpJX4Rfqy8spJ9t/YB8FT1pxjWYBjelbwRIqdwQo288I/2Z8L+CaRlpDGnyxzaVmlboPtjU2MZvGUwNlY2rHlmzQOrDw31GL1zNBHJEWztv/WRD6MMfQbPb3melIwUNj23CXtrexOpVAchhF9uPTKK1QovJiWGsbvGsvfmXt72fpuP2n6EjZWSTCKEwLuyN3M6z2HngJ2MbjSa0xGnGbNrDIO2DGLd1XXadreA7Lu5j1E7R2Fvbc/y3ssLbOwAKjhUYE7nOUQkRzD98HT0Um8ApSWbmwk38Y3wpX+d/jmuvG2sbHjPRzk1X+a/zAQKjUexMXjX4q4xfPtwrt69ytzOc3mp0Uu5rtqqlKnC5FaT2TtoL5+1/wyAT49/Sre13ZjrN5fbiVoY4eOQUrLUfylvHXwLr/Je/NH7D2o71y70eE0rNuW91u9xOOywFpRsADYEbsBKWNGvTr9cr2lbpS1dPbqy6MIi7iTdMaI641IstrQnbp9gyoEp2FnbMb/rfBq7Ni7Q/VJKfCN8WXl55b9+jKeqP0Wn6p2wFtYF1uNZzpMmFZsU+D5LIEOfwcxTM1kTsIZuNbrxVYevHns4kV+klEw/Mp3twdtZ+PRC2ldrr4Ja4xIcF4x/jH/eF+ZA84rNqV6uet4XFpAMfQbd13anoUtD5ned/9hrQ++F0m9jP56u8TRfd/xadS3G4nFbWjWKB5iUDYEb+Pz453g6ebKg6wKqlqla4DGEELSu3JrWlVsTnhjOmoA1rAtcx95bewulSSCY6j2VkQ1HFivfYGJ6Im///TZHw44yuvFoJrecnK/DifwghODjth8TEBvAe4ffY80zawr1uzQVukwd4/aMIyI5olD3O9k7sa3/NtV9mEfCjhCVEsWAugPyvNa9rDsvNXqJRRcWMaT+EFq4tVBVizlgsSs8vdTzwz8/8OuFX2lXpR2zO89WtQpHWmYakUmRBdeFnu/OfMeem3sY7DWY6W2m/+tHtGTuJN3h9X2vExwXzIdtP2SQ1yCDzHMz4SZDtg7Bs5wnS3stxc7aziDzqM3GoI18dPQjZj45k6auTQt07+2k27yy5xUGew3mg7YfqKrrzf1vciHqAnue34OtlW2e1yfrkum7sS8uDi6s6rMKa6uC73BMzeNWeEgpTfLVqlUrWVhSdCly6sGpsvGSxvLTY5/K9Mz0Qo9lCDL1mXKO7xzZeElj+eqeV+W9tHumllQkLkZflF3WdJFtV7SVR8OOGny+vTf3ysZLGsvPjn1m8LnUIFOfKftu6CsHbhoo9Xp9ocb43/H/yaZLm8qA2ADVdEUmRcpmS5vJ2b6zC3Tf1mtbZeMljeXagLWqaTEmgK/Mxe5Y3KFFbGosL+9+mV03djG11VQ+bvtxvj65jImVsOKtVm/xSbtPOBF+gpE7R1qsI/jArQOM3jkaWytblvdaTvuqhvetdfXoypjGY/jr6l9sCtpk8PmKysGQg1yPv86YxmMK7cKY0GICZe3K8vUp9QKAN13bRKbMfCT2Li961+xNC7cWfP/P9ySkJ6iixVywKIMXHB/M8G3DuRJ7hTmd5zCq8Siz9pEN8hrEj0//yO3E2wzbNqzQDm1TIKVk+aXlTDowidpOtVnRZwV1ytcx2vxvtngTn8o+fHHiCwJiA4w2b0GRUvLbxd+oVqYa3T27F3ocJ3sn3mz+JqfunCq07/hhXRsCN9DSrSWeTp4FulcIwXSf6dxNvcvCcwuLrMWcsBiDd+r2KV7c/iLJGcks7rGYbjW6mVpSvmhftT3Ley3H1sqW0TtHs/+W+UezZ+gz+OrkV8w6PYuuHl1Z3HMxro6uRtVgY2XDrI6zcLJzYvKByWZb0cMvwo/zUecZ1WhUkX21g7wG4VXei29Pf0tqRmqRxvKN8OXWvVsM9BpYqPsbuDRgQN0BrLq8iuC44CJpKSx6qWdD4AYy9BmqjWkRBi8tM43ph6fj5ujGyj4raVqxYE5hU1OnfB1W9FlBbafaTD4wmeWXlptt3mKSLomJ+yeyOmA1oxuNZnbn2TjaOJpEi4ujC7M7z+ZO0h3m+s01iYa8WHxxMRUcKvBcneeKPJa1lTXTfKYRnhTO7/6/F2msDYEbKGNbpkgLg4ktJ+Jo42iyPNtF5xfx8bGPORByQLUxLcLg2Vvbs+DpBSzrvYxqZaqZWk6hcHV0ZXHPxXT16Mqs07P46uRXqn5yqcGdpDu8tOMljoUf46O2HzHFe4pqYSeFpblbc4Y1GMb6wPVm5xIIiA3gcNhhhtUfpkosIkDryq3pXqM7iy8sLnQAfEJ6Antu7qF3zd5F+rCq4FCB15q/xrHwYxwMOVjocQrDsbBjLDi7gD61+vC0x9OqjWsRBg+UUjbl7MqZWkaRcLRxZHbn2YxuNJrVAauZuH8iSbokU8sClFppw7cNJzQxlAVdFzC43mBTS/qX8c3GU96hvKoOfTX43f93HG0cGVJ/iKrjTvWeikQyx29Ooe7fEbyD1MzUfMXe5cWQ+kOo5VSLb3y/IT0zvcjj5YfwxHDeO/wetZ1r83Hbj1X101uMwSsuWAkrpnhP4aO2H3Es/Bgv7XjJ5Ce4B0MOMmrnKKytrFneazlPVHvCpHoepqxdWSa1nMQ/kf+w/fp2U8sBlF4dO6/v5Hmv51UPFq5apipjGo9h542d+N4peKzq+qD1eJX3oqFLwyJrsbWy5b3W7xFyL4RllwyfZ5uemc7Ug1PJ0Gcwt/NcStmWUnV8zeCZiMH1BrOg6wJCE0MZvm04l2IumUTHissrmHRgErWcarGi9wrqlq9rEh158Vyd52jk0og5fnNI1iWbWg7L/JchhGBEwxEGGX9049FUKV2lwI12rsRe4VLMJQbUHaDayqh9tfZ0rt6ZX87/QmRywYPxC8LMUzO5GHOR/z3xvwKfLucHzeCZkCeqPcGyXsuwtrJm1M5RRvWTZOozmXFyBjNPzaRL9S4s7rGYiqXMt5OclbBims80IpMj+fXCrybVEpsay/rA9fSp2YfKpSsbZA5HG0emek8l4G5AgRrtrA9cj52VHc/UekZVPe96v0uGPoN5fvNUHTc7m4I28dfVvxjdeDRda3Q1yBz5MnhCiJ5CiAAhRJAQYloOr3cWQsQLIc7e//pYfanFE6/yXqzss5JaTrV46+Bb3Ii/YZR5l19azsorKxnZcCSzO81WfetgCJq7NeeZWs+w1H8pIfdC8r7BQKy6sorUzFTGNB5j0Hm61+iOdyXvfDfaSc1IZWvwVrrW6Kr6Nrt6ueq81OgltgRvYf4/81X3pQbEBvDFiS/wqezDxBYTVR07O/npWmYNLAB6AQ2BoUKInJwDh6WUze9/fa6yzmKNq6Mr87vOx97anlmnZxl8vuiUaBaeX0hH94680/odi8qXfKvVW1hbWfPt6W9NMn+yLplVV1bRpXqXB5oTGYLsjXZ+PPtjntfvu7WPe+n3VDmsyInXm7/OgLoD+Pn8z0w7PE21BkwJ6Qm8dfAtnOyc+Lrj1wbNPc/PCs8HCJJSBksp04HVQO6FtTQKhaujK+Objudw2GH+Dv3boHPN85tHWmYa77Z+16DzGAK3Um6MazqO/SH7OR5+3Ojzrw9cT3xavMFXd1nUq1CP572eZ03AGgLvBj722g2BG6hWpho+lX0MosXWypZP233KpJaT2H59O+N2j+Nu6t0ijamXej44/AG3E28zu/Nsgwe458fgVQOy7x9C7z/3MO2EEOeEEDuEEI1UUVfCGN5gOJ7lPPnm9DfoMnUGmeNC1AU2XdvEiIYjqFGuhkHmMDQjGo7AvYw7X5/6Gp3eMD+nnNDpdSy9tJSWbi1p7tbcaPNOaD6B0ralHxsAHJIQwsk7J3OtaqwWQghebvIy33T6hovRF3lx+4tFcsP8duE3DoYe5O3WbxvlZ5qftWNORz0P/9TPADWklIlCiN7ARuCR4z4hxDhgHICHh8cjg+p0OkJDQ0lNLVpajaFxcHDA3d0dW1t1ixbYWtvybut3eX3f66y4vIJRjUepOr5e6pl5aiaujq682vRVVcc2JvbW9rzT+h0mHZjEnwF/MrzBcKPMu+P6Du4k3eGjth8ZZb4snB2ceaP5G8w4NYP9t/bn6NDfEJR3VWM16enZk8qlKjNx/0Re3PEi8zrPw7tyzhWZcuN4+HHmn51Pr5q9GFZ/mIGUPkRuZVSyvoB2wK5sj6cD0/O45wbg+rhrcioPFRwcLKOiogpdYscY6PV6GRUVJYODgw02x+t7X5dtVrSRUclRqo67KWiTbLyksdwYuFHVcU2BXq+Xr+x6RbZb2U7GpMQYfL5MfaZ8buNzsv+m/iZ5f+oydfK5jc/JHmt7yNSM1Edee+rPp+Rre14zuq5bCbdk3w19ZfNlzeXmoM35vu924m355KonZb8N/WRSepKqmihieajTQF0hRE0hhB0wBNic/QIhRGVxP+hHCOGDslWOKajxTU1NxcXFxawroAghcHFxMegq9N3W75KWmcZ3Z75TbcwkXRJz/ebSxLUJfWv3VW1cUyGE4D2f90jWJTP/n8eXLleDv0P/JiguiNGNRpvk/WljZcN0n+mEJYax1H/pA68dCz9GZHKkwQ4rHkf1stVZ3ms5Ld1a8v6R9/nx7I95nuCmZ6Yz5eAU0vXpzO2ifnDx48jT4EkpM4AJwC7gMvCnlNJfCDFeCDH+/mWDgItCiHPA98AQmdf/OhfM2dhlYWiNNcrVYESDEWwM2siFqAuqjPnL+V+ITolmms80k+fHqkVt59oMrT+UtVfXGryv7eKLi6lSugo9a/Y06DyPw6eKD91qdOPXC78+kJ2zPnA9FRwq0Mm9k0l0Odk7sfDphfSr3Y+fzv3E+0fef2wa2qzTs7gQfYEvnviCmk41jag0n3F4UsrtUkovKWVtKeWX959bKKVceP/7+VLKRlLKZlLKtlLKY4YUbUhCQkLo0qULDRo0oFGjRnz3nXqrrIIwruk4XBxcmHlqZpFbF95MuMmyS8t4tvazFldpJi9ea/4a5R3KM/PUTIPl2Z6JOMM/kf/wUqOXTF5sdqr3VPRS/2+ebXRKNIdCDvFs7WextTadNltrW7544gvebPEmW4O38sruV4hLjXvkui3XtrAmYA2jGo0ySYm34vFRryI2NjbMnj2by5cvc+LECRYsWMClS8ZP+ypjV4bJrSZzPvo8W4O3Fmmsb05/g52VHZNbTlZJnflQzq4cb7Z4kzORZ9h5Y6dB5lh8cTHO9s70r9PfIOMXhGplqjGq0Sh2XN/BmYgzbLm2hQyZQf+6ptcmhGBc03HM6jhLOcHd8SK3Em79+3pAbACfH/+cVpVaManlJJNo1AzeQ1SpUoWWLVsCULZsWRo0aEBYWJhJtDxb+1mauDZhrt/cQldVORJ2hEOhh3i12atmnTpWFPrX6U+DCg2Y7Ttb9TzbwLuBHAo9xLD6w8wmG2VM4zFUKlWJmadmsj5wPS3cWlDLybBB0AWhV81e/NrjV+LT4hm+fThnIs6QkJ7AlINTKGtXlm87fWuyxlaawXsMN27c4J9//qFNmzYmmT8rfzQ6JbpQDap1mTq+PvU1HmU9eLHBiwZQaB5kFc6MSI5g8cXFqo69xH8JjjaODK0/VNVxi0Ip21JM9Z7K5djL3Ei4YRYrz4dp4daCFb1X4GzvzMu7X2bc7nGEJ4bzbadvjV49Oztm2z/w61NfcyX2iqpj1q9Qn/d83svXtYmJiQwcOJB58+ZRrpzp6vA1rdiUZ2s/y/JLyxlYdyAe5R6NX8yNlVdWciPhBgu6LrCYdoeFpWWllvSq2Ysl/kvoX7e/KoVibyfeZnvwdobUH4Kzg7MKKtWjp2dPVl9ZzdW7V+nh2cPUcnLEo5wHf/T+g0kHJuEX4ce7rd+lZaWWJtWkrfByQKfTMXDgQIYPH86AAcY/6n+YyS0nY2tlyzenv8n3PdEp0Sw8t5AO1TrQ0b2jAdWZD1NaKRWaZ/vOVmW8rPpvIxuOVGU8NRFC8F2X7/ij9x9ms9XOCSd7JxZ1W8Qfvf8wi12G2a7w8rsSUxspJWPHjqVBgwZMmTLFJBoepmKpirza7FXm+s3laNjRfBXo/OGfH0jNSLXIfNnCUrl0ZcY2Hsv8s/M5efskbaoU3hURlxrHusB19KrZiyplqqioUj2cHZzNbuWZE7bWtjSr2MzUMgBthfcIR48eZfny5ezfv5/mzZvTvHlztm83fZXdFxu8iEdZD74+nXf+qH+MPxsCNzC8wXCjxzmZmlGNR1GtTDVmnppZpJ4hqwJWkZKRwujGo1VUp2FqNIP3EB06dEBKyfnz5zl79ixnz56ld+/eppaFnbUd77Z+l+vx11l1eVWu10kpmXFyBuUdyvNqM8vNly0s9tb2vOP9DkFxQfwZ8GehxkjWJbPy8ko6uXcy2wrQGoXDbLe0Go/S0b0jT1R7gp/O/UTvWr1zPO3aGryVc1Hn+Lz955S1K2sClabnKY+naFOlDQvOLsCnsg+OtgXr3LXj+g7i0uKMVgJKw3hoBs+CEELwbut3GbhpID/88wOftf/sgdeTdcnM85tHI5dGRquaYY4IIZjWehqDtgyi/+bChWw0r9jc5CeKGuqjGTwLo5ZTLYY1GMbyS8sZXG8wjVz+Kz246MIiIlMimd15drHJly0sdcrXYUXvFQTGPb5oZm60qWya2EsNw2J2Bk9KafYFBAyVs5lfxjcbz9bgrcw8OZNlvZTuWSEJISz1X8oztZ4xanFKc6aRayMauWq1aDX+w6yWAQ4ODsTExJjcoDwOKSUxMTE4OKjTab4wlLUry+SWkzkbdZZt17cB8I3vN9hY2fBWq7dMpktDw9wxqxWeu7s7oaGhREVFmVrKY8mqeGxK+tXpx5qANcz1nYujtSMHQg4wqeUk3Eq5mVSXhoY5I0y1mvL29pa+vgXvqq7xH2cjzzJixwhshA1VylRhY7+NxT6FTEMjL4QQflLKHOvNm9WWVqNgZPVpzZAZvOP9jmbsNDTywKy2tBoF56O2sLf0/QAAIABJREFUH/Fs7WdpW6WtqaVoaJg9msGzcErZlqJd1XamlqGhYRGYzIcnhIgCbhbwNlcg2gByCoOmJXfMSY+mJWeKs5YaUsocq92azOAVBiGEb27OSGOjackdc9KjacmZkqpFO7TQ0NAoMWgGT0NDo8RgaQav4I0dDIemJXfMSY+mJWdKpBaL8uFpaGhoFAVLW+FpaGhoFBrN4GloaJQYNIOnoaFRYsjT4AkhFgshIoUQF3N5XQghvhdCBAkhzgshtDKxGhoaZkl+VnhLgJ6Peb0XUPf+1zjgp6LL0tDQ0FCfPHNppZR/CyE8H3NJP2CZVI57TwghnIUQVaSUtx83rqurq/T0fNywGhoaGgXHz88vOrfUMjWKB1QDQrI9Dr3/3GMNnqenJ1o9vKKjCwsjftt2XF4ei7DSXLKmJH7rNoS9HeW6dTPKfMm+vujCwnDqZ94NmzLj4ri75k/KDxuKdVnDd9ITQuSao6/GX0hODShyDO4TQowTQvgKIXzNvaqxpXBnxgyi5swh9cIFU0sp0cT89hvhb79N2JsTubt6jcHnu7f/ALdGjyF8+vvowsMNPl9RiFn8O1Fz53JrzFgy4+NNqkUNgxcKVM/22B3I8TcgpfxFSuktpfSuWDHHFadGAUi56E/i3n0AJB46ZGI1JZfohT8T+c23lOvdizKdO3Pn00+JXbHCYPMl7NlD6MSJ2NWqBcDdv/4y2FxFRaanE7duHfZ165B25Qq3Ro8h4+5dk+lRw+BtBkbeP61tC8Tn5b/TUIfoH37A2skJ+4YNSDz0t6nllEiiFiwgat48yvXtS9VZs3D//jvKdO1KxBf/I3bpUtXnS9i5k7DJb+HYqBE1/lhOmY4diVu7FqnTqT6XGtzbu5fMmBjc3n0P9/k/kBYUpBi92FiT6MlPWMoq4DhQTwgRKoQYK4QYL4QYf/+S7UAwEAQsAl43mFqNf0k5e5bEQ4eoMHYs5Xr0JNXfH11kpKlllRiklER+9x3RP8zHqX9/qs6cgbCxQdjZ4T5vLmW7dydixkxifvtNtTnjt24jbOrbODZrRvXffsW6bFmch7xAZlQ09/btV20eNbm7ajW27u6UfqI9ZTp1wv3HH0m/fp1bL40iIybG+IKklCb5atWqldQoPDfHjJUBbdvJzMREmXL5srxUr768u3adqWWVCPR6vYz49lt5qV59Gf7hh1KfmfnoNenpMvStt+SlevVl1E8Lizxn3MaN8lKDhvLGiyNkZmLif/NkZMjALk/JG6NGFXkOtUkNClL+/7/88sDziceOycvNmsug3n1kekSE6vMCvjIXu6Md61kgyX5+JB09isvLL2NVujT29ephU6mS5sczAlJKIr+eRcyiX3EeOoTKn32W4+m4sLWl6qxZlOvbl6h584hasKDQc8atW0f4tOmU8vGh+s8LsSpd+r95rK1xHjyY5OMnSLt+vdBzGIK7a9aArS3OAwc+8Hzpdu2o/svP6G7f5tbIl9BFRBhNk0UYPKnXc/ujj4hbu9bUUsyCqO9/wNrVlfLDhgIghKBMx44kHT2KTE83sbrii5SSiK9mELtkCeVffJHKH3/82FAgYWND1ZkzcOrfn+gf5hP53XcFbjJ/d82f3P7gQ0q3b0/1hT9hVarUI9c4DxwANjbErfmzwP8nQ6FPSSF+4ybKde+OTYUKj7xe2scHj0W/kBEZyc0RI9HdNo7b3zIMXkYGujsR3P7wI6Mc+ZszSSdOknzyJK7jXsHK0fHf58t07oQ+KYnkM/+YUF3xRer13Pn8c+4uX06FUaOo9MH7CJFTRNaDCGtrqnz5P5yfH0TMTwuJmjMn30YvdsUK7nzyCaU7dcT9xwVYOTjkeJ1NxYqUffpp4jdsQJ+aWqD/l6FI2L4DfUIC5Ye8kOs1pVq1wmPxb2TGxnJzxEjSQ8MMrssiDJ6VnR3u83+gTKdOBj/yN2eklET98AM2bm44v/DgG6l027YIW1ttW2sApF7PnU8+IW7ValxeeRm3997Nl7HLQlhZUfmzz3AeOoSYRb8S+fWsPI1e7LJlRHzxP8r8v70zD4+iSvv2/XSWzr6QBBKILCOIDMqigKJIoiMKqIMLSni/UVFRUQQdXFkEFWQZdJwXRJDXbcCRBFxQGEAHHFBk1EEGN1QEBjRkIQnphIQsvZzvj6rGJnbW3qHu68qVrq6qc379VNVT55znLJddRubixZjM5iaPT87JwV5RQeWmTS3W5UvKc3OJ7H4m0QOaXqoiul8/Or/6CvbKSg7dcjP1P//c5PGeEhIOD8BkNpO5eJFPQ/7BTvUnO6j54gtSJtz9qwfAFBtLzMCBVH1kdE/xJspup3D6DCxr3iTlngmkTZnSKmfnREwm0mfOJPkPf+Doa69RPHdeo06v7OVXKJ47j/hhw8j8y3OYIptfYD3mgkFEduuGJQhqQDXffEvt11+TPCanRbaKPvdcOr/6Cqr6uFbSO3jQZ9pCxuEBPg35Bzta6W4R4R0zSBo92u0xcdlZ1O/fT31+vp/VnZoom42CqVOpeOcdUifdR/v772+Ts3MiInSYPo1248ZRvnIlRU89hXI4Tjqm9MXlHFm4kPjhw+n052eRFjg7Z9rJOWOo2b2b2u+/b7NGb2DJy0Oio0m8tuVD3qJ796bzX19D1dVx6OZbqDvgmwBMSDk80KJfnZ7VerUfWfgMpcteDLQkv1C1bRu1X35F6oQJjb7x44YO1Y7dalRrPUXZbBQ88iiV760j7YEHSJs40SvpigjtH32ElDvHY1mVS9GsWSecXsmSJZQ89xwJV19Np2cWIhERrUo7cdQoxGymPDfXK1rbgv3YMSrWryfhqpGtHjcbdfbZmtOz2zl0yy3U7dvndX0h5/DAuyH/UEApRemixURkZpJ03XWNHhfZtSuRXbpQ9ZHh8DxBWa0cnvIglRs20P7hh0idcLdX0xcR0qZMIeWeCVjWvEnh9Bm/dGIeNYqOC+Yj4a2f1yMsKYmEESOofG8d9qpqr2puKRXvvYeqqSF5TE6bzo866yy6rNCaqw7dciu1P+z1pjyvzJYSEJwhfwkPp3Tx8yibjbTJkz2qcgQrVVu2ULtnDxlz5zb71o/NGoolbzWOmpqTorihiqOmhsLHZ2L1YzXdbrFQf/Ag7R97lJRx43ySh4hoVWT9/gVIvOF6Mp56CgkLa3O6yWNzqFi7lsr160jOaZvTaStKKSy5uUSdcw7R557T5nTM3bvTZcUKfho3jp9uvZXOr75CVK9eXtEYsg4Pfgn5S3gYZUuXgc3W5kblYEU5HJQsfp7ILl1I/P01zR4fl5VF+YqVVH/2GfHZ2b4X6GOO/Pk5KtevJ2bwhYj4p0Jiiokh5a67SLq+8dK0t0ibOJGw5GTsZUdJnXivx1N8RfXpg7lXL8pz80gaM8avz0LNrl3U/biPjDmzPU7L/JtudFm5gsMPPYyY3XfHaQsh7fDgl5A/4eGU/d9LKKut1d0GgpljH3xA3Q8/0HHhn1pUzYkZOBCJiaFq27aQd3jVn35G+cqVWiffGdMDLcdntPuf//FaWlrwIoeiWbOo/fJLovv181razVGem4cpPp6EkSO9kl5kly50XZ3n1Wc5JNvwGtKakH8ooex2Sp5/nsgzz2zxTWSKjCR28GCqt30U0jawV1VROG0akV260P7BKYGWE1IkXHUVpthYylf5L3hhO3qUY5s2kThqlNvRIG3F2wWXU8LhQctC/qFG5YaN1O/bT9p9E1vVrhOXNRRrQQH1Pohy+YsjCxZgLSoiY968U6It0p+ExcWS8PtrqNy4EbvF4pc8K955B2W1kjzmJr/k11ZOGYcHTYf8Qw1ls1G6ZAnms84i/sorW3Xuie4pITrqomrbNq2j7x23E3Ne/0DLCUmSc3K0yTffWevzvJTDQXneamIGDMDco4fP8/OEU8rhgfuQv7LbAy2r1VSsW0/9wYOkTrqv1Q3ZEenpmM8+OyQnBbVbLBTOeBxzj+6kTpoUaDkhS1TPnkT3748lN9fnTRvVO/6F9aefSPJzVLgthHzQwh0NQ/7Vn3yCNDMW0R2xF19ExhNPeF9gMyirldIXXsD8217EX355m9KIGzqUspdfxl5ZSVhCgpcV+o6iOU9jKy8nc9nSFg2pMmic5LE5FDzyKMc/+4zYCy/0WT6WvFzC2rUj/gr/LF7kCaekw3OSNnEiER06UP35560+11ZYhCU3j6Rrr/VrpAvAsnYt1p9/JnPpC21utI3LzqJs+XKqd+wgYXhTywoHD5Wb3qdy/XpSJ91HdO/egZYT8sRfeSVhT8+lfFWuzxyetbiYYx/+k5TbbwuJF9Qp7fAAkkaPbnTsaVM4qqvZN+wKShYtpvMr/huzq+rrKV26lKg+fYjzoFtJdJ8+mBITqdq6LSQcnq20lKInnySqd29S77or0HJOCUxmM4nXX8/RlSuxHjlCRPv2Xs/DsuZNcDhIuim4gxVOTrk2PG9hio0lZfx4qnfs4Lgf18+1vPUWtoJC0iZN8mygeng4cUOGUPXxx0EfuFFKUfjEEziqq7XRM60cQ2rQOMljbgKbjYq33vJ62spmw7JmDbFDhhB5xhnNnxAEGA6vCZLH5hCWlkrJosV+yc9RV0fpsheJ7t+f2CEXe5xeXHYW9rIyar/91gvqfEflunVUbd5C2v33B32UL9SI7NqV2IsGU756jdeDd1Vbt2IrLm5yks9gw3B4TWCKjib1zrs4/vnnVH/6mc/zs6xeg624mLT7vTMmOHbIEBAJ6tlTrEVFFM2eQ/R559Fu3K2BlnNKkjQmB1thodfnSizPzSM8PZ24rCyvputLDIfXDEljbiK8QwdKFi3yaXjfUVND6fIXiRk4kJgLLvBKmuHJyUT37Ru0k4IqpSic8TjKZqPjvLkeDZo3aJz4yy4lPC3Nq9NG1f/0E9Xbt5N04+g2zewSKFrk8ERkuIj8ICL7ROQxN/uzRaRCRHbrfzO9LzUwmMxmUifcTc2uXVR/ssNn+Rz96wrsJaWkTfas7a4hcVlDqf36a2ylpV5Jr+abb9k37AqK583DWuzZOriW1Wuo3r6d9g8/RGSXLl7RZ/BrJCKCpBtHU/3Rx15bN8KyejWEhbUpIBhIpLlSi4iEAXuBYUA+8G9grFJqj8sx2cBDSqmrW5rxgAED1M4GwQCr1Up+fj61QbIQyQmUwnrkCGIyEZ6WRlRUFJmZmUR4qXG9du9eDt4wmrjsbDIXL/JKmifS3rOH/15/Axnz5pF03bUepeWoreW/N4zGduQIjuPHtSUCb7yRlPF3EJGR0aq06n/+mQOjriWmX1/OeOklj2cJMWgaa2Eh+353OSnjx9N+yh89SstRX8++rGxiBgzw+v3qDUTkC6WU28U0WlIWHQTsU0od0BPLBUYBe5o8qw3k5+cTHx9P165dg262E1t6OtaCAiI6dcJSX09+fj7dunXzOF1ltVLw2GOY4uNJf2KWF5SejLlXL8LT0qjats1jh1fyv4uo37+fM156icgunSlbvpzyvDzKV68m6frrSbnzTiIzOzWbjnI4KJw6DTGZyJgzx3B2fiAiI4O47Gwsb72ljc32oM/csfc/wF5eTlIIBSuctORO6wS4LiWUr3/XkMEi8qWIbBSRNvUara2tJSUlJeicHWizyUpkJPYjR2jXrp3XSqGly16kbs93pD8xi/CUFK+k6YqIEJs1lOrt21FWa5vTOb5zJ0dfe42ksTnEDbmYyDPOIGP2bLq/v4mk0TdQ8fbb7B8+nILp06k/dKjJtMpXruT4zp10mDaNiI4d26zJoHUk54zBXlbGsS1bPEqnPC+XiM6diR082EvK/EdLHJ4779OwHrwL6KKU6gssBtyOWBaRu0Rkp4jsLCkpcZ9ZEDo74ER11lFbi6qq8kqaNd98S+myZST8/hoSrrjCK2m6Iy4rC0dVFcf/07Y1ax3V1RRMnUZEZiYdHnropH0RnTqRMWsWZ/7jA5LHjqVy/d/ZP2IkBY8+6nYhlroDBzjy5+eIy84m0cMSp0HriB0yhIhOnTyaNqp2715qdn5B8pgxIVkyb4nifMC1V2EmUOB6gFKqUilVpX/eAESISGrDhJRSy5VSA5RSA9LS0jyQ7Ttqa2sZNGgQffv2pXfv3sya9Us101nKsx05Ah5GbB11dRQ89ijhKSmkT/ft5Jaxgy8CD9asLX7mGaz5+XScNxdTbKzbYyLS00mfPo3um/9Bu1tvpfKDf3Dgqqs4POVB6n78EdAXxnlsKqaoKNKfejJoX26nKmIykTRmDMc//5y6AwfalIYlbzUSGUmiH2aD9gUtcXj/BnqISDcRiQRygPdcDxCRdNHvXhEZpKdb5m2x/sBsNvPhhx/y5Zdfsnv3bjZt2sSnn34KaKXP8PbtcdTWerzCe8miRdTv20/G03MIS0z0hvRGCYuLJWbA+VS3oXtK1fZPsKzKpd24ccQ0s6gyQHhaGh0efYTum/9Byvg7qNq6lQPX/J78yfdTPG8+tV99RfqsmT4Z5mTQPEk3XA8REZS/sQpHTU2r/mzl5VS8+y7xw68kPDk50D+lTTQbtFBK2UTkPuB9IAx4RSn1rYhM0PcvA0YD94iIDagBclSITrcrIsTFxQFa1NhqtZ5UEglLTMRWUoK9rAxlt7ep79jxXbs4+sqrJN10E3GXXOI17U0RNzRLm1Tz8GEiOjUfWACwV1ZSOGMGkWeeSdoD97cqv/CUFNo/+CDtbr+doytWUL7ydRxVVcSPGO61KcANWk94SgoJw4ZR/vrrlL/+epvSSB4TesEKJ812S/EV7rqlfPfdd/TSVycqmjuXuu+8u6CwudfZpE+b1uxxdrud888/n3379jFx4kQWLFhw8v6KCr7duZMux2tIvKbFPXEAcBw/zoFrrwO7nW7vvktYnPsqorepO/BfDowcSYeZj7d4DYWCx6ZSsW4dXXNXEX3uuR7lb6+s5NjmLcQPu7zV65UaeBdrURGVf98AqvVjrMNSU7X1b4O4OcLTbimnHWFhYezevRuLxcJ1113HN998wznn/LLsnCkhQZtrb8kSEkYMb1VP8yPPPIv1p5/ovOKvfnN2AJHduhJxxhlUb/uoRQ7v2JYtVKxdS+q993js7ADCEhL8sgqYQfNEpKeTcsftgZYREILW4bWkJOZrkpKSyM7OZtOmTSc5PBHBlJBA/cGDVKxb3+L+bdU7dlD+xhu0u/UWYgcN8pVst4gIcVlZWN58E0dtLaaoxpe+s5WXUzhzFuZevUidMMGPKg0MfEvoxZV9TElJCRZ94ZOamho2b97M2Wef/avjTFFRRP32t5S+8EKL+rfZjx2jYPoMIrt1I+2PnvV0bytxWUNRtbUcb2JCVKUURU88ib2yko7z53vUQdXAINgwHF4DCgsLufTSS+nTpw8DBw5k2LBhXH21+3a61MmTsP78M5a1zS+UUjxvPrbiYjrOn9dk6cqXxAwahERHNzl7SuWGDRx7/33SJk0iqudZflRnYOB7grZKGyj69OnDf1rYQTcuK4uovn0oXbqUpFGjGi0NHfvwn1S8/TYpd99NdN++3pTbKkxmM7EXXkjVtm0oNeNXDc/WI0coemo20X37knL7bQFSaWDgO4wSngeICGmTJmMrKMTSyIyyWnvYTMw9e5I68V4/K/w1cVlDsR4+TH2DjqdKKYoen4mqqyNj/ryQmvLHwKClGA7PQ2Ivvojo886jdNmLOOrqfrW/ePZs7BUVdFwwPygWOTmxZm2Dam3F229TtW0b7adMweyFSREMDIIRw+F5iIiQNnkytuJiLHmrT9pXuWEDlRs2kjbxXqLcBD4CQUTHjph79DhpUlDr4cMUz51HzKBBJP/h/wVQnYGBbwk6hxcKAzQaaoy98AJiBg2i9P+W46ipAcBWUkLRk08Rde65pIwfHwiZjRKXncXxL77AfuwYyuGgYPoMUIqMuXNDckC4gUFLCaq7OyoqirKysqB2ekopysrKiGoQaU2bPAl7SSnlq7SV3gsfn4mjtpaOC+YHXXtY3NChYLNRveNflL+xiuOffkr7qY+1aC47A4NQJqiexMzMTPLz82ls6qhgwTnjsSsxAwYQe9FFlL30EhIZSdXWrXSY+hjm3/wmQCobJ7p/f0wJCZSvWkXN7t3EDr0k5KbqNjBoC0Hl8CIiIrwyi3CgSJs8iYM5YymeM4eYgQNJvvnmQEtyi7Zm7cVUbtiIKTGRjNlzgnpspIGBtwiqKm2oE92vH3HZ2ZhiYsiY+3RQt4fFXXoZAOkzphPRwZiqyeD0IKhKeKcCnf7yHHaLhYj09EBLaZKEq0ZiPqsHUT17BlqKgYHfMByelzFFRWEKcmcH2uy3hrMzON0I2Hx4IlICNL3ay69JBbyzwKrnGFoaJ5j0GFrccypr6aKUcruGRMAcXlsQkZ2NTeznbwwtjRNMegwt7jldtQRvq7qBgYGBlzEcnoGBwWlDqDm85YEW4IKhpXGCSY+hxT2npZaQasMzMDAw8IRQK+EZGBgYtBnD4bUAMcZdNYphm5Mx7OGeYLFLUDk8EUkXkaDQJCLdRWQkQKAXFQ8mu0DQ2ab1K6H7CBFJCLQ9nBh2cU9QPEQiEiEizwMfAy+KyE0B1BIjIguBNUBgVtv5RUvQ2EXXEzS20fXMBBaLSMCnehGRB4AvRWRgEGgx7NIIwTK07Bqgs1Kqh4hcBSwUka+UUt/7U4SIxAN5QAelVH9/5t0IQWEXCD7biMh04CLgBeBBEekMrFBK+XX0gIj0At4CPgOGK6V+8Gf+bvQYdmmCgJbwXOr1NvShJUqpvwPrgAkikuxnSbXA34CvdX0XisiVItJD3/aLvYLQLhAkttHzCgeGAo8opd4DHgfSgbH+0uBCKdAemKaU+kFEMkXE7bAmX2PYpXn87vD0iwKc1P5jBspExDnl7p+APvqfzxo8G7ZzKKWswD+BOhEpAhYClwPbRKSfUsrhQy0nboZA20VPu6OIZLtoCohtGqYpIiallA34ll8e5B3A50BvEfHZ4iFutIQppUqAvwArXKr7K0RkvIi0d3eej7QFzC5utASNXRri17eyiDwDPCsilzfYvRU4G+gnImalVBmwBZgC3m8Y17XMBeaKyLAGuwuBVcCzSqlLlFIPo1UPnvGRljAReQrYISJdGuzeih/t4qJnNnAAuEn/zvmS8qttdKJdtIlSyqFvbgQyRKS3/qB/DVQAHX2gwcmJZef0h9UBoJSaAyQBUUqpwcAy4FwgS9/vi+t0vojEObcDaRcRuVNEhuqfA2qX5vBnFW0RWvH6c+BREZkoImYA/W2wAbgO6KeflgeUiohX1zYUkSzgCyAZ2As87Xqx9IvwL6XUQpfT3gCOiUj0rxL0TMslwI9APHCJUuqQy74wf9pFz/Nq4BtAgAnAQACllC0AtvmdiGwHlojIH3QdyqXqvBf4L3Czvu8HtJdDmn6+10oPInKFiGxECwQ481O6HufLYIRSapK+7120Bz3ZB1p+JyIfA+MBdw7Dn3a5TEQ2A3OA4Xp+AbFLS/FXCS8e7YG9Ryn1N7QSwVnAjc4DlFJL0S7UIyLyENqDfUgpVe9lLQ7gGaXUPUqpl4F/oV8sFy0nFpgVkUHAK8C/lVI1XtZSCcQrpf6olCoSkW4ikqRrsOv//WUXgGPAOKXUDLQqSKHo0TXn29gfthGRdmgP0V+AFcBoEXlc323SdRwC1gPniMgU3W4RQJWrXg80iF4TeASYCzyPVuIeISKjnMfppShcgwK6/hSgwItawkTkXuB1YIl+/1Y797vo8bVdTCISKVrvgSfRrtF8wKnFeX18bpc2oZTyyx9aSWCS/jkOGAcsATq6HBMFDAH+F7jFRzpi0NrGwvTtscCf9M/iclws8BCwGxjrQ7ssB1YDL6I9UO8DNwCJ/rSLG13dgbVAT33b5EvboDkyk/75HN0uzmvUAygDMvRts8t5/YBXga+A2T7QMhbo4XLfLgRudDnWOTwzDO3F/pxul6k+0HIr8Ge0SDnASLTSUri+HelHu1zu8v0VwI8NjvWpXdr8G/yWkVaae9nlpj1Pv3h99O2LgWi/GwBeQ3fELt9drF/cs/yQfyLwPTBL375Nd2yXBdIuet7/BB72tW3031wAzNG3u6K1PXVwOeZ54K0G58Xr/yO9ZSMXLXP17Wj990bo228At7k5L0b/fxeQ6iMtaWilqnXAHrQXUp7Tbn6yy9MNvg8HMoA3gUH+sIsnf/6M0m5He0uPA1BK7QIGAVEicgHaW1z5q16vVxFMQAe0djJEpKeIXAP8Bu0G3+trHUqpCiBLKfWkvv0qmi0iRWQwWtXfb3aBk6LXK4GuzvYY0aK2PfCibfSG91HAAmCkiPRUSh0EdqFVl5xMAzLll24w9wITAZRS9coLVeoGWoaLSHelVI1SyqGUsurtplHAvxucNwmYrGtZrrzQ582NlrOU1qb7CXAQrWR9LVrV/xoROUc/z9d2GSEi3fXvw5VWdQ1HezFU6t+Lixav2sVj/Old0TpEfoRW2usKfAj0D4SnR2uYN6M91NcDf0erVqYE8g0EnAlsBs4LpA5dy23Acpdtk4/y6az/nw/k6Z9jgRJgsL4djlbNdR7rk1JvAy1/a7CvPbBJ/9wJGK1/jvKDllXOawAkuBwTgVZLcdaU/GGXN1y+d1ZdNwLTXe8TX2nx6Hf4PUMYgdbQ/T1wX0B/PFyIFsTYDtwRQB2C1pi7AtgJ3BXoG0PX1R/Yj0vbkI/zc0bxr9K3J+ovotuAWWi99tv5WcsVLt9dgBbkuh/4j/P+xaXt18dartS3w1z2TddfkAGxC3p7Klr74lJ/3Stt1h+QTLW3UnjAfzxkAlNxaQQPoJY44O5g0KLrcb65/XqddBt87LI9Aq3D9d+AMwKgZZvL9gOAFa0/WaC1XAVsQ2tT7BRILfp396J1ZQrzp5bW/hkTgBoEDaKNFnCIyJtAEVrp+yXga+XnG9WNlqNAPvBgmkW9AAAAwElEQVS9UuqjAGopROtishstMrorgFoK0JoalgJ7lN6VKpgJitlSDAxAGy0gIjFobWVjgH1Kqa/87ezcaMkBypTW8O5XZ+dGy1igUCmV529n14iW75VSX4eCs4PgmS3FwMDJvWgR2mHKpZOzocXQ4g2MKq1BUOGsMgVaBxhaGiOYtLQWw+EZGBicNhhteAYGBqcNhsMzMDA4bTAcnoGBwWmD4fAMDAxOGwyHZ2BgcNpgODwDA4PTBsPhGRgYnDb8f/XtwYlU4KXGAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "x_test_scaled = x_scaler.fit_transform(x_test)\n",
    "plt.figure(figsize=(5,5))\n",
    "pd.DataFrame(x_test_scaled).plot(subplots=True, figsize=(5,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a separate scaler-object for the target-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x360 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"285.714315pt\" version=\"1.1\" viewBox=\"0 0 316.303125 285.714315\" width=\"316.303125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 285.714315 \r\nL 316.303125 285.714315 \r\nL 316.303125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 252 \r\nL 309.103125 252 \r\nL 309.103125 7.2 \r\nL 30.103125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m6d88ba116e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.784943\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.972589 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.012216\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(63.199862 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.239489\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(98.427135 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.466761\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(133.654407 273.532002)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.694034\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10.0 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(163.371593 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.921307\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12.5 -->\r\n      <g transform=\"translate(198.598866 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.14858\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15.0 -->\r\n      <g transform=\"translate(233.826139 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.375852\" xlink:href=\"#m6d88ba116e\" y=\"252\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 17.5 -->\r\n      <g transform=\"translate(269.053412 276.713252)rotate(-30)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"ma57671ecfd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma57671ecfd\" y=\"212.040727\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(7.2 215.839946)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma57671ecfd\" y=\"167.363491\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 171.16271)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma57671ecfd\" y=\"122.686255\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.7 -->\r\n      <g transform=\"translate(7.2 126.485473)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma57671ecfd\" y=\"78.009018\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 81.808237)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma57671ecfd\" y=\"33.331782\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.9 -->\r\n      <defs>\r\n       <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 37.131001)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p28b3c7de93)\" d=\"M 42.784943 52.945455 \r\nL 56.875852 92.509091 \r\nL 70.966761 102.4 \r\nL 85.05767 141.963636 \r\nL 99.14858 206.254545 \r\nL 113.239489 151.854545 \r\nL 127.330398 191.418182 \r\nL 141.421307 92.509091 \r\nL 155.512216 18.327273 \r\nL 169.603125 132.072727 \r\nL 183.694034 240.872727 \r\nL 197.784943 156.8 \r\nL 211.875852 122.181818 \r\nL 225.966761 151.854545 \r\nL 240.05767 240.872727 \r\nL 254.14858 102.4 \r\nL 268.239489 171.636364 \r\nL 282.330398 240.872727 \r\nL 296.421307 102.4 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 252 \r\nL 30.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 309.103125 252 \r\nL 309.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 252 \r\nL 309.103125 252 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 7.2 \r\nL 309.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 263.740625 29.878125 \r\nL 302.103125 29.878125 \r\nQ 304.103125 29.878125 304.103125 27.878125 \r\nL 304.103125 14.2 \r\nQ 304.103125 12.2 302.103125 12.2 \r\nL 263.740625 12.2 \r\nQ 261.740625 12.2 261.740625 14.2 \r\nL 261.740625 27.878125 \r\nQ 261.740625 29.878125 263.740625 29.878125 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\">\r\n     <path d=\"M 265.740625 20.298437 \r\nL 285.740625 20.298437 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\"/>\r\n    <g id=\"text_14\">\r\n     <!-- 0 -->\r\n     <g transform=\"translate(293.740625 23.798437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-48\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p28b3c7de93\">\r\n   <rect height=\"244.8\" width=\"279\" x=\"30.103125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.fit_transform(y_test)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "pd.DataFrame(y_test_scaled).plot(subplots=True, figsize=(5,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(169, 4)\n(169, 1)\n(19, 4)\n(19, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_scaled.shape)\n",
    "print(y_train_scaled.shape)\n",
    "print(x_test_scaled.shape)\n",
    "print(y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training the Recurrent Neural Network on the complete sequences of almost 300k observations, we will use the following function to create a batch of shorter sub-sequences picked at random from the training-data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "The data-set has now been prepared as 2-dimensional numpy arrays. The training-data has almost 2k+ observations, consisting of 11 input-signals and 11 output-signals.\n",
    "\n",
    "These are the array-shapes of the input and output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "neur = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compile the Keras model so it is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# del model\n",
    "#filter is also called a kernel specify\n",
    "model = Sequential()\n",
    "model.add(Dense(neur, input_shape=(num_x_signals,), activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(neur, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "#last layer is called the classification layer. We mostly use probability functions like softmax or relu for activation\n",
    "model.add(Dense(num_y_signals, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_100 (Dense)            (None, 512)               2560      \n_________________________________________________________________\ndense_101 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_102 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_103 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_104 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_105 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_106 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_107 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_108 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_109 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_110 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_111 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_112 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_113 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_114 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_115 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_116 (Dense)            (None, 512)               262656    \n_________________________________________________________________\ndense_117 (Dense)            (None, 1)                 513       \n=================================================================\nTotal params: 4,205,569\nTrainable params: 4,205,569\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Wrapping the black box\n",
    "model.compile(loss='mean_squared_error', \n",
    "            optimizer='Adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very small model with only two layers. The output shape of `(None, None, 3)` means that the model will output a batch with an arbitrary number of sequences, each of which has an arbitrary number of observations, and each observation has 3 signals. This corresponds to the 3 target signals we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Functions\n",
    "\n",
    "During training we want to save checkpoints and log the progress to TensorBoard so we create the appropriate callbacks for Keras.\n",
    "\n",
    "This is the callback for writing checkpoints during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = r'E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the callback for stopping the optimization when performance worsens on the validation-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the callback for writing the TensorBoard log during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_tensorboard = TensorBoard(log_dir=r'E:\\OneDrive\\AI\\logs',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This callback reduces the learning-rate for the optimizer if the validation-loss has not improved since the last epoch (as indicated by `patience=0`). The learning-rate will be reduced by multiplying it with the given factor. We set a start learning-rate of 1e-3 above, so multiplying it by 0.1 gives a learning-rate of 1e-4. We don't want the learning-rate to go any lower than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.99,\n",
    "                                       min_lr=1e-9,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard,\n",
    "             callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Recurrent Neural Network\n",
    "\n",
    "We can now train the neural network.\n",
    "\n",
    "Note that a single \"epoch\" does not correspond to a single processing of the training-set, because of how the batch-generator randomly selects sub-sequences from the training-set. Instead we have selected `steps_per_epoch` so that one \"epoch\" is processed in a few minutes.\n",
    "\n",
    "With these settings, each \"epoch\" took aa few minutes to process on a GTX 1060."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath =r'E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_Prediction_model.h5'\n",
    "def train_model(resume,fit_generator,epochs,initial_epoch,batch_size,model):\n",
    "    def fit_model():\n",
    "        if fit_generator:       \n",
    "            print('Using fit_generator')\n",
    "            history=model.fit(train_generator,\n",
    "                    initial_epoch=initial_epoch,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=50,\n",
    "                    callbacks=callbacks)\n",
    "            model.save(filepath)\n",
    "            model.evaluate(validation_generator, steps=50)\n",
    "        else:\n",
    "            print('Using fit')\n",
    "            history=model.fit(x_train_scaled, y_train_scaled, \n",
    "                    epochs=epochs,\n",
    "                    #initial_epoch=initial_epoch,\n",
    "                    verbose=1,\n",
    "                    #batch_size=batch_size,\n",
    "                    #steps_per_epoch=steps_per_epoch,\n",
    "                    shuffle=True,\n",
    "                    #validation_data=validation_data,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=8)\n",
    "            model.save(filepath)\n",
    "            #model.evaluate(validation_data[0],validation_data[1])\n",
    "        return history\n",
    "    \n",
    "    if resume:\n",
    "        try:\n",
    "            #model = load_model(filepath)\n",
    "            model.load_weights(path_checkpoint)\n",
    "            print(model.summary())\n",
    "            print(\"Model loading....\")\n",
    "            model.evaluate(validation_generator, steps=50)\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(\"Error trying to load checkpoint.\")\n",
    "            print(error)\n",
    "\n",
    "            \n",
    "    def plot_train_history(history, title):\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        epochs = range(len(loss))\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    # Training the Model\n",
    "    history = fit_model()\n",
    "    plot_train_history(history, 'Model Training History ')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using fit\n",
      "Epoch 1/1000\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 0.4504WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.309041). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.4628 - val_loss: 0.4830 - lr: 1.0000e-06\n",
      "Epoch 2/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4404\n",
      "Epoch 00002: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4827 - lr: 1.0000e-06\n",
      "Epoch 3/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4426\n",
      "Epoch 00003: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4587 - val_loss: 0.4824 - lr: 1.0000e-06\n",
      "Epoch 4/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4634\n",
      "Epoch 00004: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4603 - val_loss: 0.4820 - lr: 1.0000e-06\n",
      "Epoch 5/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4979\n",
      "Epoch 00005: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4454 - val_loss: 0.4817 - lr: 1.0000e-06\n",
      "Epoch 6/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4404\n",
      "Epoch 00006: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4494 - val_loss: 0.4814 - lr: 1.0000e-06\n",
      "Epoch 7/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4645\n",
      "Epoch 00007: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4493 - val_loss: 0.4810 - lr: 1.0000e-06\n",
      "Epoch 8/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4492\n",
      "Epoch 00008: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4522 - val_loss: 0.4807 - lr: 1.0000e-06\n",
      "Epoch 9/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4315\n",
      "Epoch 00009: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4515 - val_loss: 0.4803 - lr: 1.0000e-06\n",
      "Epoch 10/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4608\n",
      "Epoch 00010: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4557 - val_loss: 0.4800 - lr: 1.0000e-06\n",
      "Epoch 11/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4738\n",
      "Epoch 00011: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4636 - val_loss: 0.4796 - lr: 1.0000e-06\n",
      "Epoch 12/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5103\n",
      "Epoch 00012: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4303 - val_loss: 0.4793 - lr: 1.0000e-06\n",
      "Epoch 13/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4241\n",
      "Epoch 00013: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4393 - val_loss: 0.4789 - lr: 1.0000e-06\n",
      "Epoch 14/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4024\n",
      "Epoch 00014: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4493 - val_loss: 0.4786 - lr: 1.0000e-06\n",
      "Epoch 15/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4059\n",
      "Epoch 00015: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4672 - val_loss: 0.4782 - lr: 1.0000e-06\n",
      "Epoch 16/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5052\n",
      "Epoch 00016: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4334 - val_loss: 0.4779 - lr: 1.0000e-06\n",
      "Epoch 17/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4725\n",
      "Epoch 00017: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4456 - val_loss: 0.4775 - lr: 1.0000e-06\n",
      "Epoch 18/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4164\n",
      "Epoch 00018: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4429 - val_loss: 0.4772 - lr: 1.0000e-06\n",
      "Epoch 19/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4626\n",
      "Epoch 00019: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4422 - val_loss: 0.4768 - lr: 1.0000e-06\n",
      "Epoch 20/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4563\n",
      "Epoch 00020: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4441 - val_loss: 0.4764 - lr: 1.0000e-06\n",
      "Epoch 21/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4535\n",
      "Epoch 00021: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4603 - val_loss: 0.4761 - lr: 1.0000e-06\n",
      "Epoch 22/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4636\n",
      "Epoch 00022: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4482 - val_loss: 0.4757 - lr: 1.0000e-06\n",
      "Epoch 23/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4369\n",
      "Epoch 00023: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4562 - val_loss: 0.4753 - lr: 1.0000e-06\n",
      "Epoch 24/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4498\n",
      "Epoch 00024: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4433 - val_loss: 0.4750 - lr: 1.0000e-06\n",
      "Epoch 25/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4642\n",
      "Epoch 00025: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4539 - val_loss: 0.4746 - lr: 1.0000e-06\n",
      "Epoch 26/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4179\n",
      "Epoch 00026: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4411 - val_loss: 0.4742 - lr: 1.0000e-06\n",
      "Epoch 27/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4476\n",
      "Epoch 00027: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4417 - val_loss: 0.4738 - lr: 1.0000e-06\n",
      "Epoch 28/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4426\n",
      "Epoch 00028: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4478 - val_loss: 0.4735 - lr: 1.0000e-06\n",
      "Epoch 29/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4300\n",
      "Epoch 00029: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4305 - val_loss: 0.4731 - lr: 1.0000e-06\n",
      "Epoch 30/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4194\n",
      "Epoch 00030: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4418 - val_loss: 0.4727 - lr: 1.0000e-06\n",
      "Epoch 31/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4562\n",
      "Epoch 00031: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4346 - val_loss: 0.4723 - lr: 1.0000e-06\n",
      "Epoch 32/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4113\n",
      "Epoch 00032: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4418 - val_loss: 0.4719 - lr: 1.0000e-06\n",
      "Epoch 33/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4923\n",
      "Epoch 00033: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4407 - val_loss: 0.4715 - lr: 1.0000e-06\n",
      "Epoch 34/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4470\n",
      "Epoch 00034: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4511 - val_loss: 0.4711 - lr: 1.0000e-06\n",
      "Epoch 35/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4215\n",
      "Epoch 00035: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4468 - val_loss: 0.4707 - lr: 1.0000e-06\n",
      "Epoch 36/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4315\n",
      "Epoch 00036: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4292 - val_loss: 0.4704 - lr: 1.0000e-06\n",
      "Epoch 37/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4506\n",
      "Epoch 00037: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4280 - val_loss: 0.4700 - lr: 1.0000e-06\n",
      "Epoch 38/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3694\n",
      "Epoch 00038: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4427 - val_loss: 0.4696 - lr: 1.0000e-06\n",
      "Epoch 39/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4223\n",
      "Epoch 00039: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4498 - val_loss: 0.4692 - lr: 1.0000e-06\n",
      "Epoch 40/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4372\n",
      "Epoch 00040: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4340 - val_loss: 0.4688 - lr: 1.0000e-06\n",
      "Epoch 41/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4697\n",
      "Epoch 00041: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4176 - val_loss: 0.4684 - lr: 1.0000e-06\n",
      "Epoch 42/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4288\n",
      "Epoch 00042: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4406 - val_loss: 0.4680 - lr: 1.0000e-06\n",
      "Epoch 43/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4298\n",
      "Epoch 00043: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4350 - val_loss: 0.4676 - lr: 1.0000e-06\n",
      "Epoch 44/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4190\n",
      "Epoch 00044: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4411 - val_loss: 0.4671 - lr: 1.0000e-06\n",
      "Epoch 45/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4678\n",
      "Epoch 00045: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4305 - val_loss: 0.4667 - lr: 1.0000e-06\n",
      "Epoch 46/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4001\n",
      "Epoch 00046: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4440 - val_loss: 0.4663 - lr: 1.0000e-06\n",
      "Epoch 47/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4554\n",
      "Epoch 00047: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4368 - val_loss: 0.4659 - lr: 1.0000e-06\n",
      "Epoch 48/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3895\n",
      "Epoch 00048: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4342 - val_loss: 0.4655 - lr: 1.0000e-06\n",
      "Epoch 49/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4522\n",
      "Epoch 00049: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4339 - val_loss: 0.4651 - lr: 1.0000e-06\n",
      "Epoch 50/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4354\n",
      "Epoch 00050: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4513 - val_loss: 0.4647 - lr: 1.0000e-06\n",
      "Epoch 51/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4538\n",
      "Epoch 00051: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4346 - val_loss: 0.4642 - lr: 1.0000e-06\n",
      "Epoch 52/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4343\n",
      "Epoch 00052: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4505 - val_loss: 0.4638 - lr: 1.0000e-06\n",
      "Epoch 53/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4254\n",
      "Epoch 00053: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4402 - val_loss: 0.4634 - lr: 1.0000e-06\n",
      "Epoch 54/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4412\n",
      "Epoch 00054: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4496 - val_loss: 0.4629 - lr: 1.0000e-06\n",
      "Epoch 55/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4380\n",
      "Epoch 00055: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4295 - val_loss: 0.4625 - lr: 1.0000e-06\n",
      "Epoch 56/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3679\n",
      "Epoch 00056: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4431 - val_loss: 0.4620 - lr: 1.0000e-06\n",
      "Epoch 57/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4397\n",
      "Epoch 00057: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4238 - val_loss: 0.4616 - lr: 1.0000e-06\n",
      "Epoch 58/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4436\n",
      "Epoch 00058: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4177 - val_loss: 0.4612 - lr: 1.0000e-06\n",
      "Epoch 59/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4467\n",
      "Epoch 00059: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4313 - val_loss: 0.4607 - lr: 1.0000e-06\n",
      "Epoch 60/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4650\n",
      "Epoch 00060: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4320 - val_loss: 0.4603 - lr: 1.0000e-06\n",
      "Epoch 61/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4172\n",
      "Epoch 00061: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4286 - val_loss: 0.4598 - lr: 1.0000e-06\n",
      "Epoch 62/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4706\n",
      "Epoch 00062: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4248 - val_loss: 0.4594 - lr: 1.0000e-06\n",
      "Epoch 63/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4703\n",
      "Epoch 00063: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4335 - val_loss: 0.4589 - lr: 1.0000e-06\n",
      "Epoch 64/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4333\n",
      "Epoch 00064: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4326 - val_loss: 0.4585 - lr: 1.0000e-06\n",
      "Epoch 65/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4328\n",
      "Epoch 00065: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4436 - val_loss: 0.4580 - lr: 1.0000e-06\n",
      "Epoch 66/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3986\n",
      "Epoch 00066: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4094 - val_loss: 0.4576 - lr: 1.0000e-06\n",
      "Epoch 67/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4393\n",
      "Epoch 00067: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4375 - val_loss: 0.4571 - lr: 1.0000e-06\n",
      "Epoch 68/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4616\n",
      "Epoch 00068: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4089 - val_loss: 0.4566 - lr: 1.0000e-06\n",
      "Epoch 69/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4117\n",
      "Epoch 00069: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4481 - val_loss: 0.4562 - lr: 1.0000e-06\n",
      "Epoch 70/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4269\n",
      "Epoch 00070: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4221 - val_loss: 0.4557 - lr: 1.0000e-06\n",
      "Epoch 71/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3995\n",
      "Epoch 00071: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.4319 - val_loss: 0.4552 - lr: 1.0000e-06\n",
      "Epoch 72/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4059\n",
      "Epoch 00072: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4180 - val_loss: 0.4548 - lr: 1.0000e-06\n",
      "Epoch 73/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4301\n",
      "Epoch 00073: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4192 - val_loss: 0.4543 - lr: 1.0000e-06\n",
      "Epoch 74/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4236\n",
      "Epoch 00074: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4240 - val_loss: 0.4538 - lr: 1.0000e-06\n",
      "Epoch 75/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4198\n",
      "Epoch 00075: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4256 - val_loss: 0.4533 - lr: 1.0000e-06\n",
      "Epoch 76/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3935\n",
      "Epoch 00076: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4286 - val_loss: 0.4528 - lr: 1.0000e-06\n",
      "Epoch 77/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4126\n",
      "Epoch 00077: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4314 - val_loss: 0.4523 - lr: 1.0000e-06\n",
      "Epoch 78/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3980\n",
      "Epoch 00078: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4225 - val_loss: 0.4518 - lr: 1.0000e-06\n",
      "Epoch 79/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4247\n",
      "Epoch 00079: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4226 - val_loss: 0.4513 - lr: 1.0000e-06\n",
      "Epoch 80/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4227\n",
      "Epoch 00080: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4284 - val_loss: 0.4508 - lr: 1.0000e-06\n",
      "Epoch 81/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4458\n",
      "Epoch 00081: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4338 - val_loss: 0.4503 - lr: 1.0000e-06\n",
      "Epoch 82/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4333\n",
      "Epoch 00082: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4211 - val_loss: 0.4498 - lr: 1.0000e-06\n",
      "Epoch 83/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4474\n",
      "Epoch 00083: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4123 - val_loss: 0.4493 - lr: 1.0000e-06\n",
      "Epoch 84/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4416\n",
      "Epoch 00084: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4112 - val_loss: 0.4488 - lr: 1.0000e-06\n",
      "Epoch 85/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4474\n",
      "Epoch 00085: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4149 - val_loss: 0.4483 - lr: 1.0000e-06\n",
      "Epoch 86/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4377\n",
      "Epoch 00086: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4206 - val_loss: 0.4478 - lr: 1.0000e-06\n",
      "Epoch 87/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4202\n",
      "Epoch 00087: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4076 - val_loss: 0.4473 - lr: 1.0000e-06\n",
      "Epoch 88/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4077\n",
      "Epoch 00088: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4252 - val_loss: 0.4468 - lr: 1.0000e-06\n",
      "Epoch 89/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4509\n",
      "Epoch 00089: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4226 - val_loss: 0.4462 - lr: 1.0000e-06\n",
      "Epoch 90/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4199\n",
      "Epoch 00090: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4057 - val_loss: 0.4457 - lr: 1.0000e-06\n",
      "Epoch 91/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4448\n",
      "Epoch 00091: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4141 - val_loss: 0.4452 - lr: 1.0000e-06\n",
      "Epoch 92/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4158\n",
      "Epoch 00092: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4231 - val_loss: 0.4446 - lr: 1.0000e-06\n",
      "Epoch 93/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3947\n",
      "Epoch 00093: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4126 - val_loss: 0.4441 - lr: 1.0000e-06\n",
      "Epoch 94/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3776\n",
      "Epoch 00094: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4079 - val_loss: 0.4436 - lr: 1.0000e-06\n",
      "Epoch 95/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4073\n",
      "Epoch 00095: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4199 - val_loss: 0.4430 - lr: 1.0000e-06\n",
      "Epoch 96/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4360\n",
      "Epoch 00096: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4219 - val_loss: 0.4425 - lr: 1.0000e-06\n",
      "Epoch 97/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4296\n",
      "Epoch 00097: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4043 - val_loss: 0.4419 - lr: 1.0000e-06\n",
      "Epoch 98/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4039\n",
      "Epoch 00098: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4190 - val_loss: 0.4414 - lr: 1.0000e-06\n",
      "Epoch 99/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4286\n",
      "Epoch 00099: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4141 - val_loss: 0.4408 - lr: 1.0000e-06\n",
      "Epoch 100/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4059\n",
      "Epoch 00100: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4115 - val_loss: 0.4403 - lr: 1.0000e-06\n",
      "Epoch 101/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4081\n",
      "Epoch 00101: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4082 - val_loss: 0.4397 - lr: 1.0000e-06\n",
      "Epoch 102/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4219\n",
      "Epoch 00102: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4257 - val_loss: 0.4391 - lr: 1.0000e-06\n",
      "Epoch 103/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3922\n",
      "Epoch 00103: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4094 - val_loss: 0.4386 - lr: 1.0000e-06\n",
      "Epoch 104/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4195\n",
      "Epoch 00104: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4046 - val_loss: 0.4380 - lr: 1.0000e-06\n",
      "Epoch 105/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3912\n",
      "Epoch 00105: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4082 - val_loss: 0.4374 - lr: 1.0000e-06\n",
      "Epoch 106/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4145\n",
      "Epoch 00106: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4125 - val_loss: 0.4368 - lr: 1.0000e-06\n",
      "Epoch 107/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4745\n",
      "Epoch 00107: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4095 - val_loss: 0.4362 - lr: 1.0000e-06\n",
      "Epoch 108/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4049\n",
      "Epoch 00108: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4088 - val_loss: 0.4357 - lr: 1.0000e-06\n",
      "Epoch 109/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4274\n",
      "Epoch 00109: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4038 - val_loss: 0.4351 - lr: 1.0000e-06\n",
      "Epoch 110/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4312\n",
      "Epoch 00110: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3990 - val_loss: 0.4345 - lr: 1.0000e-06\n",
      "Epoch 111/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3998\n",
      "Epoch 00111: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4081 - val_loss: 0.4339 - lr: 1.0000e-06\n",
      "Epoch 112/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4301\n",
      "Epoch 00112: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4076 - val_loss: 0.4333 - lr: 1.0000e-06\n",
      "Epoch 113/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3977\n",
      "Epoch 00113: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4076 - val_loss: 0.4327 - lr: 1.0000e-06\n",
      "Epoch 114/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3729\n",
      "Epoch 00114: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4059 - val_loss: 0.4320 - lr: 1.0000e-06\n",
      "Epoch 115/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4044\n",
      "Epoch 00115: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.3882 - val_loss: 0.4314 - lr: 1.0000e-06\n",
      "Epoch 116/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4207\n",
      "Epoch 00116: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4190 - val_loss: 0.4308 - lr: 1.0000e-06\n",
      "Epoch 117/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3955\n",
      "Epoch 00117: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4053 - val_loss: 0.4302 - lr: 1.0000e-06\n",
      "Epoch 118/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3778\n",
      "Epoch 00118: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3978 - val_loss: 0.4295 - lr: 1.0000e-06\n",
      "Epoch 119/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3972\n",
      "Epoch 00119: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4154 - val_loss: 0.4289 - lr: 1.0000e-06\n",
      "Epoch 120/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3854\n",
      "Epoch 00120: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4091 - val_loss: 0.4282 - lr: 1.0000e-06\n",
      "Epoch 121/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3925\n",
      "Epoch 00121: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.4067 - val_loss: 0.4276 - lr: 1.0000e-06\n",
      "Epoch 122/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3986\n",
      "Epoch 00122: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.4063 - val_loss: 0.4269 - lr: 1.0000e-06\n",
      "Epoch 123/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4266\n",
      "Epoch 00123: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3938 - val_loss: 0.4262 - lr: 1.0000e-06\n",
      "Epoch 124/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3605\n",
      "Epoch 00124: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3929 - val_loss: 0.4255 - lr: 1.0000e-06\n",
      "Epoch 125/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4249\n",
      "Epoch 00125: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3875 - val_loss: 0.4249 - lr: 1.0000e-06\n",
      "Epoch 126/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3852\n",
      "Epoch 00126: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3961 - val_loss: 0.4242 - lr: 1.0000e-06\n",
      "Epoch 127/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3949\n",
      "Epoch 00127: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4142 - val_loss: 0.4235 - lr: 1.0000e-06\n",
      "Epoch 128/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3883\n",
      "Epoch 00128: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.3906 - val_loss: 0.4227 - lr: 1.0000e-06\n",
      "Epoch 129/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4024\n",
      "Epoch 00129: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3957 - val_loss: 0.4220 - lr: 1.0000e-06\n",
      "Epoch 130/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3649\n",
      "Epoch 00130: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3874 - val_loss: 0.4213 - lr: 1.0000e-06\n",
      "Epoch 131/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3887\n",
      "Epoch 00131: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3784 - val_loss: 0.4206 - lr: 1.0000e-06\n",
      "Epoch 132/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3725\n",
      "Epoch 00132: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3878 - val_loss: 0.4199 - lr: 1.0000e-06\n",
      "Epoch 133/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3881\n",
      "Epoch 00133: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3964 - val_loss: 0.4191 - lr: 1.0000e-06\n",
      "Epoch 134/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3998\n",
      "Epoch 00134: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3907 - val_loss: 0.4184 - lr: 1.0000e-06\n",
      "Epoch 135/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3877\n",
      "Epoch 00135: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3900 - val_loss: 0.4176 - lr: 1.0000e-06\n",
      "Epoch 136/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4310\n",
      "Epoch 00136: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3833 - val_loss: 0.4169 - lr: 1.0000e-06\n",
      "Epoch 137/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4454\n",
      "Epoch 00137: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3814 - val_loss: 0.4161 - lr: 1.0000e-06\n",
      "Epoch 138/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4003\n",
      "Epoch 00138: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3958 - val_loss: 0.4153 - lr: 1.0000e-06\n",
      "Epoch 139/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4158\n",
      "Epoch 00139: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3893 - val_loss: 0.4146 - lr: 1.0000e-06\n",
      "Epoch 140/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3714\n",
      "Epoch 00140: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3853 - val_loss: 0.4138 - lr: 1.0000e-06\n",
      "Epoch 141/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4155\n",
      "Epoch 00141: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3863 - val_loss: 0.4130 - lr: 1.0000e-06\n",
      "Epoch 142/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3874\n",
      "Epoch 00142: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3888 - val_loss: 0.4122 - lr: 1.0000e-06\n",
      "Epoch 143/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3791\n",
      "Epoch 00143: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3979 - val_loss: 0.4113 - lr: 1.0000e-06\n",
      "Epoch 144/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4284\n",
      "Epoch 00144: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.4105 - lr: 1.0000e-06\n",
      "Epoch 145/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3990\n",
      "Epoch 00145: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3806 - val_loss: 0.4097 - lr: 1.0000e-06\n",
      "Epoch 146/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3699\n",
      "Epoch 00146: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.3905 - val_loss: 0.4088 - lr: 1.0000e-06\n",
      "Epoch 147/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3667\n",
      "Epoch 00147: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3821 - val_loss: 0.4080 - lr: 1.0000e-06\n",
      "Epoch 148/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4242\n",
      "Epoch 00148: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3684 - val_loss: 0.4071 - lr: 1.0000e-06\n",
      "Epoch 149/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4121\n",
      "Epoch 00149: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3874 - val_loss: 0.4063 - lr: 1.0000e-06\n",
      "Epoch 150/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3679\n",
      "Epoch 00150: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3628 - val_loss: 0.4054 - lr: 1.0000e-06\n",
      "Epoch 151/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3662\n",
      "Epoch 00151: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3640 - val_loss: 0.4045 - lr: 1.0000e-06\n",
      "Epoch 152/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4087\n",
      "Epoch 00152: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3739 - val_loss: 0.4037 - lr: 1.0000e-06\n",
      "Epoch 153/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3739\n",
      "Epoch 00153: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3848 - val_loss: 0.4028 - lr: 1.0000e-06\n",
      "Epoch 154/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3945\n",
      "Epoch 00154: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.4019 - lr: 1.0000e-06\n",
      "Epoch 155/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3655\n",
      "Epoch 00155: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.4010 - lr: 1.0000e-06\n",
      "Epoch 156/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3382\n",
      "Epoch 00156: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3633 - val_loss: 0.4000 - lr: 1.0000e-06\n",
      "Epoch 157/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3643\n",
      "Epoch 00157: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3621 - val_loss: 0.3991 - lr: 1.0000e-06\n",
      "Epoch 158/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3706\n",
      "Epoch 00158: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.3714 - val_loss: 0.3982 - lr: 1.0000e-06\n",
      "Epoch 159/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3938\n",
      "Epoch 00159: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3582 - val_loss: 0.3972 - lr: 1.0000e-06\n",
      "Epoch 160/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3845\n",
      "Epoch 00160: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3733 - val_loss: 0.3963 - lr: 1.0000e-06\n",
      "Epoch 161/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3813\n",
      "Epoch 00161: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3654 - val_loss: 0.3953 - lr: 1.0000e-06\n",
      "Epoch 162/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3461\n",
      "Epoch 00162: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3592 - val_loss: 0.3944 - lr: 1.0000e-06\n",
      "Epoch 163/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3455\n",
      "Epoch 00163: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.3626 - val_loss: 0.3934 - lr: 1.0000e-06\n",
      "Epoch 164/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3548\n",
      "Epoch 00164: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3680 - val_loss: 0.3924 - lr: 1.0000e-06\n",
      "Epoch 165/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3864\n",
      "Epoch 00165: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3662 - val_loss: 0.3914 - lr: 1.0000e-06\n",
      "Epoch 166/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3672\n",
      "Epoch 00166: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3599 - val_loss: 0.3904 - lr: 1.0000e-06\n",
      "Epoch 167/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3931\n",
      "Epoch 00167: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3656 - val_loss: 0.3893 - lr: 1.0000e-06\n",
      "Epoch 168/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3806\n",
      "Epoch 00168: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3717 - val_loss: 0.3883 - lr: 1.0000e-06\n",
      "Epoch 169/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3889\n",
      "Epoch 00169: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3754 - val_loss: 0.3872 - lr: 1.0000e-06\n",
      "Epoch 170/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3674\n",
      "Epoch 00170: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3553 - val_loss: 0.3862 - lr: 1.0000e-06\n",
      "Epoch 171/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3316\n",
      "Epoch 00171: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3622 - val_loss: 0.3851 - lr: 1.0000e-06\n",
      "Epoch 172/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3358\n",
      "Epoch 00172: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3649 - val_loss: 0.3840 - lr: 1.0000e-06\n",
      "Epoch 173/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3411\n",
      "Epoch 00173: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3555 - val_loss: 0.3828 - lr: 1.0000e-06\n",
      "Epoch 174/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3697\n",
      "Epoch 00174: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3661 - val_loss: 0.3817 - lr: 1.0000e-06\n",
      "Epoch 175/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3603\n",
      "Epoch 00175: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3427 - val_loss: 0.3806 - lr: 1.0000e-06\n",
      "Epoch 176/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3101\n",
      "Epoch 00176: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.3527 - val_loss: 0.3794 - lr: 1.0000e-06\n",
      "Epoch 177/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3406\n",
      "Epoch 00177: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3502 - val_loss: 0.3782 - lr: 1.0000e-06\n",
      "Epoch 178/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3455\n",
      "Epoch 00178: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3621 - val_loss: 0.3771 - lr: 1.0000e-06\n",
      "Epoch 179/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3376\n",
      "Epoch 00179: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3538 - val_loss: 0.3759 - lr: 1.0000e-06\n",
      "Epoch 180/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3406\n",
      "Epoch 00180: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3556 - val_loss: 0.3746 - lr: 1.0000e-06\n",
      "Epoch 181/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3423\n",
      "Epoch 00181: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3502 - val_loss: 0.3734 - lr: 1.0000e-06\n",
      "Epoch 182/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3375\n",
      "Epoch 00182: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3576 - val_loss: 0.3722 - lr: 1.0000e-06\n",
      "Epoch 183/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3192\n",
      "Epoch 00183: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3470 - val_loss: 0.3709 - lr: 1.0000e-06\n",
      "Epoch 184/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3522\n",
      "Epoch 00184: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3421 - val_loss: 0.3696 - lr: 1.0000e-06\n",
      "Epoch 185/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3514\n",
      "Epoch 00185: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3403 - val_loss: 0.3683 - lr: 1.0000e-06\n",
      "Epoch 186/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3718\n",
      "Epoch 00186: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3324 - val_loss: 0.3670 - lr: 1.0000e-06\n",
      "Epoch 187/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3457\n",
      "Epoch 00187: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3415 - val_loss: 0.3657 - lr: 1.0000e-06\n",
      "Epoch 188/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3425\n",
      "Epoch 00188: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3341 - val_loss: 0.3643 - lr: 1.0000e-06\n",
      "Epoch 189/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3203\n",
      "Epoch 00189: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3449 - val_loss: 0.3629 - lr: 1.0000e-06\n",
      "Epoch 190/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3747\n",
      "Epoch 00190: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3337 - val_loss: 0.3616 - lr: 1.0000e-06\n",
      "Epoch 191/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3020\n",
      "Epoch 00191: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.3409 - val_loss: 0.3602 - lr: 1.0000e-06\n",
      "Epoch 192/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3461\n",
      "Epoch 00192: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3374 - val_loss: 0.3587 - lr: 1.0000e-06\n",
      "Epoch 193/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3511\n",
      "Epoch 00193: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3260 - val_loss: 0.3573 - lr: 1.0000e-06\n",
      "Epoch 194/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3448\n",
      "Epoch 00194: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3445 - val_loss: 0.3558 - lr: 1.0000e-06\n",
      "Epoch 195/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2983\n",
      "Epoch 00195: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3349 - val_loss: 0.3543 - lr: 1.0000e-06\n",
      "Epoch 196/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3338\n",
      "Epoch 00196: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3439 - val_loss: 0.3528 - lr: 1.0000e-06\n",
      "Epoch 197/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3162\n",
      "Epoch 00197: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3146 - val_loss: 0.3512 - lr: 1.0000e-06\n",
      "Epoch 198/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3260\n",
      "Epoch 00198: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3117 - val_loss: 0.3497 - lr: 1.0000e-06\n",
      "Epoch 199/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3238\n",
      "Epoch 00199: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3233 - val_loss: 0.3481 - lr: 1.0000e-06\n",
      "Epoch 200/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3269\n",
      "Epoch 00200: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3276 - val_loss: 0.3465 - lr: 1.0000e-06\n",
      "Epoch 201/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3401\n",
      "Epoch 00201: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3330 - val_loss: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 202/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3059\n",
      "Epoch 00202: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3095 - val_loss: 0.3433 - lr: 1.0000e-06\n",
      "Epoch 203/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3411\n",
      "Epoch 00203: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3156 - val_loss: 0.3416 - lr: 1.0000e-06\n",
      "Epoch 204/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3023\n",
      "Epoch 00204: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3150 - val_loss: 0.3399 - lr: 1.0000e-06\n",
      "Epoch 205/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3123\n",
      "Epoch 00205: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3087 - val_loss: 0.3383 - lr: 1.0000e-06\n",
      "Epoch 206/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3467\n",
      "Epoch 00206: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3128 - val_loss: 0.3365 - lr: 1.0000e-06\n",
      "Epoch 207/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3510\n",
      "Epoch 00207: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3141 - val_loss: 0.3348 - lr: 1.0000e-06\n",
      "Epoch 208/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3419\n",
      "Epoch 00208: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3145 - val_loss: 0.3330 - lr: 1.0000e-06\n",
      "Epoch 209/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3260\n",
      "Epoch 00209: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2994 - val_loss: 0.3312 - lr: 1.0000e-06\n",
      "Epoch 210/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2917\n",
      "Epoch 00210: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3020 - val_loss: 0.3294 - lr: 1.0000e-06\n",
      "Epoch 211/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3109\n",
      "Epoch 00211: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3013 - val_loss: 0.3275 - lr: 1.0000e-06\n",
      "Epoch 212/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2645\n",
      "Epoch 00212: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2994 - val_loss: 0.3256 - lr: 1.0000e-06\n",
      "Epoch 213/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3246\n",
      "Epoch 00213: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2981 - val_loss: 0.3237 - lr: 1.0000e-06\n",
      "Epoch 214/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3139\n",
      "Epoch 00214: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3055 - val_loss: 0.3217 - lr: 1.0000e-06\n",
      "Epoch 215/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3159\n",
      "Epoch 00215: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2843 - val_loss: 0.3197 - lr: 1.0000e-06\n",
      "Epoch 216/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2542\n",
      "Epoch 00216: val_loss did not improve from 0.31703\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3039 - val_loss: 0.3177 - lr: 1.0000e-06\n",
      "Epoch 217/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3000\n",
      "Epoch 00217: val_loss improved from 0.31703 to 0.31562, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.2943 - val_loss: 0.3156 - lr: 1.0000e-06\n",
      "Epoch 218/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3169\n",
      "Epoch 00218: val_loss improved from 0.31562 to 0.31353, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.2857 - val_loss: 0.3135 - lr: 1.0000e-06\n",
      "Epoch 219/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2742\n",
      "Epoch 00219: val_loss improved from 0.31353 to 0.31141, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.3016 - val_loss: 0.3114 - lr: 1.0000e-06\n",
      "Epoch 220/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3165\n",
      "Epoch 00220: val_loss improved from 0.31141 to 0.30924, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.2860 - val_loss: 0.3092 - lr: 1.0000e-06\n",
      "Epoch 221/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2818\n",
      "Epoch 00221: val_loss improved from 0.30924 to 0.30704, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.2852 - val_loss: 0.3070 - lr: 1.0000e-06\n",
      "Epoch 222/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2692\n",
      "Epoch 00222: val_loss improved from 0.30704 to 0.30481, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.2856 - val_loss: 0.3048 - lr: 1.0000e-06\n",
      "Epoch 223/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2847\n",
      "Epoch 00223: val_loss improved from 0.30481 to 0.30255, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.2884 - val_loss: 0.3025 - lr: 1.0000e-06\n",
      "Epoch 224/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2805\n",
      "Epoch 00224: val_loss improved from 0.30255 to 0.30026, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.2769 - val_loss: 0.3003 - lr: 1.0000e-06\n",
      "Epoch 225/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2649\n",
      "Epoch 00225: val_loss improved from 0.30026 to 0.29794, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.2805 - val_loss: 0.2979 - lr: 1.0000e-06\n",
      "Epoch 226/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2742\n",
      "Epoch 00226: val_loss improved from 0.29794 to 0.29558, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.2839 - val_loss: 0.2956 - lr: 1.0000e-06\n",
      "Epoch 227/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2550\n",
      "Epoch 00227: val_loss improved from 0.29558 to 0.29318, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.2703 - val_loss: 0.2932 - lr: 1.0000e-06\n",
      "Epoch 228/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2830\n",
      "Epoch 00228: val_loss improved from 0.29318 to 0.29075, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.2595 - val_loss: 0.2907 - lr: 1.0000e-06\n",
      "Epoch 229/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2371\n",
      "Epoch 00229: val_loss improved from 0.29075 to 0.28830, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.2720 - val_loss: 0.2883 - lr: 1.0000e-06\n",
      "Epoch 230/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3044\n",
      "Epoch 00230: val_loss improved from 0.28830 to 0.28579, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.2686 - val_loss: 0.2858 - lr: 1.0000e-06\n",
      "Epoch 231/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2601\n",
      "Epoch 00231: val_loss improved from 0.28579 to 0.28325, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2617 - val_loss: 0.2833 - lr: 1.0000e-06\n",
      "Epoch 232/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2382\n",
      "Epoch 00232: val_loss improved from 0.28325 to 0.28068, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.2570 - val_loss: 0.2807 - lr: 1.0000e-06\n",
      "Epoch 233/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2388\n",
      "Epoch 00233: val_loss improved from 0.28068 to 0.27805, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.2487 - val_loss: 0.2780 - lr: 1.0000e-06\n",
      "Epoch 234/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2082\n",
      "Epoch 00234: val_loss improved from 0.27805 to 0.27538, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.2571 - val_loss: 0.2754 - lr: 1.0000e-06\n",
      "Epoch 235/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2231\n",
      "Epoch 00235: val_loss improved from 0.27538 to 0.27267, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2506 - val_loss: 0.2727 - lr: 1.0000e-06\n",
      "Epoch 236/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2351\n",
      "Epoch 00236: val_loss improved from 0.27267 to 0.26994, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.2478 - val_loss: 0.2699 - lr: 1.0000e-06\n",
      "Epoch 237/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2475\n",
      "Epoch 00237: val_loss improved from 0.26994 to 0.26715, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.2523 - val_loss: 0.2672 - lr: 1.0000e-06\n",
      "Epoch 238/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2335\n",
      "Epoch 00238: val_loss improved from 0.26715 to 0.26432, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2492 - val_loss: 0.2643 - lr: 1.0000e-06\n",
      "Epoch 239/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2412\n",
      "Epoch 00239: val_loss improved from 0.26432 to 0.26144, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2544 - val_loss: 0.2614 - lr: 1.0000e-06\n",
      "Epoch 240/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2246\n",
      "Epoch 00240: val_loss improved from 0.26144 to 0.25852, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.2414 - val_loss: 0.2585 - lr: 1.0000e-06\n",
      "Epoch 241/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2218\n",
      "Epoch 00241: val_loss improved from 0.25852 to 0.25557, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.2381 - val_loss: 0.2556 - lr: 1.0000e-06\n",
      "Epoch 242/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2329\n",
      "Epoch 00242: val_loss improved from 0.25557 to 0.25258, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.2316 - val_loss: 0.2526 - lr: 1.0000e-06\n",
      "Epoch 243/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2402\n",
      "Epoch 00243: val_loss improved from 0.25258 to 0.24956, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.2230 - val_loss: 0.2496 - lr: 1.0000e-06\n",
      "Epoch 244/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2177\n",
      "Epoch 00244: val_loss improved from 0.24956 to 0.24654, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2300 - val_loss: 0.2465 - lr: 1.0000e-06\n",
      "Epoch 245/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2316\n",
      "Epoch 00245: val_loss improved from 0.24654 to 0.24346, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.2328 - val_loss: 0.2435 - lr: 1.0000e-06\n",
      "Epoch 246/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2270\n",
      "Epoch 00246: val_loss improved from 0.24346 to 0.24033, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.2202 - val_loss: 0.2403 - lr: 1.0000e-06\n",
      "Epoch 247/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2306\n",
      "Epoch 00247: val_loss improved from 0.24033 to 0.23716, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.2170 - val_loss: 0.2372 - lr: 1.0000e-06\n",
      "Epoch 248/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2024\n",
      "Epoch 00248: val_loss improved from 0.23716 to 0.23398, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.2250 - val_loss: 0.2340 - lr: 1.0000e-06\n",
      "Epoch 249/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2342\n",
      "Epoch 00249: val_loss improved from 0.23398 to 0.23071, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.2109 - val_loss: 0.2307 - lr: 1.0000e-06\n",
      "Epoch 250/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1991\n",
      "Epoch 00250: val_loss improved from 0.23071 to 0.22744, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.2040 - val_loss: 0.2274 - lr: 1.0000e-06\n",
      "Epoch 251/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2011\n",
      "Epoch 00251: val_loss improved from 0.22744 to 0.22415, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.2138 - val_loss: 0.2241 - lr: 1.0000e-06\n",
      "Epoch 252/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2214\n",
      "Epoch 00252: val_loss improved from 0.22415 to 0.22079, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.2044 - val_loss: 0.2208 - lr: 1.0000e-06\n",
      "Epoch 253/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1957\n",
      "Epoch 00253: val_loss improved from 0.22079 to 0.21743, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.1987 - val_loss: 0.2174 - lr: 1.0000e-06\n",
      "Epoch 254/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2240\n",
      "Epoch 00254: val_loss improved from 0.21743 to 0.21401, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.1969 - val_loss: 0.2140 - lr: 1.0000e-06\n",
      "Epoch 255/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2036\n",
      "Epoch 00255: val_loss improved from 0.21401 to 0.21056, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.1996 - val_loss: 0.2106 - lr: 1.0000e-06\n",
      "Epoch 256/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1860\n",
      "Epoch 00256: val_loss improved from 0.21056 to 0.20707, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.1811 - val_loss: 0.2071 - lr: 1.0000e-06\n",
      "Epoch 257/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2060\n",
      "Epoch 00257: val_loss improved from 0.20707 to 0.20359, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1847 - val_loss: 0.2036 - lr: 1.0000e-06\n",
      "Epoch 258/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1542\n",
      "Epoch 00258: val_loss improved from 0.20359 to 0.20013, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.1863 - val_loss: 0.2001 - lr: 1.0000e-06\n",
      "Epoch 259/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1566\n",
      "Epoch 00259: val_loss improved from 0.20013 to 0.19658, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.1744 - val_loss: 0.1966 - lr: 1.0000e-06\n",
      "Epoch 260/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1895\n",
      "Epoch 00260: val_loss improved from 0.19658 to 0.19301, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.1739 - val_loss: 0.1930 - lr: 1.0000e-06\n",
      "Epoch 261/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1994\n",
      "Epoch 00261: val_loss improved from 0.19301 to 0.18938, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.1757 - val_loss: 0.1894 - lr: 1.0000e-06\n",
      "Epoch 262/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1788\n",
      "Epoch 00262: val_loss improved from 0.18938 to 0.18573, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.1698 - val_loss: 0.1857 - lr: 1.0000e-06\n",
      "Epoch 263/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1860\n",
      "Epoch 00263: val_loss improved from 0.18573 to 0.18204, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 263ms/step - loss: 0.1670 - val_loss: 0.1820 - lr: 1.0000e-06\n",
      "Epoch 264/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1750\n",
      "Epoch 00264: val_loss improved from 0.18204 to 0.17833, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.1605 - val_loss: 0.1783 - lr: 1.0000e-06\n",
      "Epoch 265/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1452\n",
      "Epoch 00265: val_loss improved from 0.17833 to 0.17463, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.1543 - val_loss: 0.1746 - lr: 1.0000e-06\n",
      "Epoch 266/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1625\n",
      "Epoch 00266: val_loss improved from 0.17463 to 0.17092, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.1538 - val_loss: 0.1709 - lr: 1.0000e-06\n",
      "Epoch 267/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1417\n",
      "Epoch 00267: val_loss improved from 0.17092 to 0.16727, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.1508 - val_loss: 0.1673 - lr: 1.0000e-06\n",
      "Epoch 268/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1198\n",
      "Epoch 00268: val_loss improved from 0.16727 to 0.16358, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.1525 - val_loss: 0.1636 - lr: 1.0000e-06\n",
      "Epoch 269/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1581\n",
      "Epoch 00269: val_loss improved from 0.16358 to 0.15983, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.1418 - val_loss: 0.1598 - lr: 1.0000e-06\n",
      "Epoch 270/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1582\n",
      "Epoch 00270: val_loss improved from 0.15983 to 0.15607, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 0.1336 - val_loss: 0.1561 - lr: 1.0000e-06\n",
      "Epoch 271/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1251\n",
      "Epoch 00271: val_loss improved from 0.15607 to 0.15234, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.1428 - val_loss: 0.1523 - lr: 1.0000e-06\n",
      "Epoch 272/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1404\n",
      "Epoch 00272: val_loss improved from 0.15234 to 0.14855, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.1354 - val_loss: 0.1485 - lr: 1.0000e-06\n",
      "Epoch 273/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1130\n",
      "Epoch 00273: val_loss improved from 0.14855 to 0.14475, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.1305 - val_loss: 0.1447 - lr: 1.0000e-06\n",
      "Epoch 274/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1467\n",
      "Epoch 00274: val_loss improved from 0.14475 to 0.14091, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.1268 - val_loss: 0.1409 - lr: 1.0000e-06\n",
      "Epoch 275/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1375\n",
      "Epoch 00275: val_loss improved from 0.14091 to 0.13711, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.1185 - val_loss: 0.1371 - lr: 1.0000e-06\n",
      "Epoch 276/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1148\n",
      "Epoch 00276: val_loss improved from 0.13711 to 0.13337, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.1184 - val_loss: 0.1334 - lr: 1.0000e-06\n",
      "Epoch 277/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1181\n",
      "Epoch 00277: val_loss improved from 0.13337 to 0.12963, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.1142 - val_loss: 0.1296 - lr: 1.0000e-06\n",
      "Epoch 278/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1142\n",
      "Epoch 00278: val_loss improved from 0.12963 to 0.12592, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.1099 - val_loss: 0.1259 - lr: 1.0000e-06\n",
      "Epoch 279/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0980\n",
      "Epoch 00279: val_loss improved from 0.12592 to 0.12225, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.1137 - val_loss: 0.1222 - lr: 1.0000e-06\n",
      "Epoch 280/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1123\n",
      "Epoch 00280: val_loss improved from 0.12225 to 0.11854, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.1026 - val_loss: 0.1185 - lr: 1.0000e-06\n",
      "Epoch 281/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1098\n",
      "Epoch 00281: val_loss improved from 0.11854 to 0.11485, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.1026 - val_loss: 0.1148 - lr: 1.0000e-06\n",
      "Epoch 282/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1056\n",
      "Epoch 00282: val_loss improved from 0.11485 to 0.11117, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0968 - val_loss: 0.1112 - lr: 1.0000e-06\n",
      "Epoch 283/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1034\n",
      "Epoch 00283: val_loss improved from 0.11117 to 0.10753, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.0960 - val_loss: 0.1075 - lr: 1.0000e-06\n",
      "Epoch 284/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0994\n",
      "Epoch 00284: val_loss improved from 0.10753 to 0.10392, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.0905 - val_loss: 0.1039 - lr: 1.0000e-06\n",
      "Epoch 285/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0951\n",
      "Epoch 00285: val_loss improved from 0.10392 to 0.10035, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0958 - val_loss: 0.1004 - lr: 1.0000e-06\n",
      "Epoch 286/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0932\n",
      "Epoch 00286: val_loss improved from 0.10035 to 0.09678, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0828 - val_loss: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 287/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0799\n",
      "Epoch 00287: val_loss improved from 0.09678 to 0.09332, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0847 - val_loss: 0.0933 - lr: 1.0000e-06\n",
      "Epoch 288/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0952\n",
      "Epoch 00288: val_loss improved from 0.09332 to 0.08988, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0787 - val_loss: 0.0899 - lr: 1.0000e-06\n",
      "Epoch 289/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0669\n",
      "Epoch 00289: val_loss improved from 0.08988 to 0.08651, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0812 - val_loss: 0.0865 - lr: 1.0000e-06\n",
      "Epoch 290/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0696\n",
      "Epoch 00290: val_loss improved from 0.08651 to 0.08317, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0694 - val_loss: 0.0832 - lr: 1.0000e-06\n",
      "Epoch 291/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0631\n",
      "Epoch 00291: val_loss improved from 0.08317 to 0.07994, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.0722 - val_loss: 0.0799 - lr: 1.0000e-06\n",
      "Epoch 292/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0633\n",
      "Epoch 00292: val_loss improved from 0.07994 to 0.07677, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0683 - val_loss: 0.0768 - lr: 1.0000e-06\n",
      "Epoch 293/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0627\n",
      "Epoch 00293: val_loss improved from 0.07677 to 0.07366, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0691 - val_loss: 0.0737 - lr: 1.0000e-06\n",
      "Epoch 294/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0685\n",
      "Epoch 00294: val_loss improved from 0.07366 to 0.07058, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 0.0659 - val_loss: 0.0706 - lr: 1.0000e-06\n",
      "Epoch 295/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0529\n",
      "Epoch 00295: val_loss improved from 0.07058 to 0.06758, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 263ms/step - loss: 0.0671 - val_loss: 0.0676 - lr: 1.0000e-06\n",
      "Epoch 296/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0484\n",
      "Epoch 00296: val_loss improved from 0.06758 to 0.06474, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0566 - val_loss: 0.0647 - lr: 1.0000e-06\n",
      "Epoch 297/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0550\n",
      "Epoch 00297: val_loss improved from 0.06474 to 0.06199, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0556 - val_loss: 0.0620 - lr: 1.0000e-06\n",
      "Epoch 298/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0505\n",
      "Epoch 00298: val_loss improved from 0.06199 to 0.05928, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0500 - val_loss: 0.0593 - lr: 1.0000e-06\n",
      "Epoch 299/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0559\n",
      "Epoch 00299: val_loss improved from 0.05928 to 0.05667, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0462 - val_loss: 0.0567 - lr: 1.0000e-06\n",
      "Epoch 300/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0578\n",
      "Epoch 00300: val_loss improved from 0.05667 to 0.05417, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0503 - val_loss: 0.0542 - lr: 1.0000e-06\n",
      "Epoch 301/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0632\n",
      "Epoch 00301: val_loss improved from 0.05417 to 0.05174, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0436 - val_loss: 0.0517 - lr: 1.0000e-06\n",
      "Epoch 302/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0448\n",
      "Epoch 00302: val_loss improved from 0.05174 to 0.04944, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0450 - val_loss: 0.0494 - lr: 1.0000e-06\n",
      "Epoch 303/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0389\n",
      "Epoch 00303: val_loss improved from 0.04944 to 0.04720, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0401 - val_loss: 0.0472 - lr: 1.0000e-06\n",
      "Epoch 304/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0464\n",
      "Epoch 00304: val_loss improved from 0.04720 to 0.04505, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0385 - val_loss: 0.0451 - lr: 1.0000e-06\n",
      "Epoch 305/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0334\n",
      "Epoch 00305: val_loss improved from 0.04505 to 0.04299, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 0.0411 - val_loss: 0.0430 - lr: 1.0000e-06\n",
      "Epoch 306/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0434\n",
      "Epoch 00306: val_loss improved from 0.04299 to 0.04095, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0411 - val_loss: 0.0410 - lr: 1.0000e-06\n",
      "Epoch 307/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0301\n",
      "Epoch 00307: val_loss improved from 0.04095 to 0.03897, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0359 - val_loss: 0.0390 - lr: 1.0000e-06\n",
      "Epoch 308/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0338\n",
      "Epoch 00308: val_loss improved from 0.03897 to 0.03708, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0320 - val_loss: 0.0371 - lr: 1.0000e-06\n",
      "Epoch 309/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0453\n",
      "Epoch 00309: val_loss improved from 0.03708 to 0.03531, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0325 - val_loss: 0.0353 - lr: 1.0000e-06\n",
      "Epoch 310/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0379\n",
      "Epoch 00310: val_loss improved from 0.03531 to 0.03361, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 0.0289 - val_loss: 0.0336 - lr: 1.0000e-06\n",
      "Epoch 311/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0255\n",
      "Epoch 00311: val_loss improved from 0.03361 to 0.03204, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0331 - val_loss: 0.0320 - lr: 1.0000e-06\n",
      "Epoch 312/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0281\n",
      "Epoch 00312: val_loss improved from 0.03204 to 0.03051, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0290 - val_loss: 0.0305 - lr: 1.0000e-06\n",
      "Epoch 313/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0289\n",
      "Epoch 00313: val_loss improved from 0.03051 to 0.02905, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0298 - val_loss: 0.0290 - lr: 1.0000e-06\n",
      "Epoch 314/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0318\n",
      "Epoch 00314: val_loss improved from 0.02905 to 0.02765, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0263 - val_loss: 0.0277 - lr: 1.0000e-06\n",
      "Epoch 315/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0200\n",
      "Epoch 00315: val_loss improved from 0.02765 to 0.02632, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0272 - val_loss: 0.0263 - lr: 1.0000e-06\n",
      "Epoch 316/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0250\n",
      "Epoch 00316: val_loss improved from 0.02632 to 0.02508, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0230 - val_loss: 0.0251 - lr: 1.0000e-06\n",
      "Epoch 317/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0242\n",
      "Epoch 00317: val_loss improved from 0.02508 to 0.02399, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 0.0248 - val_loss: 0.0240 - lr: 1.0000e-06\n",
      "Epoch 318/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0348\n",
      "Epoch 00318: val_loss improved from 0.02399 to 0.02298, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0206 - val_loss: 0.0230 - lr: 1.0000e-06\n",
      "Epoch 319/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0196\n",
      "Epoch 00319: val_loss improved from 0.02298 to 0.02204, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0226 - val_loss: 0.0220 - lr: 1.0000e-06\n",
      "Epoch 320/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 00320: val_loss improved from 0.02204 to 0.02115, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0192 - val_loss: 0.0212 - lr: 1.0000e-06\n",
      "Epoch 321/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0305\n",
      "Epoch 00321: val_loss improved from 0.02115 to 0.02038, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0203 - val_loss: 0.0204 - lr: 1.0000e-06\n",
      "Epoch 322/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0354\n",
      "Epoch 00322: val_loss improved from 0.02038 to 0.01962, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0218 - val_loss: 0.0196 - lr: 1.0000e-06\n",
      "Epoch 323/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0195\n",
      "Epoch 00323: val_loss improved from 0.01962 to 0.01891, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.0188 - val_loss: 0.0189 - lr: 1.0000e-06\n",
      "Epoch 324/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00324: val_loss improved from 0.01891 to 0.01824, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 0.0209 - val_loss: 0.0182 - lr: 1.0000e-06\n",
      "Epoch 325/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00325: val_loss improved from 0.01824 to 0.01758, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0176 - val_loss: 0.0176 - lr: 1.0000e-06\n",
      "Epoch 326/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0280\n",
      "Epoch 00326: val_loss improved from 0.01758 to 0.01701, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0170 - val_loss: 0.0170 - lr: 1.0000e-06\n",
      "Epoch 327/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 00327: val_loss improved from 0.01701 to 0.01650, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.0185 - val_loss: 0.0165 - lr: 1.0000e-06\n",
      "Epoch 328/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 00328: val_loss improved from 0.01650 to 0.01603, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.0169 - val_loss: 0.0160 - lr: 1.0000e-06\n",
      "Epoch 329/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 00329: val_loss improved from 0.01603 to 0.01561, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0175 - val_loss: 0.0156 - lr: 1.0000e-06\n",
      "Epoch 330/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00330: val_loss improved from 0.01561 to 0.01520, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0179 - val_loss: 0.0152 - lr: 1.0000e-06\n",
      "Epoch 331/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00331: val_loss improved from 0.01520 to 0.01481, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0167 - val_loss: 0.0148 - lr: 1.0000e-06\n",
      "Epoch 332/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00332: val_loss improved from 0.01481 to 0.01448, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0283 - val_loss: 0.0145 - lr: 1.0000e-06\n",
      "Epoch 333/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0279\n",
      "Epoch 00333: val_loss improved from 0.01448 to 0.01421, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0167 - val_loss: 0.0142 - lr: 1.0000e-06\n",
      "Epoch 334/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0320\n",
      "Epoch 00334: val_loss improved from 0.01421 to 0.01395, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0164 - val_loss: 0.0139 - lr: 1.0000e-06\n",
      "Epoch 335/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00335: val_loss improved from 0.01395 to 0.01367, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0188 - val_loss: 0.0137 - lr: 1.0000e-06\n",
      "Epoch 336/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0243\n",
      "Epoch 00336: val_loss improved from 0.01367 to 0.01342, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0171 - val_loss: 0.0134 - lr: 1.0000e-06\n",
      "Epoch 337/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0316\n",
      "Epoch 00337: val_loss improved from 0.01342 to 0.01315, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.0168 - val_loss: 0.0131 - lr: 1.0000e-06\n",
      "Epoch 338/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00338: val_loss improved from 0.01315 to 0.01291, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0175 - val_loss: 0.0129 - lr: 1.0000e-06\n",
      "Epoch 339/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 00339: val_loss improved from 0.01291 to 0.01266, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0165 - val_loss: 0.0127 - lr: 1.0000e-06\n",
      "Epoch 340/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00340: val_loss improved from 0.01266 to 0.01247, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0152 - val_loss: 0.0125 - lr: 1.0000e-06\n",
      "Epoch 341/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00341: val_loss improved from 0.01247 to 0.01231, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 0.0152 - val_loss: 0.0123 - lr: 1.0000e-06\n",
      "Epoch 342/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0303\n",
      "Epoch 00342: val_loss improved from 0.01231 to 0.01217, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0183 - val_loss: 0.0122 - lr: 1.0000e-06\n",
      "Epoch 343/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00343: val_loss improved from 0.01217 to 0.01202, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0173 - val_loss: 0.0120 - lr: 1.0000e-06\n",
      "Epoch 344/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 00344: val_loss improved from 0.01202 to 0.01188, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 0.0163 - val_loss: 0.0119 - lr: 1.0000e-06\n",
      "Epoch 345/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 00345: val_loss improved from 0.01188 to 0.01175, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0281 - val_loss: 0.0118 - lr: 1.0000e-06\n",
      "Epoch 346/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00346: val_loss improved from 0.01175 to 0.01170, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 9.899999975004903e-07.\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0158 - val_loss: 0.0117 - lr: 1.0000e-06\n",
      "Epoch 347/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0361\n",
      "Epoch 00347: val_loss improved from 0.01170 to 0.01164, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0160 - val_loss: 0.0116 - lr: 9.9000e-07\n",
      "Epoch 348/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00348: val_loss improved from 0.01164 to 0.01156, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 9.800999896469875e-07.\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0154 - val_loss: 0.0116 - lr: 9.9000e-07\n",
      "Epoch 349/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0229\n",
      "Epoch 00349: val_loss improved from 0.01156 to 0.01147, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.0163 - val_loss: 0.0115 - lr: 9.8010e-07\n",
      "Epoch 350/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00350: val_loss improved from 0.01147 to 0.01137, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 9.702990257665079e-07.\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0145 - val_loss: 0.0114 - lr: 9.8010e-07\n",
      "Epoch 351/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00351: val_loss improved from 0.01137 to 0.01129, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0187 - val_loss: 0.0113 - lr: 9.7030e-07\n",
      "Epoch 352/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00352: val_loss improved from 0.01129 to 0.01124, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 9.605959803593577e-07.\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0145 - val_loss: 0.0112 - lr: 9.7030e-07\n",
      "Epoch 353/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0277\n",
      "Epoch 00353: val_loss improved from 0.01124 to 0.01119, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 9.50990065575752e-07.\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.0153 - val_loss: 0.0112 - lr: 9.6060e-07\n",
      "Epoch 354/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00354: val_loss improved from 0.01119 to 0.01113, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0147 - val_loss: 0.0111 - lr: 9.5099e-07\n",
      "Epoch 355/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00355: val_loss improved from 0.01113 to 0.01107, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 9.414801559159969e-07.\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0162 - val_loss: 0.0111 - lr: 9.5099e-07\n",
      "Epoch 356/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0278\n",
      "Epoch 00356: val_loss improved from 0.01107 to 0.01104, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 9.320653509803379e-07.\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.0156 - val_loss: 0.0110 - lr: 9.4148e-07\n",
      "Epoch 357/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00357: val_loss improved from 0.01104 to 0.01101, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.0258 - val_loss: 0.0110 - lr: 9.3207e-07\n",
      "Epoch 358/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00358: val_loss did not improve from 0.01101\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 9.227446940940354e-07.\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0150 - val_loss: 0.0110 - lr: 9.3207e-07\n",
      "Epoch 359/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00359: val_loss did not improve from 0.01101\n",
      "\n",
      "Epoch 00359: ReduceLROnPlateau reducing learning rate to 9.1351722858235e-07.\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0281 - val_loss: 0.0111 - lr: 9.2274e-07\n",
      "Epoch 360/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0257\n",
      "Epoch 00360: val_loss did not improve from 0.01101\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 9.043820540455272e-07.\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0154 - val_loss: 0.0111 - lr: 9.1352e-07\n",
      "Epoch 361/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00361: val_loss did not improve from 0.01101\n",
      "\n",
      "Epoch 00361: ReduceLROnPlateau reducing learning rate to 8.953382138088273e-07.\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0271 - val_loss: 0.0111 - lr: 9.0438e-07\n",
      "Epoch 362/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0075\n",
      "Epoch 00362: val_loss did not improve from 0.01101\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 8.863848074724956e-07.\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0144 - val_loss: 0.0111 - lr: 8.9534e-07\n",
      "Epoch 363/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00363: val_loss did not improve from 0.01101\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 8.775209346367773e-07.\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0156 - val_loss: 0.0110 - lr: 8.8638e-07\n",
      "Epoch 364/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00364: val_loss improved from 0.01101 to 0.01098, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 8.687457511769025e-07.\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0149 - val_loss: 0.0110 - lr: 8.7752e-07\n",
      "Epoch 365/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0358\n",
      "Epoch 00365: val_loss improved from 0.01098 to 0.01093, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 8.600583004181316e-07.\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.0156 - val_loss: 0.0109 - lr: 8.6875e-07\n",
      "Epoch 366/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00366: val_loss improved from 0.01093 to 0.01090, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 0.0161 - val_loss: 0.0109 - lr: 8.6006e-07\n",
      "Epoch 367/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00367: val_loss improved from 0.01090 to 0.01087, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00367: ReduceLROnPlateau reducing learning rate to 8.514577382356947e-07.\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0155 - val_loss: 0.0109 - lr: 8.6006e-07\n",
      "Epoch 368/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00368: val_loss improved from 0.01087 to 0.01084, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00368: ReduceLROnPlateau reducing learning rate to 8.429431642298369e-07.\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.0172 - val_loss: 0.0108 - lr: 8.5146e-07\n",
      "Epoch 369/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0272\n",
      "Epoch 00369: val_loss improved from 0.01084 to 0.01080, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 8.34513734275788e-07.\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 0.0166 - val_loss: 0.0108 - lr: 8.4294e-07\n",
      "Epoch 370/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 00370: val_loss improved from 0.01080 to 0.01078, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0165 - val_loss: 0.0108 - lr: 8.3451e-07\n",
      "Epoch 371/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00371: val_loss improved from 0.01078 to 0.01076, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00371: ReduceLROnPlateau reducing learning rate to 8.261686042487781e-07.\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.0145 - val_loss: 0.0108 - lr: 8.3451e-07\n",
      "Epoch 372/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 00372: val_loss improved from 0.01076 to 0.01074, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00372: ReduceLROnPlateau reducing learning rate to 8.179069300240371e-07.\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 0.0173 - val_loss: 0.0107 - lr: 8.2617e-07\n",
      "Epoch 373/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00373: val_loss improved from 0.01074 to 0.01070, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00373: ReduceLROnPlateau reducing learning rate to 8.097278674767949e-07.\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.0158 - val_loss: 0.0107 - lr: 8.1791e-07\n",
      "Epoch 374/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00374: val_loss improved from 0.01070 to 0.01067, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 0.0152 - val_loss: 0.0107 - lr: 8.0973e-07\n",
      "Epoch 375/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 00375: val_loss improved from 0.01067 to 0.01066, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 8.016305724822814e-07.\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0149 - val_loss: 0.0107 - lr: 8.0973e-07\n",
      "Epoch 376/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0256\n",
      "Epoch 00376: val_loss improved from 0.01066 to 0.01065, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00376: ReduceLROnPlateau reducing learning rate to 7.936142571907112e-07.\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.0159 - val_loss: 0.0106 - lr: 8.0163e-07\n",
      "Epoch 377/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0303\n",
      "Epoch 00377: val_loss improved from 0.01065 to 0.01062, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 7.856781337522989e-07.\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.0144 - val_loss: 0.0106 - lr: 7.9361e-07\n",
      "Epoch 378/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 00378: val_loss improved from 0.01062 to 0.01060, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 7.778213580422743e-07.\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.0253 - val_loss: 0.0106 - lr: 7.8568e-07\n",
      "Epoch 379/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0170\n",
      "Epoch 00379: val_loss did not improve from 0.01060\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 7.700431422108523e-07.\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0151 - val_loss: 0.0106 - lr: 7.7782e-07\n",
      "Epoch 380/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 00380: val_loss improved from 0.01060 to 0.01059, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00380: ReduceLROnPlateau reducing learning rate to 7.623426984082471e-07.\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.0170 - val_loss: 0.0106 - lr: 7.7004e-07\n",
      "Epoch 381/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 00381: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00381: ReduceLROnPlateau reducing learning rate to 7.547192950596582e-07.\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0185 - val_loss: 0.0106 - lr: 7.6234e-07\n",
      "Epoch 382/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0288\n",
      "Epoch 00382: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00382: ReduceLROnPlateau reducing learning rate to 7.471720880403154e-07.\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0154 - val_loss: 0.0106 - lr: 7.5472e-07\n",
      "Epoch 383/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00383: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 7.397003457754181e-07.\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0152 - val_loss: 0.0106 - lr: 7.4717e-07\n",
      "Epoch 384/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00384: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 7.323033366901654e-07.\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0169 - val_loss: 0.0106 - lr: 7.3970e-07\n",
      "Epoch 385/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 00385: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 7.249803292097568e-07.\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0164 - val_loss: 0.0106 - lr: 7.3230e-07\n",
      "Epoch 386/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00386: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00386: ReduceLROnPlateau reducing learning rate to 7.177305354844065e-07.\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0170 - val_loss: 0.0106 - lr: 7.2498e-07\n",
      "Epoch 387/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00387: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00387: ReduceLROnPlateau reducing learning rate to 7.105532239393142e-07.\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0140 - val_loss: 0.0106 - lr: 7.1773e-07\n",
      "Epoch 388/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00388: val_loss did not improve from 0.01059\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 7.034477192746636e-07.\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0106 - lr: 7.1055e-07\n",
      "Epoch 389/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00389: val_loss improved from 0.01059 to 0.01058, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00389: ReduceLROnPlateau reducing learning rate to 6.964132336406692e-07.\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0153 - val_loss: 0.0106 - lr: 7.0345e-07\n",
      "Epoch 390/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 00390: val_loss improved from 0.01058 to 0.01056, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0141 - val_loss: 0.0106 - lr: 6.9641e-07\n",
      "Epoch 391/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00391: val_loss improved from 0.01056 to 0.01056, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00391: ReduceLROnPlateau reducing learning rate to 6.894490917375151e-07.\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.0145 - val_loss: 0.0106 - lr: 6.9641e-07\n",
      "Epoch 392/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 00392: val_loss improved from 0.01056 to 0.01054, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00392: ReduceLROnPlateau reducing learning rate to 6.825546182653852e-07.\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.0152 - val_loss: 0.0105 - lr: 6.8945e-07\n",
      "Epoch 393/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00393: val_loss improved from 0.01054 to 0.01053, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00393: ReduceLROnPlateau reducing learning rate to 6.757290816494788e-07.\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.0152 - val_loss: 0.0105 - lr: 6.8255e-07\n",
      "Epoch 394/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00394: val_loss improved from 0.01053 to 0.01052, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 6.689718065899797e-07.\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0149 - val_loss: 0.0105 - lr: 6.7573e-07\n",
      "Epoch 395/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0277\n",
      "Epoch 00395: val_loss improved from 0.01052 to 0.01051, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 6.622820615120873e-07.\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 0.0148 - val_loss: 0.0105 - lr: 6.6897e-07\n",
      "Epoch 396/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 00396: val_loss improved from 0.01051 to 0.01050, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 6.5565922739097e-07.\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.0143 - val_loss: 0.0105 - lr: 6.6228e-07\n",
      "Epoch 397/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0290\n",
      "Epoch 00397: val_loss improved from 0.01050 to 0.01049, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 6.49102628926812e-07.\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 0.0156 - val_loss: 0.0105 - lr: 6.5566e-07\n",
      "Epoch 398/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00398: val_loss improved from 0.01049 to 0.01049, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 6.426115908197971e-07.\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.0156 - val_loss: 0.0105 - lr: 6.4910e-07\n",
      "Epoch 399/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00399: val_loss improved from 0.01049 to 0.01046, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0145 - val_loss: 0.0105 - lr: 6.4261e-07\n",
      "Epoch 400/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00400: val_loss improved from 0.01046 to 0.01043, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00400: ReduceLROnPlateau reducing learning rate to 6.36185494045094e-07.\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0146 - val_loss: 0.0104 - lr: 6.4261e-07\n",
      "Epoch 401/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00401: val_loss improved from 0.01043 to 0.01040, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00401: ReduceLROnPlateau reducing learning rate to 6.298236633028864e-07.\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0256 - val_loss: 0.0104 - lr: 6.3619e-07\n",
      "Epoch 402/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00402: val_loss did not improve from 0.01040\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 6.235254232933585e-07.\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0151 - val_loss: 0.0104 - lr: 6.2982e-07\n",
      "Epoch 403/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00403: val_loss improved from 0.01040 to 0.01039, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 6.172901549916787e-07.\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.0157 - val_loss: 0.0104 - lr: 6.2353e-07\n",
      "Epoch 404/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00404: val_loss improved from 0.01039 to 0.01036, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 6.111172393730158e-07.\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.0268 - val_loss: 0.0104 - lr: 6.1729e-07\n",
      "Epoch 405/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00405: val_loss improved from 0.01036 to 0.01035, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0153 - val_loss: 0.0103 - lr: 6.1112e-07\n",
      "Epoch 406/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 00406: val_loss improved from 0.01035 to 0.01032, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00406: ReduceLROnPlateau reducing learning rate to 6.050060574125382e-07.\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0154 - val_loss: 0.0103 - lr: 6.1112e-07\n",
      "Epoch 407/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0284\n",
      "Epoch 00407: val_loss improved from 0.01032 to 0.01030, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00407: ReduceLROnPlateau reducing learning rate to 5.989559900854146e-07.\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.0148 - val_loss: 0.0103 - lr: 6.0501e-07\n",
      "Epoch 408/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 00408: val_loss improved from 0.01030 to 0.01028, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00408: ReduceLROnPlateau reducing learning rate to 5.929664183668138e-07.\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.0149 - val_loss: 0.0103 - lr: 5.9896e-07\n",
      "Epoch 409/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 00409: val_loss improved from 0.01028 to 0.01028, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00409: ReduceLROnPlateau reducing learning rate to 5.870367795068887e-07.\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0149 - val_loss: 0.0103 - lr: 5.9297e-07\n",
      "Epoch 410/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00410: val_loss improved from 0.01028 to 0.01026, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00410: ReduceLROnPlateau reducing learning rate to 5.811663982058235e-07.\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 0.0159 - val_loss: 0.0103 - lr: 5.8704e-07\n",
      "Epoch 411/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00411: val_loss improved from 0.01026 to 0.01026, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 5.753547117137714e-07.\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.0145 - val_loss: 0.0103 - lr: 5.8117e-07\n",
      "Epoch 412/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00412: val_loss did not improve from 0.01026\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 5.696011572808856e-07.\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0159 - val_loss: 0.0103 - lr: 5.7535e-07\n",
      "Epoch 413/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 00413: val_loss did not improve from 0.01026\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 5.639051721573196e-07.\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0148 - val_loss: 0.0103 - lr: 5.6960e-07\n",
      "Epoch 414/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00414: val_loss did not improve from 0.01026\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 5.582661373182418e-07.\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0103 - lr: 5.6391e-07\n",
      "Epoch 415/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0273\n",
      "Epoch 00415: val_loss did not improve from 0.01026\n",
      "\n",
      "Epoch 00415: ReduceLROnPlateau reducing learning rate to 5.526834900138055e-07.\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0103 - lr: 5.5827e-07\n",
      "Epoch 416/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 00416: val_loss improved from 0.01026 to 0.01024, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0152 - val_loss: 0.0102 - lr: 5.5268e-07\n",
      "Epoch 417/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00417: val_loss improved from 0.01024 to 0.01022, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00417: ReduceLROnPlateau reducing learning rate to 5.471566674941642e-07.\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.0141 - val_loss: 0.0102 - lr: 5.5268e-07\n",
      "Epoch 418/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00418: val_loss improved from 0.01022 to 0.01021, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00418: ReduceLROnPlateau reducing learning rate to 5.416851070094708e-07.\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.0152 - val_loss: 0.0102 - lr: 5.4716e-07\n",
      "Epoch 419/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0240\n",
      "Epoch 00419: val_loss improved from 0.01021 to 0.01020, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00419: ReduceLROnPlateau reducing learning rate to 5.362682458098789e-07.\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0143 - val_loss: 0.0102 - lr: 5.4169e-07\n",
      "Epoch 420/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00420: val_loss improved from 0.01020 to 0.01019, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00420: ReduceLROnPlateau reducing learning rate to 5.309055774205262e-07.\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.0136 - val_loss: 0.0102 - lr: 5.3627e-07\n",
      "Epoch 421/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00421: val_loss improved from 0.01019 to 0.01018, saving model to E:\\Dropbox\\AI\\Data_cleaning\\Thing\\Model\\Timetable_checkpoint.keras\n",
      "\n",
      "Epoch 00421: ReduceLROnPlateau reducing learning rate to 5.255965390915662e-07.\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0166 - val_loss: 0.0102 - lr: 5.3091e-07\n",
      "Epoch 422/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 00422: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 5.203405680731521e-07.\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0163 - val_loss: 0.0102 - lr: 5.2560e-07\n",
      "Epoch 423/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 00423: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00423: ReduceLROnPlateau reducing learning rate to 5.151371578904218e-07.\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0257 - val_loss: 0.0102 - lr: 5.2034e-07\n",
      "Epoch 424/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00424: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00424: ReduceLROnPlateau reducing learning rate to 5.099858020685133e-07.\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0102 - lr: 5.1514e-07\n",
      "Epoch 425/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 00425: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00425: ReduceLROnPlateau reducing learning rate to 5.048859378575798e-07.\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0147 - val_loss: 0.0102 - lr: 5.0999e-07\n",
      "Epoch 426/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00426: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00426: ReduceLROnPlateau reducing learning rate to 4.998370587827594e-07.\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0102 - lr: 5.0489e-07\n",
      "Epoch 427/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 00427: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00427: ReduceLROnPlateau reducing learning rate to 4.948387146441746e-07.\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0138 - val_loss: 0.0102 - lr: 4.9984e-07\n",
      "Epoch 428/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00428: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00428: ReduceLROnPlateau reducing learning rate to 4.898903426919788e-07.\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0264 - val_loss: 0.0102 - lr: 4.9484e-07\n",
      "Epoch 429/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 00429: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00429: ReduceLROnPlateau reducing learning rate to 4.849914364513097e-07.\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0169 - val_loss: 0.0102 - lr: 4.8989e-07\n",
      "Epoch 430/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00430: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00430: ReduceLROnPlateau reducing learning rate to 4.801415457222902e-07.\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0102 - lr: 4.8499e-07\n",
      "Epoch 431/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00431: val_loss did not improve from 0.01018\n",
      "\n",
      "Epoch 00431: ReduceLROnPlateau reducing learning rate to 4.753401077550734e-07.\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.0102 - lr: 4.8014e-07\n",
      "Epoch 00431: early stopping\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1080x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"317.99625pt\" version=\"1.1\" viewBox=\"0 0 874.303125 317.99625\" width=\"874.303125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 317.99625 \r\nL 874.303125 317.99625 \r\nL 874.303125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 294.118125 \r\nL 867.103125 294.118125 \r\nL 867.103125 22.318125 \r\nL 30.103125 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"md92cb1e854\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"68.14858\" xlink:href=\"#md92cb1e854\" y=\"294.118125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(64.96733 308.716563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.104182\" xlink:href=\"#md92cb1e854\" y=\"294.118125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(235.560432 308.716563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"422.059785\" xlink:href=\"#md92cb1e854\" y=\"294.118125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 200 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(412.516035 308.716563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"599.015387\" xlink:href=\"#md92cb1e854\" y=\"294.118125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 300 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(589.471637 308.716563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"775.97099\" xlink:href=\"#md92cb1e854\" y=\"294.118125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 400 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(766.42724 308.716563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mfb5657b7f0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfb5657b7f0\" y=\"287.085201\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0.0 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 290.88442)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfb5657b7f0\" y=\"234.828752\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.1 -->\r\n      <g transform=\"translate(7.2 238.62797)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfb5657b7f0\" y=\"182.572303\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 186.371521)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfb5657b7f0\" y=\"130.315854\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.3 -->\r\n      <g transform=\"translate(7.2 134.115072)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfb5657b7f0\" y=\"78.059405\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(7.2 81.858623)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfb5657b7f0\" y=\"25.802956\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 29.602174)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p3afcede291)\" d=\"M 68.14858 45.222858 \r\nL 69.918136 50.226434 \r\nL 71.687692 47.379963 \r\nL 73.457248 46.52321 \r\nL 75.226804 54.330959 \r\nL 76.99636 52.220996 \r\nL 78.765916 52.302228 \r\nL 80.535472 50.76388 \r\nL 82.305028 51.147941 \r\nL 84.074584 48.943135 \r\nL 85.84414 44.820981 \r\nL 87.613696 62.242864 \r\nL 89.383252 57.518384 \r\nL 91.152808 52.301465 \r\nL 92.922364 42.917213 \r\nL 94.69192 60.625184 \r\nL 96.461476 54.232409 \r\nL 98.231032 55.631498 \r\nL 100.000588 55.996715 \r\nL 101.770144 55.012087 \r\nL 103.5397 46.545122 \r\nL 105.309256 52.861244 \r\nL 107.078812 48.708363 \r\nL 108.848368 55.444225 \r\nL 110.617924 49.914478 \r\nL 112.38748 56.586333 \r\nL 114.157036 56.289686 \r\nL 115.926592 53.094521 \r\nL 117.696148 62.115534 \r\nL 119.465704 56.206679 \r\nL 121.23526 59.982429 \r\nL 123.004816 56.195217 \r\nL 124.774372 56.779882 \r\nL 126.543928 51.367234 \r\nL 128.313484 53.611691 \r\nL 130.08304 62.78939 \r\nL 131.852596 63.441115 \r\nL 133.622152 55.75794 \r\nL 135.391709 52.03187 \r\nL 138.930821 68.839716 \r\nL 140.700377 56.848593 \r\nL 142.469933 59.761377 \r\nL 144.239489 56.605815 \r\nL 146.009045 62.143177 \r\nL 147.778601 55.079148 \r\nL 149.548157 58.809345 \r\nL 151.317713 60.182519 \r\nL 153.087269 60.351726 \r\nL 154.856825 51.270662 \r\nL 156.626381 59.998392 \r\nL 158.395937 51.665656 \r\nL 160.165493 57.068384 \r\nL 161.935049 52.121745 \r\nL 163.704605 62.66846 \r\nL 165.474161 55.542712 \r\nL 167.243717 65.636671 \r\nL 169.013273 68.832957 \r\nL 170.782829 61.704265 \r\nL 172.552385 61.34548 \r\nL 174.321941 63.129642 \r\nL 176.091497 65.109223 \r\nL 177.861053 60.569539 \r\nL 179.630609 61.044021 \r\nL 181.400165 55.280982 \r\nL 183.169721 73.154859 \r\nL 184.939277 58.481224 \r\nL 186.708833 73.425108 \r\nL 188.478389 52.904897 \r\nL 190.247945 66.535488 \r\nL 192.017501 61.404442 \r\nL 193.787057 68.650808 \r\nL 195.556613 68.019001 \r\nL 197.326169 65.518 \r\nL 199.095725 64.706816 \r\nL 202.634837 61.658495 \r\nL 204.404393 66.315432 \r\nL 206.17395 66.261594 \r\nL 209.713062 60.391922 \r\nL 211.482618 67.0264 \r\nL 213.252174 71.611418 \r\nL 215.02173 72.230236 \r\nL 216.791286 70.27886 \r\nL 218.560842 67.315509 \r\nL 220.330398 74.105442 \r\nL 222.099954 64.894976 \r\nL 223.86951 66.259367 \r\nL 225.639066 75.10066 \r\nL 227.408622 70.698383 \r\nL 229.178178 65.965119 \r\nL 230.947734 71.453797 \r\nL 232.71729 73.930566 \r\nL 234.486846 67.643801 \r\nL 236.256402 66.630082 \r\nL 238.025958 75.79146 \r\nL 239.795514 68.147546 \r\nL 241.56507 70.679741 \r\nL 243.334626 72.030396 \r\nL 245.104182 73.77184 \r\nL 246.873738 64.623123 \r\nL 248.643294 73.169062 \r\nL 250.41285 75.632577 \r\nL 252.182406 73.783925 \r\nL 253.951962 71.54305 \r\nL 255.721518 73.072583 \r\nL 257.491074 73.44213 \r\nL 261.030186 78.577209 \r\nL 262.799742 73.82669 \r\nL 264.569298 74.107467 \r\nL 266.338854 74.104555 \r\nL 268.10841 74.959236 \r\nL 269.877966 84.217669 \r\nL 271.647522 68.146144 \r\nL 273.417078 75.292698 \r\nL 275.186635 79.221724 \r\nL 276.956191 70.009 \r\nL 278.725747 73.292125 \r\nL 280.495303 74.547157 \r\nL 282.264859 74.750238 \r\nL 284.034415 81.27598 \r\nL 285.803971 81.759884 \r\nL 287.573527 84.605421 \r\nL 289.343083 80.108067 \r\nL 291.112639 70.647706 \r\nL 292.882195 82.982866 \r\nL 294.651751 80.308452 \r\nL 296.421307 84.627411 \r\nL 298.190863 89.351159 \r\nL 299.960419 84.457253 \r\nL 301.729975 79.962204 \r\nL 303.499531 82.938544 \r\nL 305.269087 83.265668 \r\nL 307.038643 86.785668 \r\nL 308.808199 87.80314 \r\nL 310.577755 80.245753 \r\nL 312.347311 83.647378 \r\nL 314.116867 85.739587 \r\nL 315.886423 85.195677 \r\nL 317.655979 83.923934 \r\nL 319.425535 79.136832 \r\nL 321.195091 92.697342 \r\nL 322.964647 88.204364 \r\nL 324.734203 83.003377 \r\nL 326.503759 87.393164 \r\nL 328.273315 94.565913 \r\nL 330.042871 84.618503 \r\nL 331.812427 97.50743 \r\nL 333.581983 96.87078 \r\nL 335.351539 91.707372 \r\nL 337.121095 86.024226 \r\nL 338.890651 91.844109 \r\nL 340.660207 93.727553 \r\nL 342.429763 97.235281 \r\nL 344.19932 97.850642 \r\nL 345.968876 93.028562 \r\nL 347.738432 99.886334 \r\nL 349.507988 92.021633 \r\nL 351.277544 96.149036 \r\nL 353.0471 99.392027 \r\nL 354.816656 97.588538 \r\nL 356.586212 94.760693 \r\nL 358.355768 95.735696 \r\nL 360.125324 98.991691 \r\nL 361.89488 96.056061 \r\nL 363.664436 92.838205 \r\nL 365.433992 90.933628 \r\nL 367.203548 101.428778 \r\nL 368.973104 97.836439 \r\nL 370.74266 96.40002 \r\nL 372.512216 101.325946 \r\nL 374.281772 95.785578 \r\nL 376.051328 108.025786 \r\nL 377.820884 102.751883 \r\nL 379.59044 104.084986 \r\nL 381.359996 97.845191 \r\nL 383.129552 102.201168 \r\nL 384.899108 101.253528 \r\nL 386.668664 104.062919 \r\nL 388.43822 100.205002 \r\nL 390.207776 105.767655 \r\nL 391.977332 108.298402 \r\nL 393.746888 109.277688 \r\nL 395.516444 113.36583 \r\nL 397.286 108.610077 \r\nL 399.055556 112.493083 \r\nL 400.825112 106.869475 \r\nL 402.594668 112.731329 \r\nL 404.364224 108.927639 \r\nL 406.13378 110.748338 \r\nL 407.903336 116.726776 \r\nL 409.672892 107.066154 \r\nL 411.442448 112.079556 \r\nL 413.212004 107.37582 \r\nL 414.981561 122.703221 \r\nL 416.751117 124.205547 \r\nL 418.520673 118.134025 \r\nL 420.290229 115.914159 \r\nL 422.059785 113.069183 \r\nL 423.829341 125.361625 \r\nL 425.598897 122.146572 \r\nL 427.368453 122.454012 \r\nL 429.138009 125.744565 \r\nL 430.907565 123.627594 \r\nL 432.677121 122.934053 \r\nL 434.446677 122.74393 \r\nL 436.216233 130.622523 \r\nL 437.985789 129.283066 \r\nL 439.755345 129.630639 \r\nL 441.524901 130.60846 \r\nL 443.294457 131.304306 \r\nL 445.064013 127.452354 \r\nL 446.833569 138.522452 \r\nL 448.603125 128.293299 \r\nL 450.372681 133.312962 \r\nL 452.142237 137.790554 \r\nL 453.911793 129.472566 \r\nL 455.681349 137.619851 \r\nL 457.450905 138.047706 \r\nL 459.220461 137.821701 \r\nL 460.990017 136.392991 \r\nL 462.759573 142.382736 \r\nL 466.298685 138.747242 \r\nL 468.068241 145.815056 \r\nL 469.837797 151.463552 \r\nL 471.607353 144.965265 \r\nL 473.376909 146.723389 \r\nL 475.146465 150.324714 \r\nL 476.916021 152.762813 \r\nL 478.685577 157.101924 \r\nL 480.455133 152.711576 \r\nL 482.224689 156.153972 \r\nL 483.994246 157.593436 \r\nL 485.763802 155.229163 \r\nL 487.533358 156.84376 \r\nL 489.302914 154.123606 \r\nL 491.07247 160.948425 \r\nL 492.842026 162.656238 \r\nL 494.611582 166.051742 \r\nL 496.381138 170.555925 \r\nL 498.150694 166.895047 \r\nL 499.92025 165.457538 \r\nL 501.689806 172.042359 \r\nL 503.459362 173.685066 \r\nL 505.228918 169.497004 \r\nL 506.998474 176.866137 \r\nL 508.76803 180.496857 \r\nL 510.537586 175.364971 \r\nL 512.307142 180.24933 \r\nL 514.076698 183.246351 \r\nL 515.846254 184.192746 \r\nL 517.61581 182.80174 \r\nL 519.385366 192.472562 \r\nL 521.154922 190.565867 \r\nL 522.924478 189.732926 \r\nL 524.694034 195.926997 \r\nL 526.46359 196.221284 \r\nL 528.233146 195.27686 \r\nL 530.002702 198.375842 \r\nL 531.772258 199.842217 \r\nL 535.31137 206.473401 \r\nL 537.080926 206.706507 \r\nL 538.850482 208.302742 \r\nL 540.620038 207.370209 \r\nL 542.389594 212.977776 \r\nL 544.15915 217.294025 \r\nL 545.928706 212.441093 \r\nL 547.698262 216.304756 \r\nL 549.467818 218.865311 \r\nL 551.237374 220.814881 \r\nL 553.00693 225.159162 \r\nL 554.776487 225.192035 \r\nL 558.315599 229.643536 \r\nL 560.085155 227.689462 \r\nL 561.854711 233.489551 \r\nL 563.624267 233.464913 \r\nL 565.393823 236.498712 \r\nL 567.163379 236.921143 \r\nL 568.932935 239.774389 \r\nL 570.702491 237.004742 \r\nL 572.472047 243.81681 \r\nL 574.241603 242.849648 \r\nL 576.011159 245.954085 \r\nL 577.780715 244.628181 \r\nL 579.550271 250.834921 \r\nL 581.319827 249.381172 \r\nL 583.089383 251.374162 \r\nL 584.858939 250.999635 \r\nL 586.628495 252.638605 \r\nL 588.398051 252.006155 \r\nL 590.167607 257.505085 \r\nL 591.937163 258.052715 \r\nL 593.706719 260.952802 \r\nL 595.476275 262.960512 \r\nL 597.245831 260.791675 \r\nL 599.015387 264.315584 \r\nL 600.784943 263.563021 \r\nL 602.554499 266.115404 \r\nL 604.324055 266.962004 \r\nL 606.093611 265.594265 \r\nL 607.863167 265.626789 \r\nL 609.632723 268.313087 \r\nL 611.402279 270.370822 \r\nL 613.171835 270.124116 \r\nL 614.941391 271.976817 \r\nL 616.710947 269.802587 \r\nL 618.480503 271.941572 \r\nL 620.250059 271.51191 \r\nL 622.019615 273.345397 \r\nL 623.789172 272.856538 \r\nL 625.558728 275.072413 \r\nL 627.328284 274.102057 \r\nL 629.09784 276.296107 \r\nL 630.867396 275.300016 \r\nL 632.636952 277.055945 \r\nL 634.406508 276.497665 \r\nL 636.176064 275.679002 \r\nL 637.94562 277.275584 \r\nL 639.715176 276.172173 \r\nL 641.484732 277.884251 \r\nL 643.254288 278.202917 \r\nL 645.023844 277.396546 \r\nL 646.7934 278.267146 \r\nL 648.562956 277.924944 \r\nL 650.332512 277.753495 \r\nL 652.102068 278.34453 \r\nL 653.871624 272.300915 \r\nL 655.64118 278.373892 \r\nL 657.410736 278.490003 \r\nL 659.180292 277.257084 \r\nL 660.949848 278.134586 \r\nL 662.719404 278.33106 \r\nL 664.48896 277.957125 \r\nL 666.258516 278.461563 \r\nL 668.028072 279.146672 \r\nL 669.797628 279.120191 \r\nL 671.567184 277.530614 \r\nL 675.106296 278.581258 \r\nL 676.875852 272.424411 \r\nL 678.645408 278.851281 \r\nL 680.414964 278.727607 \r\nL 682.18452 279.051111 \r\nL 683.954076 278.546058 \r\nL 685.723632 279.49116 \r\nL 687.493188 277.331204 \r\nL 689.262744 279.514031 \r\nL 691.0323 279.080288 \r\nL 692.801857 279.404151 \r\nL 694.571413 278.643585 \r\nL 696.340969 278.934009 \r\nL 698.110525 273.627359 \r\nL 699.880081 279.240911 \r\nL 701.649637 272.422384 \r\nL 703.419193 279.055449 \r\nL 705.188749 272.928301 \r\nL 706.958305 279.575353 \r\nL 708.727861 278.947221 \r\nL 710.497417 279.306451 \r\nL 714.036529 278.653873 \r\nL 715.806085 278.972109 \r\nL 717.575641 278.08379 \r\nL 719.345197 278.405229 \r\nL 721.114753 278.473004 \r\nL 722.884309 279.487748 \r\nL 724.653865 278.052547 \r\nL 726.423421 278.820652 \r\nL 729.962533 279.306202 \r\nL 731.732089 278.791907 \r\nL 733.501645 279.572754 \r\nL 735.271201 273.887702 \r\nL 737.040757 279.188592 \r\nL 738.810313 278.189096 \r\nL 740.579869 277.43199 \r\nL 742.349425 279.029019 \r\nL 744.118981 279.125139 \r\nL 745.888537 278.277581 \r\nL 747.658093 278.492404 \r\nL 749.427649 278.186751 \r\nL 751.197205 279.792626 \r\nL 752.966761 279.3577 \r\nL 754.736317 279.098484 \r\nL 756.505873 279.716319 \r\nL 758.275429 279.511584 \r\nL 760.044985 279.166494 \r\nL 761.814541 279.154265 \r\nL 767.12321 279.624696 \r\nL 768.892766 278.955491 \r\nL 770.662322 278.912766 \r\nL 772.431878 279.489775 \r\nL 774.201434 279.447681 \r\nL 775.97099 273.701863 \r\nL 777.740546 279.203858 \r\nL 779.510102 278.901291 \r\nL 781.279658 273.07949 \r\nL 783.049214 279.089298 \r\nL 784.81877 279.041724 \r\nL 786.588326 279.349666 \r\nL 790.127438 279.283571 \r\nL 791.896994 278.777124 \r\nL 793.66655 279.507804 \r\nL 795.436106 278.787817 \r\nL 797.205662 279.34426 \r\nL 798.975218 279.327647 \r\nL 800.744774 279.646446 \r\nL 802.51433 279.151686 \r\nL 804.283886 279.711257 \r\nL 806.053442 279.124451 \r\nL 807.822998 279.624531 \r\nL 809.592554 279.97508 \r\nL 811.36211 278.414122 \r\nL 813.131666 278.549791 \r\nL 814.901222 273.674407 \r\nL 816.670778 278.247914 \r\nL 818.440334 279.411384 \r\nL 820.20989 279.460994 \r\nL 821.979446 279.880701 \r\nL 823.749002 273.263428 \r\nL 825.518558 278.278537 \r\nL 827.288114 279.933872 \r\nL 829.05767 279.71714 \r\nL 829.05767 279.71714 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p3afcede291)\" d=\"M 68.14858 34.67267 \r\nL 94.69192 37.357627 \r\nL 119.465704 40.074168 \r\nL 147.778601 43.399731 \r\nL 170.782829 46.322591 \r\nL 192.017501 49.19574 \r\nL 215.02173 52.548634 \r\nL 234.486846 55.573688 \r\nL 255.721518 59.121409 \r\nL 273.417078 62.293011 \r\nL 287.573527 65.069977 \r\nL 301.729975 68.063137 \r\nL 314.116867 70.866936 \r\nL 326.503759 73.881478 \r\nL 340.660207 77.558818 \r\nL 353.0471 81.008861 \r\nL 363.664436 84.17182 \r\nL 372.512216 87.031093 \r\nL 383.129552 90.675541 \r\nL 391.977332 93.952966 \r\nL 402.594668 98.148955 \r\nL 409.672892 101.144077 \r\nL 418.520673 105.168179 \r\nL 425.598897 108.565116 \r\nL 432.677121 112.13232 \r\nL 439.755345 115.941086 \r\nL 446.833569 120.018622 \r\nL 452.142237 123.245931 \r\nL 459.220461 127.800425 \r\nL 466.298685 132.624483 \r\nL 473.376909 137.741217 \r\nL 480.455133 143.178798 \r\nL 487.533358 148.960043 \r\nL 494.611582 155.097582 \r\nL 501.689806 161.499047 \r\nL 508.76803 168.235625 \r\nL 515.846254 175.252249 \r\nL 526.46359 186.226156 \r\nL 535.31137 195.827536 \r\nL 551.237374 213.448645 \r\nL 558.315599 221.281436 \r\nL 572.472047 236.509395 \r\nL 579.550271 243.623989 \r\nL 584.858939 248.594085 \r\nL 588.398051 251.770051 \r\nL 593.706719 256.105278 \r\nL 597.245831 258.778645 \r\nL 600.784943 261.248762 \r\nL 604.324055 263.541243 \r\nL 609.632723 266.720745 \r\nL 613.171835 268.633947 \r\nL 616.710947 270.342807 \r\nL 622.019615 272.634586 \r\nL 625.558728 273.980062 \r\nL 629.09784 275.078697 \r\nL 634.406508 276.435803 \r\nL 639.715176 277.554389 \r\nL 643.254288 278.198112 \r\nL 650.332512 279.141488 \r\nL 655.64118 279.660016 \r\nL 669.797628 280.650762 \r\nL 680.414964 281.005149 \r\nL 698.110525 281.33057 \r\nL 708.727861 281.316695 \r\nL 726.423421 281.494008 \r\nL 745.888537 281.546814 \r\nL 790.127438 281.715202 \r\nL 823.749002 281.751428 \r\nL 829.05767 281.73169 \r\nL 829.05767 281.73169 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 294.118125 \r\nL 30.103125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 867.103125 294.118125 \r\nL 867.103125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 294.118125 \r\nL 867.103125 294.118125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 22.318125 \r\nL 867.103125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_12\">\r\n    <!-- Model Training History  -->\r\n    <defs>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n     <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n     <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n     <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n     <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     <path id=\"DejaVuSans-32\"/>\r\n     <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n     <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n     <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n     <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n     <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n     <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 43.015625 \r\nL 55.515625 43.015625 \r\nL 55.515625 72.90625 \r\nL 65.375 72.90625 \r\nL 65.375 0 \r\nL 55.515625 0 \r\nL 55.515625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-72\"/>\r\n     <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n    </defs>\r\n    <g transform=\"translate(379.849688 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-77\"/>\r\n     <use x=\"86.279297\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"147.460938\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"210.9375\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"272.460938\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"300.244141\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"332.03125\" xlink:href=\"#DejaVuSans-84\"/>\r\n     <use x=\"378.365234\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"419.478516\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"480.757812\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"508.541016\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"571.919922\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"599.703125\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"663.082031\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"726.558594\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"758.345703\" xlink:href=\"#DejaVuSans-72\"/>\r\n     <use x=\"833.541016\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"861.324219\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"913.423828\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"952.632812\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"1013.814453\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"1054.927734\" xlink:href=\"#DejaVuSans-121\"/>\r\n     <use x=\"1114.107422\" xlink:href=\"#DejaVuSans-32\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 756.228125 59.674375 \r\nL 860.103125 59.674375 \r\nQ 862.103125 59.674375 862.103125 57.674375 \r\nL 862.103125 29.318125 \r\nQ 862.103125 27.318125 860.103125 27.318125 \r\nL 756.228125 27.318125 \r\nQ 754.228125 27.318125 754.228125 29.318125 \r\nL 754.228125 57.674375 \r\nQ 754.228125 59.674375 756.228125 59.674375 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_14\">\r\n     <path d=\"M 758.228125 35.416562 \r\nL 778.228125 35.416562 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\"/>\r\n    <g id=\"text_13\">\r\n     <!-- Training loss -->\r\n     <g transform=\"translate(786.228125 38.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"394.527344\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"426.314453\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"454.097656\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"515.279297\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"567.378906\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 758.228125 50.094688 \r\nL 778.228125 50.094688 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_14\">\r\n     <!-- Validation loss -->\r\n     <defs>\r\n      <path d=\"M 28.609375 0 \r\nL 0.78125 72.90625 \r\nL 11.078125 72.90625 \r\nL 34.1875 11.53125 \r\nL 57.328125 72.90625 \r\nL 67.578125 72.90625 \r\nL 39.796875 0 \r\nz\r\n\" id=\"DejaVuSans-86\"/>\r\n     </defs>\r\n     <g transform=\"translate(786.228125 53.594688)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-86\"/>\r\n      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"149.720703\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"177.503906\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"240.980469\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"302.259766\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"341.46875\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"369.251953\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"430.433594\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"493.8125\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"525.599609\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"553.382812\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"614.564453\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"666.664062\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p3afcede291\">\r\n   <rect height=\"271.8\" width=\"837\" x=\"30.103125\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "EPOCHS=1000\n",
    "batch_size=20\n",
    "#steps_per_epoch = int((num_train/batch_size)/2)\n",
    "#steps_per_epoch=256\n",
    "\n",
    "train_model(resume=False, fit_generator=False, epochs=EPOCHS, initial_epoch=0, batch_size=batch_size, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "#try:\n",
    "#    model.load_weights(path_checkpoint)\n",
    "#except Exception as error:\n",
    "    #print(\"Error trying to load checkpoint.\")\n",
    "    #print(error)\n",
    "\n",
    "for _ in range(10):\n",
    "    batch_size = np.random.randint(250)\n",
    "    model.fit(generator,\n",
    "                    epochs=4,\n",
    "                    steps_per_epoch=batch_size,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)\n",
    "    result = model.evaluate(x=validation_data[0], y=validation_data[1])\n",
    "    if result<=0.00041:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint\n",
    "\n",
    "Because we use early-stopping when training the model, it is possible that the model's performance has worsened on the test-set for several epochs before training was stopped. We therefore reload the last saved checkpoint, which should have the best performance on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Test-Set\n",
    "\n",
    "We can now evaluate the model's performance on the test-set. This function expects a batch of data, but we will just use one long time-series for the test-set, so we just expand the array-dimensionality to create a batch with that one sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test_scaled,y_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss (test-set): 0.019671950489282608\n"
     ]
    }
   ],
   "source": [
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have several metrics you can use this instead.\n",
    "if False:\n",
    "    for res, metric in zip(result, model.metrics_names):\n",
    "        print(\"{0}: {1:.3e}\".format(metric, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions\n",
    "\n",
    "This helper-function plots the predicted and true output-signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Output: [[72.99503 ]\n [69.79742 ]\n [69.26444 ]\n [66.68957 ]\n [64.74388 ]\n [64.31577 ]\n [58.557243]\n [66.59733 ]\n [72.50849 ]\n [70.972664]\n [57.117764]\n [66.44183 ]\n [75.37403 ]\n [70.074   ]\n [68.05224 ]\n [72.75919 ]\n [59.65115 ]\n [68.05224 ]\n [72.141045]]\nDifference: [[  5.00496674]\n [  0.20258331]\n [ -1.26444244]\n [ -6.68956757]\n [-17.74388123]\n [ -6.31577301]\n [ -8.55724335]\n [  3.40267181]\n [ 12.49150848]\n [ -8.97266388]\n [-17.11776352]\n [ -9.4418335 ]\n [-11.37403107]\n [-12.0739975 ]\n [-28.05223846]\n [ -4.75919342]\n [ -5.65114975]\n [-28.05223846]\n [ -4.14104462]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test_scaled, verbose=0)\n",
    "y_predict = y_scaler.inverse_transform(y_predict)\n",
    "print('Model Output:', y_predict)\n",
    "print('Difference:', y_scaler.inverse_transform(y_test_scaled)-y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-3c10957f8f23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = next(train_generator)\n",
    "x[0].shape\n",
    "x_scaler.inverse_transform(x[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(start_idx, length=100, train=True):\n",
    "    \"\"\"\n",
    "    Plot the predicted and true output-signals.\n",
    "    \n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if train:\n",
    "        # Use training-data.\n",
    "        x, y_true = next(train_generator)\n",
    "        x, y_true = x[0], y_true[0]\n",
    "        y_signal = x_scaler.inverse_transform(x)[:,:num_y_signals]\n",
    "        y_true = y_scaler.inverse_transform(y_true)[:,:num_y_signals]\n",
    "        \n",
    "    else:\n",
    "        # Use test-data.\n",
    "        print('Using test data')\n",
    "        x, y_true = next(validation_generator)\n",
    "        x, y_true = x[0], y_true[0]\n",
    "        y_signal = x_scaler.inverse_transform(x)[:,:num_y_signals]\n",
    "        y_true = y_scaler.inverse_transform(y_true)[:,:num_y_signals]\n",
    "        \n",
    "    print(x.shape)      \n",
    "    # Input-signals for the model.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Use the model to predict the output-signals.\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # The output of the model is between 0 and 1.\n",
    "    # Do an inverse map to get it back to the scale\n",
    "    # of the original data-set.\n",
    "    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n",
    "    \n",
    "    # For each output-signal.\n",
    "    #for signal in range(len(target_names)):\n",
    "    for signal in range(num_y_signals):\n",
    "        # Get the output-signal predicted by the model.\n",
    "        signal_pred = y_pred_rescaled[:, signal]\n",
    "        \n",
    "        # Get the true output-signal from the data-set.\n",
    "        signal_true = y_true[:, signal]\n",
    "        \n",
    "        # Get the input-signals used for prediction.\n",
    "        #y_signal = y_signal[warmup_steps:, signal]\n",
    "\n",
    "        # Make the plotting-canvas bigger.\n",
    "        plt.figure(figsize=(35,5))\n",
    "        \n",
    "        # Plot and compare the two signals.\n",
    "        plt.plot(signal_true, label='true')\n",
    "        plt.plot(signal_pred, label='pred')\n",
    "        #plt.plot(y_signal, label='input')\n",
    "        \n",
    "\n",
    "        # Plot grey box for warmup-period.\n",
    "        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n",
    "        \n",
    "        # Plot labels etc.\n",
    "        plt.ylabel(target_names[signal])\n",
    "        plt.grid(color='b', linestyle='-.', linewidth=0.15)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return y_pred_rescaled, y_true, y_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=-sequence_length+20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plot_comparison(start_idx=-look_back, length=look_back-1, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot an example of predicted output-signals. It is important to understand what these plots show, as they are actually a bit more complicated than you might think.\n",
    "\n",
    "These plots only show the output-signals and not the 336 input-signals used to predict the output-signals. The time-shift between the input-signals and the output-signals is held fixed in these plots. The model **always** predicts the output-signals e.g. 24 hours into the future (as defined in the `shift_steps` variable above). So the plot's x-axis merely shows how many time-steps of the input-signals have been seen by the predictive model so far.\n",
    "\n",
    "The prediction is not very accurate for the first 30-50 time-steps because the model has seen very little input-data at this point.\n",
    "The model generates a single time-step of output data for each time-step of the input-data, so when the model has only run for a few time-steps, it knows very little of the history of the input-signals and cannot make an accurate prediction. The model needs to \"warm up\" by processing perhaps 30-50 time-steps before its predicted output-signals can be used.\n",
    "\n",
    "That is why we ignore this \"warmup-period\" of 50 time-steps when calculating the mean-squared-error in the loss-function. The \"warmup-period\" is shown as a grey box in these plots.\n",
    "\n",
    "Let us start with an example from the training-data. This is data that the model has seen during training so it should perform reasonably well on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal_pred0, signal_true0, y_signal0 = plot_comparison(start_idx=look_back, length=np.abs(look_back+1), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_pred0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(signal_true0[:,2]),pd.DataFrame(signal_pred0[:,2]),pd.DataFrame(y_signal0[:,2])])#.plot(figsize=(35,5), subplots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(signal_pred0).tail(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f1d78661a2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal_true0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(signal_true0).tail(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a4023953c488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myPred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal_pred0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mshift_steps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myPred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myPred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "yPred = pd.DataFrame(signal_pred0).values[:-shift_steps]\n",
    "print(yPred.shape)\n",
    "pd.DataFrame(yPred).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a959de42ee1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myTrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal_true0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mshift_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshift_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "yTrue = pd.DataFrame(signal_true0).shift(2*shift_steps).values[shift_steps:]\n",
    "print(yTrue.shape)\n",
    "pd.DataFrame(yTrue).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'target_names' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ceca2068f04a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msignal\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[1;31m# Get the output-signal predicted by the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msignal_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myPred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# Get the true output-signal from the data-set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_names' is not defined"
     ]
    }
   ],
   "source": [
    "for signal in range(len(target_names)):\n",
    "        # Get the output-signal predicted by the model.\n",
    "        signal_pred = yPred[warmup_steps:, signal]\n",
    "        \n",
    "        # Get the true output-signal from the data-set.\n",
    "        signal_true = yTrue[warmup_steps:, signal]\n",
    "\n",
    "        # Make the plotting-canvas bigger.\n",
    "        plt.figure(figsize=(35,10))\n",
    "        \n",
    "        # Plot and compare the two signals.\n",
    "        plt.plot(signal_true, label='true')\n",
    "        plt.plot(signal_pred, label='pred')\n",
    "        \n",
    "        # Plot grey box for warmup-period.\n",
    "        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n",
    "        \n",
    "        # Plot labels etc.\n",
    "        plt.ylabel(target_names[signal])\n",
    "        plt.grid(color='b', linestyle='-.', linewidth=0.15)\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'myData' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-290d7cad4376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_scaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQuantileTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_data_scaled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_data_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_data_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'myData' is not defined"
     ]
    }
   ],
   "source": [
    "x_data = myData.values\n",
    "print(x_data.shape)\n",
    "x_scaler=QuantileTransformer()\n",
    "x_data_scaled=x_scaler.fit_transform(x_data)\n",
    "print(x_data_scaled.min(),x_data_scaled.max(),x_data_scaled.shape)\n",
    "y_data = x_data[:,:4]\n",
    "y_scaler=QuantileTransformer()\n",
    "y_data_scaled=y_scaler.fit_transform(y_data)\n",
    "print(y_data_scaled.min(),y_data_scaled.max(),y_data_scaled.shape)\n",
    "#x_data_rescaled = x_scaler.inverse_transform(x_data_scaled)\n",
    "#plt.plot(x_data_rescaled[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(look_back, x_data=True):\n",
    "    \"\"\"\n",
    "    Plot the predicted and true output-signals.\n",
    "    \n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if x_data:\n",
    "        # Use training-data.\n",
    "        x = x_data_scaled[-look_back:]\n",
    "        num_x = x.shape[1]\n",
    "        y_true = x_scaler.inverse_transform(x)[:,:4]\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        print('x_input.shape:',x.shape)\n",
    "        print('y_true.shape:',y_true.shape)\n",
    "    else:\n",
    "        print('No data input to model')\n",
    "   \n",
    "   \n",
    "    # Use the model to predict the output-signals.\n",
    "    y_pred = model.predict(x)\n",
    "    #print(y_pred.shape)\n",
    "    # The output of the model is between 0 and 1.\n",
    "    # Do an inverse map to get it back to the scale\n",
    "    # of the original data-set.\n",
    "    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n",
    "    print('y_pred_rescaled: ',y_pred_rescaled.shape)\n",
    "    # For each output-signal.\n",
    "    for signal in range(len(target_names)):\n",
    "        # Get the output-signal predicted by the model.\n",
    "        signal_pred = y_pred_rescaled[warmup_steps:, signal]\n",
    "        \n",
    "        # Get the true output-signal from the data-set.\n",
    "        signal_true = y_true[warmup_steps:, signal]\n",
    "        \n",
    "        # Make the plotting-canvas bigger.\n",
    "        plt.figure(figsize=(35,10))\n",
    "        \n",
    "        # Plot and compare the two signals.\n",
    "        plt.plot(signal_true, label='true')\n",
    "        plt.plot(signal_pred, label='pred')\n",
    "        \n",
    "        # Plot grey box for warmup-period.\n",
    "        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n",
    "        \n",
    "        # Plot labels etc.\n",
    "        plt.ylabel(target_names[signal])\n",
    "        plt.grid(color='b', linestyle='-.', linewidth=0.15)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return y_pred_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'shift_steps' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-30d5651e1a4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfuture_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshift_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_pred_rescaled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_forecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pred_rescaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shift_steps' is not defined"
     ]
    }
   ],
   "source": [
    "future_steps=shift_steps\n",
    "look_back=sequence_length\n",
    "x_pred_rescaled=plot_forecast(look_back=look_back, x_data=True)\n",
    "print(x_pred_rescaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was able to predict the overall oscillations of the temperature quite well but the peaks were sometimes inaccurate. For the wind-speed, the overall oscillations are predicted reasonably well but the peaks are quite inaccurate. For the atmospheric pressure, the overall curve-shape has been predicted although there seems to be a slight lag and the predicted curve has a lot of noise compared to the smoothness of the original signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_comparison(start_idx=-look_back, length=look_back-1, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check, we can plot this signal directly from the resampled data-set, which looks similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the same period from the original data that has not been resampled. It also looks similar.\n",
    "\n",
    "So either the temperature was unusually stable for a part of this period, or there is a data-error in the raw data that was obtained from the internet weather-database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'shift_steps' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7dfe36afc500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffsets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDateOffset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0madd_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mDateOffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshift_steps\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfuture_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shift_steps' is not defined"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import DateOffset\n",
    "add_dates = [myData.index[-1] + DateOffset(hours=4*x) for x in range(0,shift_steps+1) ]\n",
    "future_dates = pd.DataFrame(index=add_dates[1:],columns=myData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_pred_rescaled' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cabe93206c49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df_predict = pd.DataFrame(x_pred_rescaled[-shift_steps:],\n\u001b[0m\u001b[0;32m      2\u001b[0m                           index=future_dates[-shift_steps:].index, columns=list(myData.columns.values))\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_pred_rescaled' is not defined"
     ]
    }
   ],
   "source": [
    "df_predict = pd.DataFrame(x_pred_rescaled[-shift_steps:],\n",
    "                          index=future_dates[-shift_steps:].index, columns=list(myData.columns.values))\n",
    "\n",
    "df_predict=pd.DataFrame(df_predict)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_predict' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a4e09ba8e775>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_predict' is not defined"
     ]
    }
   ],
   "source": [
    "df_predict.index.name='datetime'\n",
    "df_predict\n",
    "myData.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address1=r'C:\\Users\\hp\\Desktop\\myData.csv'\n",
    "Address2=r'C:\\Users\\hp\\Desktop\\df_pred.csv'\n",
    "Address3=r'C:\\Users\\hp\\Desktop\\output.csv'\n",
    "os.rmdir(Address1)\n",
    "os.rmdir(Address2)\n",
    "os.rmdir(Address3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_predict' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-8bec57c69395>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\hp\\Desktop\\myData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\hp\\Desktop\\df_pred.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_predict' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(myData).to_csv(r'C:\\Users\\hp\\Desktop\\myData.csv')\n",
    "pd.DataFrame(df_predict).to_csv(r'C:\\Users\\hp\\Desktop\\df_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(r'C:\\Users\\hp\\Desktop\\myData.csv',header=None)\n",
    "b = pd.read_csv(r'C:\\Users\\hp\\Desktop\\df_pred.csv',header=None)\n",
    "b = b.dropna(axis=0)\n",
    "merged = pd.concat([a, b])\n",
    "merged.to_csv(r'C:\\Users\\hp\\Desktop\\output.csv', index=None, header=None)\n",
    "df_proj = pd.read_csv(r'C:\\Users\\hp\\Desktop\\output.csv',delimiter=',',low_memory=False)#index_col=[0], parse_dates=True)\n",
    "\n",
    "df_proj = df_proj.set_index('datetime')\n",
    "df_proj=(df_proj.assign(datetime=lambda df_proj: pd.to_datetime(df_proj.index))\n",
    "         .set_index('datetime'))\n",
    "#type(df_proj.index)\n",
    "df_proj.tail(future_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Vanilla LSTM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n[[102.23133]]\n"
    }
   ],
   "source": [
    "# univariate lstm example\n",
    "from numpy import array\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate stacked lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\nWARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n[[102.75422]]\n"
    }
   ],
   "source": [
    "from numpy import array\n",
    " \n",
    "# split a univariate sequence\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Bidirectional lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\nWARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\nWARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n[[102.50265]]\n"
    }
   ],
   "source": [
    "\n",
    "# split a univariate sequence\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate CNN lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n[[100.93751]]\n"
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate ConvLSTM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hstack' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-4d8fda1a0df7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mout_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# horizontally stack columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_seq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_seq2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m# choose a number of time steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hstack' is not defined"
     ]
    }
   ],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate output stacked lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=400, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Step LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate multi-step vector-output stacked lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(336, 4) (2, 5)\n"
    }
   ],
   "source": [
    "from numpy import array\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 5\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "print(x.shape,y.shape)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "##model.add(LSTM(100, activation='relu'))\n",
    "#model.add(Dense(n_steps_out))\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=50, verbose=0)\n",
    "# demonstrate prediction\n",
    "#x_input = array([70, 80, 90])\n",
    "#x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "#yhat = model.predict(x_input, verbose=0)\n",
    "#print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate multi-step encoder-decoder lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\nWARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n[[[ 97.31378 ]\n  [109.932556]]]\n"
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Multi-Step LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Multi-Step Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate multi-step stacked lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(31040, 4) (3449, 4) (34489, 4)\n"
    }
   ],
   "source": [
    "print(myData.values[:num_train].shape,\n",
    "myData.values[num_train:].shape,\n",
    "myData.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(30705, 335, 4) (30705, 4)\n[[1.2734 1.2755 1.2723 1.273 ]\n [1.273  1.2789 1.273  1.2778]\n [1.2778 1.281  1.2775 1.2805]\n ...\n [1.3452 1.3462 1.342  1.3448]\n [1.3438 1.3487 1.3432 1.3465]\n [1.3455 1.3522 1.3455 1.351 ]] [1.3506 1.3548 1.3498 1.3548]\nEpoch 1/200\n  416/30705 [..............................] - ETA: 51:51 - loss: 2.4792"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-350-0e2845c5bd8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;31m# demonstrate prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mx_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps_in\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;31m# Delegate logic to `fit_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m         return training_arrays.fit_loop(self, fit_function, fit_inputs,\n\u001b[0m\u001b[0;32m   1228\u001b[0m                                         \u001b[0mout_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out-1\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix-1,:], sequences[end_ix-1:out_end_ix, :4]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y).reshape(len(y),4)\n",
    "\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 336, 1\n",
    "\n",
    "# covert into input/output\n",
    "X, y = split_sequences(myData.values[:num_train], n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_steps_in=n_steps_in-1\n",
    "n_features = X.shape[2]\n",
    "print(X.shape,y.shape)\n",
    "#pd.DataFrame(np.vstack([X[0],y[0]])).tail(10)\n",
    "print(X[0],y[0])\n",
    "# define model\n",
    "#del model\n",
    "model = Sequential()\n",
    "model.add(LSTM(768, activation='selu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(768, activation='selu'))\n",
    "model.add(Dense(4, activation='selu'))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=1)\n",
    "# demonstrate prediction\n",
    "x_input,y_output = split_sequences(myData.values[num_train:], n_steps_in+1, n_steps_out)\n",
    "x_input[0].shape,y_output[0].shape\n",
    "print(x_input[0],y_output[0])\n",
    "print(myData.values[num_train:num_train+n_steps_in+1])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=1)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate multi-step encoder-decoder lstm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hstack' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-74d16e6d4567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mout_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# horizontally stack columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_seq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_seq2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# choose a number of time steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hstack' is not defined"
     ]
    }
   ],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "for i in range(len(y)): print(X[i],y[i])\n",
    "n_features = X.shape[2]\n",
    "print(X.shape)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=300, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python38264bitad33d1ee1d09461ead214b7fdb01f87d",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "e588a23f49329b9290dda077d79a9005879a30fe97c1fa2c6a93e79fd5926943"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}